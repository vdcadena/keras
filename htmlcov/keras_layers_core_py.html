


<!DOCTYPE html>
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    
    
    <meta http-equiv="X-UA-Compatible" content="IE=emulateIE7" />
    <title>Coverage for keras/layers/core.py: 94%</title>
    <link rel="stylesheet" href="style.css" type="text/css">
    
    <script type="text/javascript" src="jquery.min.js"></script>
    <script type="text/javascript" src="jquery.hotkeys.js"></script>
    <script type="text/javascript" src="jquery.isonscreen.js"></script>
    <script type="text/javascript" src="coverage_html.js"></script>
    <script type="text/javascript">
        jQuery(document).ready(coverage.pyfile_ready);
    </script>
</head>
<body class="pyfile">

<div id="header">
    <div class="content">
        <h1>Coverage for <b>keras/layers/core.py</b> :
            <span class="pc_cov">94%</span>
        </h1>

        <img id="keyboard_icon" src="keybd_closed.png" alt="Show keyboard shortcuts" />

        <h2 class="stats">
            347 statements &nbsp;
            <span class="run hide_run shortkey_r button_toggle_run">327 run</span>
            <span class="mis shortkey_m button_toggle_mis">20 missing</span>
            <span class="exc shortkey_x button_toggle_exc">0 excluded</span>

            
        </h2>
    </div>
</div>

<div class="help_panel">
    <img id="panel_icon" src="keybd_open.png" alt="Hide keyboard shortcuts" />
    <p class="legend">Hot-keys on this page</p>
    <div>
    <p class="keyhelp">
        <span class="key">r</span>
        <span class="key">m</span>
        <span class="key">x</span>
        <span class="key">p</span> &nbsp; toggle line displays
    </p>
    <p class="keyhelp">
        <span class="key">j</span>
        <span class="key">k</span> &nbsp; next/prev highlighted chunk
    </p>
    <p class="keyhelp">
        <span class="key">0</span> &nbsp; (zero) top of page
    </p>
    <p class="keyhelp">
        <span class="key">1</span> &nbsp; (one) first highlighted chunk
    </p>
    </div>
</div>

<div id="source">
    <table>
        <tr>
            <td class="linenos">
<p id="n1" class="pln"><a href="#n1">1</a></p>
<p id="n2" class="stm run hide_run"><a href="#n2">2</a></p>
<p id="n3" class="pln"><a href="#n3">3</a></p>
<p id="n4" class="stm run hide_run"><a href="#n4">4</a></p>
<p id="n5" class="stm run hide_run"><a href="#n5">5</a></p>
<p id="n6" class="stm run hide_run"><a href="#n6">6</a></p>
<p id="n7" class="pln"><a href="#n7">7</a></p>
<p id="n8" class="stm run hide_run"><a href="#n8">8</a></p>
<p id="n9" class="pln"><a href="#n9">9</a></p>
<p id="n10" class="stm run hide_run"><a href="#n10">10</a></p>
<p id="n11" class="stm run hide_run"><a href="#n11">11</a></p>
<p id="n12" class="stm run hide_run"><a href="#n12">12</a></p>
<p id="n13" class="pln"><a href="#n13">13</a></p>
<p id="n14" class="stm run hide_run"><a href="#n14">14</a></p>
<p id="n15" class="stm run hide_run"><a href="#n15">15</a></p>
<p id="n16" class="stm run hide_run"><a href="#n16">16</a></p>
<p id="n17" class="stm run hide_run"><a href="#n17">17</a></p>
<p id="n18" class="stm run hide_run"><a href="#n18">18</a></p>
<p id="n19" class="stm run hide_run"><a href="#n19">19</a></p>
<p id="n20" class="stm run hide_run"><a href="#n20">20</a></p>
<p id="n21" class="stm run hide_run"><a href="#n21">21</a></p>
<p id="n22" class="stm run hide_run"><a href="#n22">22</a></p>
<p id="n23" class="stm run hide_run"><a href="#n23">23</a></p>
<p id="n24" class="stm run hide_run"><a href="#n24">24</a></p>
<p id="n25" class="stm run hide_run"><a href="#n25">25</a></p>
<p id="n26" class="pln"><a href="#n26">26</a></p>
<p id="n27" class="pln"><a href="#n27">27</a></p>
<p id="n28" class="stm run hide_run"><a href="#n28">28</a></p>
<p id="n29" class="pln"><a href="#n29">29</a></p>
<p id="n30" class="pln"><a href="#n30">30</a></p>
<p id="n31" class="pln"><a href="#n31">31</a></p>
<p id="n32" class="pln"><a href="#n32">32</a></p>
<p id="n33" class="pln"><a href="#n33">33</a></p>
<p id="n34" class="pln"><a href="#n34">34</a></p>
<p id="n35" class="pln"><a href="#n35">35</a></p>
<p id="n36" class="pln"><a href="#n36">36</a></p>
<p id="n37" class="pln"><a href="#n37">37</a></p>
<p id="n38" class="pln"><a href="#n38">38</a></p>
<p id="n39" class="pln"><a href="#n39">39</a></p>
<p id="n40" class="pln"><a href="#n40">40</a></p>
<p id="n41" class="pln"><a href="#n41">41</a></p>
<p id="n42" class="pln"><a href="#n42">42</a></p>
<p id="n43" class="pln"><a href="#n43">43</a></p>
<p id="n44" class="pln"><a href="#n44">44</a></p>
<p id="n45" class="pln"><a href="#n45">45</a></p>
<p id="n46" class="pln"><a href="#n46">46</a></p>
<p id="n47" class="pln"><a href="#n47">47</a></p>
<p id="n48" class="pln"><a href="#n48">48</a></p>
<p id="n49" class="pln"><a href="#n49">49</a></p>
<p id="n50" class="pln"><a href="#n50">50</a></p>
<p id="n51" class="pln"><a href="#n51">51</a></p>
<p id="n52" class="pln"><a href="#n52">52</a></p>
<p id="n53" class="pln"><a href="#n53">53</a></p>
<p id="n54" class="pln"><a href="#n54">54</a></p>
<p id="n55" class="pln"><a href="#n55">55</a></p>
<p id="n56" class="pln"><a href="#n56">56</a></p>
<p id="n57" class="pln"><a href="#n57">57</a></p>
<p id="n58" class="stm run hide_run"><a href="#n58">58</a></p>
<p id="n59" class="stm run hide_run"><a href="#n59">59</a></p>
<p id="n60" class="stm run hide_run"><a href="#n60">60</a></p>
<p id="n61" class="stm run hide_run"><a href="#n61">61</a></p>
<p id="n62" class="pln"><a href="#n62">62</a></p>
<p id="n63" class="stm run hide_run"><a href="#n63">63</a></p>
<p id="n64" class="stm run hide_run"><a href="#n64">64</a></p>
<p id="n65" class="stm run hide_run"><a href="#n65">65</a></p>
<p id="n66" class="pln"><a href="#n66">66</a></p>
<p id="n67" class="stm run hide_run"><a href="#n67">67</a></p>
<p id="n68" class="stm run hide_run"><a href="#n68">68</a></p>
<p id="n69" class="pln"><a href="#n69">69</a></p>
<p id="n70" class="stm run hide_run"><a href="#n70">70</a></p>
<p id="n71" class="pln"><a href="#n71">71</a></p>
<p id="n72" class="stm run hide_run"><a href="#n72">72</a></p>
<p id="n73" class="stm run hide_run"><a href="#n73">73</a></p>
<p id="n74" class="stm run hide_run"><a href="#n74">74</a></p>
<p id="n75" class="stm run hide_run"><a href="#n75">75</a></p>
<p id="n76" class="pln"><a href="#n76">76</a></p>
<p id="n77" class="stm run hide_run"><a href="#n77">77</a></p>
<p id="n78" class="stm run hide_run"><a href="#n78">78</a></p>
<p id="n79" class="pln"><a href="#n79">79</a></p>
<p id="n80" class="pln"><a href="#n80">80</a></p>
<p id="n81" class="stm run hide_run"><a href="#n81">81</a></p>
<p id="n82" class="pln"><a href="#n82">82</a></p>
<p id="n83" class="pln"><a href="#n83">83</a></p>
<p id="n84" class="pln"><a href="#n84">84</a></p>
<p id="n85" class="pln"><a href="#n85">85</a></p>
<p id="n86" class="pln"><a href="#n86">86</a></p>
<p id="n87" class="pln"><a href="#n87">87</a></p>
<p id="n88" class="pln"><a href="#n88">88</a></p>
<p id="n89" class="pln"><a href="#n89">89</a></p>
<p id="n90" class="pln"><a href="#n90">90</a></p>
<p id="n91" class="pln"><a href="#n91">91</a></p>
<p id="n92" class="pln"><a href="#n92">92</a></p>
<p id="n93" class="pln"><a href="#n93">93</a></p>
<p id="n94" class="pln"><a href="#n94">94</a></p>
<p id="n95" class="pln"><a href="#n95">95</a></p>
<p id="n96" class="pln"><a href="#n96">96</a></p>
<p id="n97" class="pln"><a href="#n97">97</a></p>
<p id="n98" class="pln"><a href="#n98">98</a></p>
<p id="n99" class="pln"><a href="#n99">99</a></p>
<p id="n100" class="pln"><a href="#n100">100</a></p>
<p id="n101" class="pln"><a href="#n101">101</a></p>
<p id="n102" class="stm run hide_run"><a href="#n102">102</a></p>
<p id="n103" class="stm run hide_run"><a href="#n103">103</a></p>
<p id="n104" class="stm run hide_run"><a href="#n104">104</a></p>
<p id="n105" class="stm run hide_run"><a href="#n105">105</a></p>
<p id="n106" class="stm run hide_run"><a href="#n106">106</a></p>
<p id="n107" class="stm run hide_run"><a href="#n107">107</a></p>
<p id="n108" class="stm run hide_run"><a href="#n108">108</a></p>
<p id="n109" class="pln"><a href="#n109">109</a></p>
<p id="n110" class="stm run hide_run"><a href="#n110">110</a></p>
<p id="n111" class="stm run hide_run"><a href="#n111">111</a></p>
<p id="n112" class="stm run hide_run"><a href="#n112">112</a></p>
<p id="n113" class="pln"><a href="#n113">113</a></p>
<p id="n114" class="stm run hide_run"><a href="#n114">114</a></p>
<p id="n115" class="stm run hide_run"><a href="#n115">115</a></p>
<p id="n116" class="pln"><a href="#n116">116</a></p>
<p id="n117" class="stm run hide_run"><a href="#n117">117</a></p>
<p id="n118" class="pln"><a href="#n118">118</a></p>
<p id="n119" class="stm run hide_run"><a href="#n119">119</a></p>
<p id="n120" class="stm run hide_run"><a href="#n120">120</a></p>
<p id="n121" class="stm run hide_run"><a href="#n121">121</a></p>
<p id="n122" class="pln"><a href="#n122">122</a></p>
<p id="n123" class="stm run hide_run"><a href="#n123">123</a></p>
<p id="n124" class="stm run hide_run"><a href="#n124">124</a></p>
<p id="n125" class="pln"><a href="#n125">125</a></p>
<p id="n126" class="stm run hide_run"><a href="#n126">126</a></p>
<p id="n127" class="pln"><a href="#n127">127</a></p>
<p id="n128" class="stm mis"><a href="#n128">128</a></p>
<p id="n129" class="pln"><a href="#n129">129</a></p>
<p id="n130" class="stm run hide_run"><a href="#n130">130</a></p>
<p id="n131" class="stm run hide_run"><a href="#n131">131</a></p>
<p id="n132" class="pln"><a href="#n132">132</a></p>
<p id="n133" class="pln"><a href="#n133">133</a></p>
<p id="n134" class="stm run hide_run"><a href="#n134">134</a></p>
<p id="n135" class="stm run hide_run"><a href="#n135">135</a></p>
<p id="n136" class="pln"><a href="#n136">136</a></p>
<p id="n137" class="stm run hide_run"><a href="#n137">137</a></p>
<p id="n138" class="stm run hide_run"><a href="#n138">138</a></p>
<p id="n139" class="pln"><a href="#n139">139</a></p>
<p id="n140" class="pln"><a href="#n140">140</a></p>
<p id="n141" class="stm run hide_run"><a href="#n141">141</a></p>
<p id="n142" class="pln"><a href="#n142">142</a></p>
<p id="n143" class="pln"><a href="#n143">143</a></p>
<p id="n144" class="pln"><a href="#n144">144</a></p>
<p id="n145" class="pln"><a href="#n145">145</a></p>
<p id="n146" class="pln"><a href="#n146">146</a></p>
<p id="n147" class="pln"><a href="#n147">147</a></p>
<p id="n148" class="pln"><a href="#n148">148</a></p>
<p id="n149" class="pln"><a href="#n149">149</a></p>
<p id="n150" class="pln"><a href="#n150">150</a></p>
<p id="n151" class="pln"><a href="#n151">151</a></p>
<p id="n152" class="pln"><a href="#n152">152</a></p>
<p id="n153" class="pln"><a href="#n153">153</a></p>
<p id="n154" class="pln"><a href="#n154">154</a></p>
<p id="n155" class="pln"><a href="#n155">155</a></p>
<p id="n156" class="pln"><a href="#n156">156</a></p>
<p id="n157" class="pln"><a href="#n157">157</a></p>
<p id="n158" class="pln"><a href="#n158">158</a></p>
<p id="n159" class="pln"><a href="#n159">159</a></p>
<p id="n160" class="pln"><a href="#n160">160</a></p>
<p id="n161" class="pln"><a href="#n161">161</a></p>
<p id="n162" class="pln"><a href="#n162">162</a></p>
<p id="n163" class="pln"><a href="#n163">163</a></p>
<p id="n164" class="pln"><a href="#n164">164</a></p>
<p id="n165" class="pln"><a href="#n165">165</a></p>
<p id="n166" class="pln"><a href="#n166">166</a></p>
<p id="n167" class="stm run hide_run"><a href="#n167">167</a></p>
<p id="n168" class="pln"><a href="#n168">168</a></p>
<p id="n169" class="stm run hide_run"><a href="#n169">169</a></p>
<p id="n170" class="stm run hide_run"><a href="#n170">170</a></p>
<p id="n171" class="pln"><a href="#n171">171</a></p>
<p id="n172" class="stm run hide_run"><a href="#n172">172</a></p>
<p id="n173" class="stm run hide_run"><a href="#n173">173</a></p>
<p id="n174" class="stm run hide_run"><a href="#n174">174</a></p>
<p id="n175" class="stm run hide_run"><a href="#n175">175</a></p>
<p id="n176" class="pln"><a href="#n176">176</a></p>
<p id="n177" class="pln"><a href="#n177">177</a></p>
<p id="n178" class="stm run hide_run"><a href="#n178">178</a></p>
<p id="n179" class="pln"><a href="#n179">179</a></p>
<p id="n180" class="pln"><a href="#n180">180</a></p>
<p id="n181" class="pln"><a href="#n181">181</a></p>
<p id="n182" class="pln"><a href="#n182">182</a></p>
<p id="n183" class="pln"><a href="#n183">183</a></p>
<p id="n184" class="pln"><a href="#n184">184</a></p>
<p id="n185" class="pln"><a href="#n185">185</a></p>
<p id="n186" class="pln"><a href="#n186">186</a></p>
<p id="n187" class="pln"><a href="#n187">187</a></p>
<p id="n188" class="pln"><a href="#n188">188</a></p>
<p id="n189" class="pln"><a href="#n189">189</a></p>
<p id="n190" class="pln"><a href="#n190">190</a></p>
<p id="n191" class="pln"><a href="#n191">191</a></p>
<p id="n192" class="pln"><a href="#n192">192</a></p>
<p id="n193" class="pln"><a href="#n193">193</a></p>
<p id="n194" class="pln"><a href="#n194">194</a></p>
<p id="n195" class="pln"><a href="#n195">195</a></p>
<p id="n196" class="pln"><a href="#n196">196</a></p>
<p id="n197" class="pln"><a href="#n197">197</a></p>
<p id="n198" class="pln"><a href="#n198">198</a></p>
<p id="n199" class="pln"><a href="#n199">199</a></p>
<p id="n200" class="pln"><a href="#n200">200</a></p>
<p id="n201" class="pln"><a href="#n201">201</a></p>
<p id="n202" class="pln"><a href="#n202">202</a></p>
<p id="n203" class="pln"><a href="#n203">203</a></p>
<p id="n204" class="pln"><a href="#n204">204</a></p>
<p id="n205" class="pln"><a href="#n205">205</a></p>
<p id="n206" class="pln"><a href="#n206">206</a></p>
<p id="n207" class="pln"><a href="#n207">207</a></p>
<p id="n208" class="pln"><a href="#n208">208</a></p>
<p id="n209" class="pln"><a href="#n209">209</a></p>
<p id="n210" class="pln"><a href="#n210">210</a></p>
<p id="n211" class="pln"><a href="#n211">211</a></p>
<p id="n212" class="pln"><a href="#n212">212</a></p>
<p id="n213" class="stm run hide_run"><a href="#n213">213</a></p>
<p id="n214" class="stm run hide_run"><a href="#n214">214</a></p>
<p id="n215" class="stm run hide_run"><a href="#n215">215</a></p>
<p id="n216" class="stm run hide_run"><a href="#n216">216</a></p>
<p id="n217" class="stm run hide_run"><a href="#n217">217</a></p>
<p id="n218" class="pln"><a href="#n218">218</a></p>
<p id="n219" class="stm run hide_run"><a href="#n219">219</a></p>
<p id="n220" class="stm run hide_run"><a href="#n220">220</a></p>
<p id="n221" class="stm run hide_run"><a href="#n221">221</a></p>
<p id="n222" class="stm run hide_run"><a href="#n222">222</a></p>
<p id="n223" class="pln"><a href="#n223">223</a></p>
<p id="n224" class="stm run hide_run"><a href="#n224">224</a></p>
<p id="n225" class="stm run hide_run"><a href="#n225">225</a></p>
<p id="n226" class="pln"><a href="#n226">226</a></p>
<p id="n227" class="pln"><a href="#n227">227</a></p>
<p id="n228" class="stm run hide_run"><a href="#n228">228</a></p>
<p id="n229" class="pln"><a href="#n229">229</a></p>
<p id="n230" class="pln"><a href="#n230">230</a></p>
<p id="n231" class="pln"><a href="#n231">231</a></p>
<p id="n232" class="pln"><a href="#n232">232</a></p>
<p id="n233" class="pln"><a href="#n233">233</a></p>
<p id="n234" class="pln"><a href="#n234">234</a></p>
<p id="n235" class="pln"><a href="#n235">235</a></p>
<p id="n236" class="pln"><a href="#n236">236</a></p>
<p id="n237" class="pln"><a href="#n237">237</a></p>
<p id="n238" class="pln"><a href="#n238">238</a></p>
<p id="n239" class="pln"><a href="#n239">239</a></p>
<p id="n240" class="pln"><a href="#n240">240</a></p>
<p id="n241" class="pln"><a href="#n241">241</a></p>
<p id="n242" class="pln"><a href="#n242">242</a></p>
<p id="n243" class="pln"><a href="#n243">243</a></p>
<p id="n244" class="pln"><a href="#n244">244</a></p>
<p id="n245" class="pln"><a href="#n245">245</a></p>
<p id="n246" class="pln"><a href="#n246">246</a></p>
<p id="n247" class="pln"><a href="#n247">247</a></p>
<p id="n248" class="pln"><a href="#n248">248</a></p>
<p id="n249" class="pln"><a href="#n249">249</a></p>
<p id="n250" class="pln"><a href="#n250">250</a></p>
<p id="n251" class="pln"><a href="#n251">251</a></p>
<p id="n252" class="pln"><a href="#n252">252</a></p>
<p id="n253" class="pln"><a href="#n253">253</a></p>
<p id="n254" class="pln"><a href="#n254">254</a></p>
<p id="n255" class="pln"><a href="#n255">255</a></p>
<p id="n256" class="pln"><a href="#n256">256</a></p>
<p id="n257" class="pln"><a href="#n257">257</a></p>
<p id="n258" class="pln"><a href="#n258">258</a></p>
<p id="n259" class="pln"><a href="#n259">259</a></p>
<p id="n260" class="pln"><a href="#n260">260</a></p>
<p id="n261" class="pln"><a href="#n261">261</a></p>
<p id="n262" class="stm run hide_run"><a href="#n262">262</a></p>
<p id="n263" class="stm run hide_run"><a href="#n263">263</a></p>
<p id="n264" class="stm run hide_run"><a href="#n264">264</a></p>
<p id="n265" class="stm run hide_run"><a href="#n265">265</a></p>
<p id="n266" class="stm run hide_run"><a href="#n266">266</a></p>
<p id="n267" class="pln"><a href="#n267">267</a></p>
<p id="n268" class="stm run hide_run"><a href="#n268">268</a></p>
<p id="n269" class="stm run hide_run"><a href="#n269">269</a></p>
<p id="n270" class="stm run hide_run"><a href="#n270">270</a></p>
<p id="n271" class="stm run hide_run"><a href="#n271">271</a></p>
<p id="n272" class="pln"><a href="#n272">272</a></p>
<p id="n273" class="stm run hide_run"><a href="#n273">273</a></p>
<p id="n274" class="stm run hide_run"><a href="#n274">274</a></p>
<p id="n275" class="pln"><a href="#n275">275</a></p>
<p id="n276" class="pln"><a href="#n276">276</a></p>
<p id="n277" class="stm run hide_run"><a href="#n277">277</a></p>
<p id="n278" class="pln"><a href="#n278">278</a></p>
<p id="n279" class="pln"><a href="#n279">279</a></p>
<p id="n280" class="pln"><a href="#n280">280</a></p>
<p id="n281" class="pln"><a href="#n281">281</a></p>
<p id="n282" class="pln"><a href="#n282">282</a></p>
<p id="n283" class="pln"><a href="#n283">283</a></p>
<p id="n284" class="pln"><a href="#n284">284</a></p>
<p id="n285" class="pln"><a href="#n285">285</a></p>
<p id="n286" class="pln"><a href="#n286">286</a></p>
<p id="n287" class="pln"><a href="#n287">287</a></p>
<p id="n288" class="pln"><a href="#n288">288</a></p>
<p id="n289" class="pln"><a href="#n289">289</a></p>
<p id="n290" class="pln"><a href="#n290">290</a></p>
<p id="n291" class="pln"><a href="#n291">291</a></p>
<p id="n292" class="pln"><a href="#n292">292</a></p>
<p id="n293" class="pln"><a href="#n293">293</a></p>
<p id="n294" class="stm run hide_run"><a href="#n294">294</a></p>
<p id="n295" class="stm run hide_run"><a href="#n295">295</a></p>
<p id="n296" class="stm run hide_run"><a href="#n296">296</a></p>
<p id="n297" class="stm run hide_run"><a href="#n297">297</a></p>
<p id="n298" class="pln"><a href="#n298">298</a></p>
<p id="n299" class="stm run hide_run"><a href="#n299">299</a></p>
<p id="n300" class="stm run hide_run"><a href="#n300">300</a></p>
<p id="n301" class="pln"><a href="#n301">301</a></p>
<p id="n302" class="stm run hide_run"><a href="#n302">302</a></p>
<p id="n303" class="stm run hide_run"><a href="#n303">303</a></p>
<p id="n304" class="stm run hide_run"><a href="#n304">304</a></p>
<p id="n305" class="stm run hide_run"><a href="#n305">305</a></p>
<p id="n306" class="pln"><a href="#n306">306</a></p>
<p id="n307" class="stm run hide_run"><a href="#n307">307</a></p>
<p id="n308" class="stm run hide_run"><a href="#n308">308</a></p>
<p id="n309" class="pln"><a href="#n309">309</a></p>
<p id="n310" class="pln"><a href="#n310">310</a></p>
<p id="n311" class="stm run hide_run"><a href="#n311">311</a></p>
<p id="n312" class="pln"><a href="#n312">312</a></p>
<p id="n313" class="pln"><a href="#n313">313</a></p>
<p id="n314" class="pln"><a href="#n314">314</a></p>
<p id="n315" class="pln"><a href="#n315">315</a></p>
<p id="n316" class="pln"><a href="#n316">316</a></p>
<p id="n317" class="pln"><a href="#n317">317</a></p>
<p id="n318" class="pln"><a href="#n318">318</a></p>
<p id="n319" class="pln"><a href="#n319">319</a></p>
<p id="n320" class="pln"><a href="#n320">320</a></p>
<p id="n321" class="pln"><a href="#n321">321</a></p>
<p id="n322" class="pln"><a href="#n322">322</a></p>
<p id="n323" class="pln"><a href="#n323">323</a></p>
<p id="n324" class="pln"><a href="#n324">324</a></p>
<p id="n325" class="pln"><a href="#n325">325</a></p>
<p id="n326" class="pln"><a href="#n326">326</a></p>
<p id="n327" class="pln"><a href="#n327">327</a></p>
<p id="n328" class="pln"><a href="#n328">328</a></p>
<p id="n329" class="pln"><a href="#n329">329</a></p>
<p id="n330" class="pln"><a href="#n330">330</a></p>
<p id="n331" class="pln"><a href="#n331">331</a></p>
<p id="n332" class="pln"><a href="#n332">332</a></p>
<p id="n333" class="pln"><a href="#n333">333</a></p>
<p id="n334" class="pln"><a href="#n334">334</a></p>
<p id="n335" class="pln"><a href="#n335">335</a></p>
<p id="n336" class="pln"><a href="#n336">336</a></p>
<p id="n337" class="pln"><a href="#n337">337</a></p>
<p id="n338" class="pln"><a href="#n338">338</a></p>
<p id="n339" class="pln"><a href="#n339">339</a></p>
<p id="n340" class="pln"><a href="#n340">340</a></p>
<p id="n341" class="pln"><a href="#n341">341</a></p>
<p id="n342" class="pln"><a href="#n342">342</a></p>
<p id="n343" class="pln"><a href="#n343">343</a></p>
<p id="n344" class="pln"><a href="#n344">344</a></p>
<p id="n345" class="pln"><a href="#n345">345</a></p>
<p id="n346" class="stm run hide_run"><a href="#n346">346</a></p>
<p id="n347" class="stm run hide_run"><a href="#n347">347</a></p>
<p id="n348" class="stm run hide_run"><a href="#n348">348</a></p>
<p id="n349" class="pln"><a href="#n349">349</a></p>
<p id="n350" class="stm run hide_run"><a href="#n350">350</a></p>
<p id="n351" class="pln"><a href="#n351">351</a></p>
<p id="n352" class="pln"><a href="#n352">352</a></p>
<p id="n353" class="pln"><a href="#n353">353</a></p>
<p id="n354" class="pln"><a href="#n354">354</a></p>
<p id="n355" class="pln"><a href="#n355">355</a></p>
<p id="n356" class="pln"><a href="#n356">356</a></p>
<p id="n357" class="pln"><a href="#n357">357</a></p>
<p id="n358" class="pln"><a href="#n358">358</a></p>
<p id="n359" class="pln"><a href="#n359">359</a></p>
<p id="n360" class="pln"><a href="#n360">360</a></p>
<p id="n361" class="pln"><a href="#n361">361</a></p>
<p id="n362" class="pln"><a href="#n362">362</a></p>
<p id="n363" class="pln"><a href="#n363">363</a></p>
<p id="n364" class="pln"><a href="#n364">364</a></p>
<p id="n365" class="pln"><a href="#n365">365</a></p>
<p id="n366" class="pln"><a href="#n366">366</a></p>
<p id="n367" class="pln"><a href="#n367">367</a></p>
<p id="n368" class="stm run hide_run"><a href="#n368">368</a></p>
<p id="n369" class="stm run hide_run"><a href="#n369">369</a></p>
<p id="n370" class="pln"><a href="#n370">370</a></p>
<p id="n371" class="stm run hide_run"><a href="#n371">371</a></p>
<p id="n372" class="stm run hide_run"><a href="#n372">372</a></p>
<p id="n373" class="stm run hide_run"><a href="#n373">373</a></p>
<p id="n374" class="stm run hide_run"><a href="#n374">374</a></p>
<p id="n375" class="stm run hide_run"><a href="#n375">375</a></p>
<p id="n376" class="pln"><a href="#n376">376</a></p>
<p id="n377" class="stm mis"><a href="#n377">377</a></p>
<p id="n378" class="pln"><a href="#n378">378</a></p>
<p id="n379" class="stm run hide_run"><a href="#n379">379</a></p>
<p id="n380" class="pln"><a href="#n380">380</a></p>
<p id="n381" class="stm run hide_run"><a href="#n381">381</a></p>
<p id="n382" class="stm run hide_run"><a href="#n382">382</a></p>
<p id="n383" class="stm run hide_run"><a href="#n383">383</a></p>
<p id="n384" class="stm mis"><a href="#n384">384</a></p>
<p id="n385" class="stm run hide_run"><a href="#n385">385</a></p>
<p id="n386" class="stm run hide_run"><a href="#n386">386</a></p>
<p id="n387" class="stm mis"><a href="#n387">387</a></p>
<p id="n388" class="pln"><a href="#n388">388</a></p>
<p id="n389" class="stm run hide_run"><a href="#n389">389</a></p>
<p id="n390" class="pln"><a href="#n390">390</a></p>
<p id="n391" class="stm run hide_run"><a href="#n391">391</a></p>
<p id="n392" class="stm run hide_run"><a href="#n392">392</a></p>
<p id="n393" class="pln"><a href="#n393">393</a></p>
<p id="n394" class="stm run hide_run"><a href="#n394">394</a></p>
<p id="n395" class="pln"><a href="#n395">395</a></p>
<p id="n396" class="pln"><a href="#n396">396</a></p>
<p id="n397" class="pln"><a href="#n397">397</a></p>
<p id="n398" class="stm run hide_run"><a href="#n398">398</a></p>
<p id="n399" class="pln"><a href="#n399">399</a></p>
<p id="n400" class="pln"><a href="#n400">400</a></p>
<p id="n401" class="stm run hide_run"><a href="#n401">401</a></p>
<p id="n402" class="stm run hide_run"><a href="#n402">402</a></p>
<p id="n403" class="pln"><a href="#n403">403</a></p>
<p id="n404" class="stm run hide_run"><a href="#n404">404</a></p>
<p id="n405" class="stm run hide_run"><a href="#n405">405</a></p>
<p id="n406" class="stm run hide_run"><a href="#n406">406</a></p>
<p id="n407" class="stm run hide_run"><a href="#n407">407</a></p>
<p id="n408" class="pln"><a href="#n408">408</a></p>
<p id="n409" class="pln"><a href="#n409">409</a></p>
<p id="n410" class="stm run hide_run"><a href="#n410">410</a></p>
<p id="n411" class="pln"><a href="#n411">411</a></p>
<p id="n412" class="pln"><a href="#n412">412</a></p>
<p id="n413" class="pln"><a href="#n413">413</a></p>
<p id="n414" class="pln"><a href="#n414">414</a></p>
<p id="n415" class="pln"><a href="#n415">415</a></p>
<p id="n416" class="pln"><a href="#n416">416</a></p>
<p id="n417" class="pln"><a href="#n417">417</a></p>
<p id="n418" class="pln"><a href="#n418">418</a></p>
<p id="n419" class="pln"><a href="#n419">419</a></p>
<p id="n420" class="pln"><a href="#n420">420</a></p>
<p id="n421" class="pln"><a href="#n421">421</a></p>
<p id="n422" class="pln"><a href="#n422">422</a></p>
<p id="n423" class="pln"><a href="#n423">423</a></p>
<p id="n424" class="pln"><a href="#n424">424</a></p>
<p id="n425" class="pln"><a href="#n425">425</a></p>
<p id="n426" class="pln"><a href="#n426">426</a></p>
<p id="n427" class="pln"><a href="#n427">427</a></p>
<p id="n428" class="pln"><a href="#n428">428</a></p>
<p id="n429" class="pln"><a href="#n429">429</a></p>
<p id="n430" class="pln"><a href="#n430">430</a></p>
<p id="n431" class="pln"><a href="#n431">431</a></p>
<p id="n432" class="pln"><a href="#n432">432</a></p>
<p id="n433" class="pln"><a href="#n433">433</a></p>
<p id="n434" class="pln"><a href="#n434">434</a></p>
<p id="n435" class="pln"><a href="#n435">435</a></p>
<p id="n436" class="pln"><a href="#n436">436</a></p>
<p id="n437" class="pln"><a href="#n437">437</a></p>
<p id="n438" class="pln"><a href="#n438">438</a></p>
<p id="n439" class="pln"><a href="#n439">439</a></p>
<p id="n440" class="stm run hide_run"><a href="#n440">440</a></p>
<p id="n441" class="stm run hide_run"><a href="#n441">441</a></p>
<p id="n442" class="stm run hide_run"><a href="#n442">442</a></p>
<p id="n443" class="stm run hide_run"><a href="#n443">443</a></p>
<p id="n444" class="pln"><a href="#n444">444</a></p>
<p id="n445" class="stm run hide_run"><a href="#n445">445</a></p>
<p id="n446" class="stm run hide_run"><a href="#n446">446</a></p>
<p id="n447" class="stm run hide_run"><a href="#n447">447</a></p>
<p id="n448" class="stm run hide_run"><a href="#n448">448</a></p>
<p id="n449" class="stm run hide_run"><a href="#n449">449</a></p>
<p id="n450" class="stm run hide_run"><a href="#n450">450</a></p>
<p id="n451" class="stm run hide_run"><a href="#n451">451</a></p>
<p id="n452" class="pln"><a href="#n452">452</a></p>
<p id="n453" class="stm run hide_run"><a href="#n453">453</a></p>
<p id="n454" class="stm run hide_run"><a href="#n454">454</a></p>
<p id="n455" class="pln"><a href="#n455">455</a></p>
<p id="n456" class="stm run hide_run"><a href="#n456">456</a></p>
<p id="n457" class="stm run hide_run"><a href="#n457">457</a></p>
<p id="n458" class="stm run hide_run"><a href="#n458">458</a></p>
<p id="n459" class="stm run hide_run"><a href="#n459">459</a></p>
<p id="n460" class="pln"><a href="#n460">460</a></p>
<p id="n461" class="pln"><a href="#n461">461</a></p>
<p id="n462" class="stm run hide_run"><a href="#n462">462</a></p>
<p id="n463" class="pln"><a href="#n463">463</a></p>
<p id="n464" class="pln"><a href="#n464">464</a></p>
<p id="n465" class="pln"><a href="#n465">465</a></p>
<p id="n466" class="pln"><a href="#n466">466</a></p>
<p id="n467" class="pln"><a href="#n467">467</a></p>
<p id="n468" class="pln"><a href="#n468">468</a></p>
<p id="n469" class="pln"><a href="#n469">469</a></p>
<p id="n470" class="pln"><a href="#n470">470</a></p>
<p id="n471" class="pln"><a href="#n471">471</a></p>
<p id="n472" class="pln"><a href="#n472">472</a></p>
<p id="n473" class="pln"><a href="#n473">473</a></p>
<p id="n474" class="pln"><a href="#n474">474</a></p>
<p id="n475" class="pln"><a href="#n475">475</a></p>
<p id="n476" class="pln"><a href="#n476">476</a></p>
<p id="n477" class="pln"><a href="#n477">477</a></p>
<p id="n478" class="pln"><a href="#n478">478</a></p>
<p id="n479" class="pln"><a href="#n479">479</a></p>
<p id="n480" class="pln"><a href="#n480">480</a></p>
<p id="n481" class="pln"><a href="#n481">481</a></p>
<p id="n482" class="pln"><a href="#n482">482</a></p>
<p id="n483" class="pln"><a href="#n483">483</a></p>
<p id="n484" class="pln"><a href="#n484">484</a></p>
<p id="n485" class="pln"><a href="#n485">485</a></p>
<p id="n486" class="pln"><a href="#n486">486</a></p>
<p id="n487" class="pln"><a href="#n487">487</a></p>
<p id="n488" class="pln"><a href="#n488">488</a></p>
<p id="n489" class="pln"><a href="#n489">489</a></p>
<p id="n490" class="pln"><a href="#n490">490</a></p>
<p id="n491" class="pln"><a href="#n491">491</a></p>
<p id="n492" class="stm run hide_run"><a href="#n492">492</a></p>
<p id="n493" class="stm run hide_run"><a href="#n493">493</a></p>
<p id="n494" class="stm run hide_run"><a href="#n494">494</a></p>
<p id="n495" class="stm run hide_run"><a href="#n495">495</a></p>
<p id="n496" class="pln"><a href="#n496">496</a></p>
<p id="n497" class="stm run hide_run"><a href="#n497">497</a></p>
<p id="n498" class="stm run hide_run"><a href="#n498">498</a></p>
<p id="n499" class="stm mis"><a href="#n499">499</a></p>
<p id="n500" class="pln"><a href="#n500">500</a></p>
<p id="n501" class="pln"><a href="#n501">501</a></p>
<p id="n502" class="pln"><a href="#n502">502</a></p>
<p id="n503" class="pln"><a href="#n503">503</a></p>
<p id="n504" class="pln"><a href="#n504">504</a></p>
<p id="n505" class="stm run hide_run"><a href="#n505">505</a></p>
<p id="n506" class="pln"><a href="#n506">506</a></p>
<p id="n507" class="stm run hide_run"><a href="#n507">507</a></p>
<p id="n508" class="stm run hide_run"><a href="#n508">508</a></p>
<p id="n509" class="pln"><a href="#n509">509</a></p>
<p id="n510" class="stm run hide_run"><a href="#n510">510</a></p>
<p id="n511" class="stm run hide_run"><a href="#n511">511</a></p>
<p id="n512" class="pln"><a href="#n512">512</a></p>
<p id="n513" class="stm run hide_run"><a href="#n513">513</a></p>
<p id="n514" class="stm run hide_run"><a href="#n514">514</a></p>
<p id="n515" class="pln"><a href="#n515">515</a></p>
<p id="n516" class="stm run hide_run"><a href="#n516">516</a></p>
<p id="n517" class="pln"><a href="#n517">517</a></p>
<p id="n518" class="stm run hide_run"><a href="#n518">518</a></p>
<p id="n519" class="stm run hide_run"><a href="#n519">519</a></p>
<p id="n520" class="stm run hide_run"><a href="#n520">520</a></p>
<p id="n521" class="stm run hide_run"><a href="#n521">521</a></p>
<p id="n522" class="pln"><a href="#n522">522</a></p>
<p id="n523" class="pln"><a href="#n523">523</a></p>
<p id="n524" class="stm run hide_run"><a href="#n524">524</a></p>
<p id="n525" class="pln"><a href="#n525">525</a></p>
<p id="n526" class="pln"><a href="#n526">526</a></p>
<p id="n527" class="pln"><a href="#n527">527</a></p>
<p id="n528" class="pln"><a href="#n528">528</a></p>
<p id="n529" class="pln"><a href="#n529">529</a></p>
<p id="n530" class="pln"><a href="#n530">530</a></p>
<p id="n531" class="pln"><a href="#n531">531</a></p>
<p id="n532" class="pln"><a href="#n532">532</a></p>
<p id="n533" class="pln"><a href="#n533">533</a></p>
<p id="n534" class="pln"><a href="#n534">534</a></p>
<p id="n535" class="pln"><a href="#n535">535</a></p>
<p id="n536" class="pln"><a href="#n536">536</a></p>
<p id="n537" class="pln"><a href="#n537">537</a></p>
<p id="n538" class="pln"><a href="#n538">538</a></p>
<p id="n539" class="pln"><a href="#n539">539</a></p>
<p id="n540" class="pln"><a href="#n540">540</a></p>
<p id="n541" class="pln"><a href="#n541">541</a></p>
<p id="n542" class="pln"><a href="#n542">542</a></p>
<p id="n543" class="pln"><a href="#n543">543</a></p>
<p id="n544" class="pln"><a href="#n544">544</a></p>
<p id="n545" class="pln"><a href="#n545">545</a></p>
<p id="n546" class="pln"><a href="#n546">546</a></p>
<p id="n547" class="pln"><a href="#n547">547</a></p>
<p id="n548" class="pln"><a href="#n548">548</a></p>
<p id="n549" class="stm run hide_run"><a href="#n549">549</a></p>
<p id="n550" class="stm run hide_run"><a href="#n550">550</a></p>
<p id="n551" class="stm run hide_run"><a href="#n551">551</a></p>
<p id="n552" class="stm run hide_run"><a href="#n552">552</a></p>
<p id="n553" class="pln"><a href="#n553">553</a></p>
<p id="n554" class="stm run hide_run"><a href="#n554">554</a></p>
<p id="n555" class="stm run hide_run"><a href="#n555">555</a></p>
<p id="n556" class="pln"><a href="#n556">556</a></p>
<p id="n557" class="stm run hide_run"><a href="#n557">557</a></p>
<p id="n558" class="stm run hide_run"><a href="#n558">558</a></p>
<p id="n559" class="pln"><a href="#n559">559</a></p>
<p id="n560" class="stm run hide_run"><a href="#n560">560</a></p>
<p id="n561" class="stm run hide_run"><a href="#n561">561</a></p>
<p id="n562" class="stm run hide_run"><a href="#n562">562</a></p>
<p id="n563" class="stm run hide_run"><a href="#n563">563</a></p>
<p id="n564" class="pln"><a href="#n564">564</a></p>
<p id="n565" class="pln"><a href="#n565">565</a></p>
<p id="n566" class="stm run hide_run"><a href="#n566">566</a></p>
<p id="n567" class="pln"><a href="#n567">567</a></p>
<p id="n568" class="pln"><a href="#n568">568</a></p>
<p id="n569" class="pln"><a href="#n569">569</a></p>
<p id="n570" class="pln"><a href="#n570">570</a></p>
<p id="n571" class="pln"><a href="#n571">571</a></p>
<p id="n572" class="pln"><a href="#n572">572</a></p>
<p id="n573" class="pln"><a href="#n573">573</a></p>
<p id="n574" class="pln"><a href="#n574">574</a></p>
<p id="n575" class="pln"><a href="#n575">575</a></p>
<p id="n576" class="pln"><a href="#n576">576</a></p>
<p id="n577" class="pln"><a href="#n577">577</a></p>
<p id="n578" class="pln"><a href="#n578">578</a></p>
<p id="n579" class="pln"><a href="#n579">579</a></p>
<p id="n580" class="pln"><a href="#n580">580</a></p>
<p id="n581" class="pln"><a href="#n581">581</a></p>
<p id="n582" class="pln"><a href="#n582">582</a></p>
<p id="n583" class="pln"><a href="#n583">583</a></p>
<p id="n584" class="pln"><a href="#n584">584</a></p>
<p id="n585" class="pln"><a href="#n585">585</a></p>
<p id="n586" class="pln"><a href="#n586">586</a></p>
<p id="n587" class="pln"><a href="#n587">587</a></p>
<p id="n588" class="pln"><a href="#n588">588</a></p>
<p id="n589" class="pln"><a href="#n589">589</a></p>
<p id="n590" class="pln"><a href="#n590">590</a></p>
<p id="n591" class="pln"><a href="#n591">591</a></p>
<p id="n592" class="pln"><a href="#n592">592</a></p>
<p id="n593" class="pln"><a href="#n593">593</a></p>
<p id="n594" class="pln"><a href="#n594">594</a></p>
<p id="n595" class="pln"><a href="#n595">595</a></p>
<p id="n596" class="pln"><a href="#n596">596</a></p>
<p id="n597" class="pln"><a href="#n597">597</a></p>
<p id="n598" class="pln"><a href="#n598">598</a></p>
<p id="n599" class="pln"><a href="#n599">599</a></p>
<p id="n600" class="pln"><a href="#n600">600</a></p>
<p id="n601" class="pln"><a href="#n601">601</a></p>
<p id="n602" class="pln"><a href="#n602">602</a></p>
<p id="n603" class="pln"><a href="#n603">603</a></p>
<p id="n604" class="pln"><a href="#n604">604</a></p>
<p id="n605" class="pln"><a href="#n605">605</a></p>
<p id="n606" class="pln"><a href="#n606">606</a></p>
<p id="n607" class="pln"><a href="#n607">607</a></p>
<p id="n608" class="pln"><a href="#n608">608</a></p>
<p id="n609" class="pln"><a href="#n609">609</a></p>
<p id="n610" class="pln"><a href="#n610">610</a></p>
<p id="n611" class="pln"><a href="#n611">611</a></p>
<p id="n612" class="pln"><a href="#n612">612</a></p>
<p id="n613" class="pln"><a href="#n613">613</a></p>
<p id="n614" class="pln"><a href="#n614">614</a></p>
<p id="n615" class="pln"><a href="#n615">615</a></p>
<p id="n616" class="pln"><a href="#n616">616</a></p>
<p id="n617" class="pln"><a href="#n617">617</a></p>
<p id="n618" class="pln"><a href="#n618">618</a></p>
<p id="n619" class="pln"><a href="#n619">619</a></p>
<p id="n620" class="pln"><a href="#n620">620</a></p>
<p id="n621" class="pln"><a href="#n621">621</a></p>
<p id="n622" class="pln"><a href="#n622">622</a></p>
<p id="n623" class="pln"><a href="#n623">623</a></p>
<p id="n624" class="pln"><a href="#n624">624</a></p>
<p id="n625" class="pln"><a href="#n625">625</a></p>
<p id="n626" class="pln"><a href="#n626">626</a></p>
<p id="n627" class="pln"><a href="#n627">627</a></p>
<p id="n628" class="pln"><a href="#n628">628</a></p>
<p id="n629" class="pln"><a href="#n629">629</a></p>
<p id="n630" class="pln"><a href="#n630">630</a></p>
<p id="n631" class="pln"><a href="#n631">631</a></p>
<p id="n632" class="pln"><a href="#n632">632</a></p>
<p id="n633" class="pln"><a href="#n633">633</a></p>
<p id="n634" class="pln"><a href="#n634">634</a></p>
<p id="n635" class="pln"><a href="#n635">635</a></p>
<p id="n636" class="pln"><a href="#n636">636</a></p>
<p id="n637" class="pln"><a href="#n637">637</a></p>
<p id="n638" class="pln"><a href="#n638">638</a></p>
<p id="n639" class="pln"><a href="#n639">639</a></p>
<p id="n640" class="pln"><a href="#n640">640</a></p>
<p id="n641" class="pln"><a href="#n641">641</a></p>
<p id="n642" class="pln"><a href="#n642">642</a></p>
<p id="n643" class="pln"><a href="#n643">643</a></p>
<p id="n644" class="pln"><a href="#n644">644</a></p>
<p id="n645" class="pln"><a href="#n645">645</a></p>
<p id="n646" class="stm run hide_run"><a href="#n646">646</a></p>
<p id="n647" class="stm run hide_run"><a href="#n647">647</a></p>
<p id="n648" class="pln"><a href="#n648">648</a></p>
<p id="n649" class="stm run hide_run"><a href="#n649">649</a></p>
<p id="n650" class="stm run hide_run"><a href="#n650">650</a></p>
<p id="n651" class="stm run hide_run"><a href="#n651">651</a></p>
<p id="n652" class="stm run hide_run"><a href="#n652">652</a></p>
<p id="n653" class="stm run hide_run"><a href="#n653">653</a></p>
<p id="n654" class="stm run hide_run"><a href="#n654">654</a></p>
<p id="n655" class="stm run hide_run"><a href="#n655">655</a></p>
<p id="n656" class="pln"><a href="#n656">656</a></p>
<p id="n657" class="stm run hide_run"><a href="#n657">657</a></p>
<p id="n658" class="stm run hide_run"><a href="#n658">658</a></p>
<p id="n659" class="stm run hide_run"><a href="#n659">659</a></p>
<p id="n660" class="stm run hide_run"><a href="#n660">660</a></p>
<p id="n661" class="pln"><a href="#n661">661</a></p>
<p id="n662" class="stm run hide_run"><a href="#n662">662</a></p>
<p id="n663" class="stm mis"><a href="#n663">663</a></p>
<p id="n664" class="pln"><a href="#n664">664</a></p>
<p id="n665" class="stm run hide_run"><a href="#n665">665</a></p>
<p id="n666" class="pln"><a href="#n666">666</a></p>
<p id="n667" class="stm run hide_run"><a href="#n667">667</a></p>
<p id="n668" class="stm run hide_run"><a href="#n668">668</a></p>
<p id="n669" class="pln"><a href="#n669">669</a></p>
<p id="n670" class="stm run hide_run"><a href="#n670">670</a></p>
<p id="n671" class="stm run hide_run"><a href="#n671">671</a></p>
<p id="n672" class="stm run hide_run"><a href="#n672">672</a></p>
<p id="n673" class="pln"><a href="#n673">673</a></p>
<p id="n674" class="stm run hide_run"><a href="#n674">674</a></p>
<p id="n675" class="pln"><a href="#n675">675</a></p>
<p id="n676" class="stm run hide_run"><a href="#n676">676</a></p>
<p id="n677" class="stm run hide_run"><a href="#n677">677</a></p>
<p id="n678" class="stm run hide_run"><a href="#n678">678</a></p>
<p id="n679" class="stm run hide_run"><a href="#n679">679</a></p>
<p id="n680" class="pln"><a href="#n680">680</a></p>
<p id="n681" class="stm run hide_run"><a href="#n681">681</a></p>
<p id="n682" class="pln"><a href="#n682">682</a></p>
<p id="n683" class="stm mis"><a href="#n683">683</a></p>
<p id="n684" class="pln"><a href="#n684">684</a></p>
<p id="n685" class="pln"><a href="#n685">685</a></p>
<p id="n686" class="pln"><a href="#n686">686</a></p>
<p id="n687" class="pln"><a href="#n687">687</a></p>
<p id="n688" class="pln"><a href="#n688">688</a></p>
<p id="n689" class="pln"><a href="#n689">689</a></p>
<p id="n690" class="pln"><a href="#n690">690</a></p>
<p id="n691" class="stm mis"><a href="#n691">691</a></p>
<p id="n692" class="stm run hide_run"><a href="#n692">692</a></p>
<p id="n693" class="stm run hide_run"><a href="#n693">693</a></p>
<p id="n694" class="stm run hide_run"><a href="#n694">694</a></p>
<p id="n695" class="pln"><a href="#n695">695</a></p>
<p id="n696" class="stm run hide_run"><a href="#n696">696</a></p>
<p id="n697" class="stm run hide_run"><a href="#n697">697</a></p>
<p id="n698" class="pln"><a href="#n698">698</a></p>
<p id="n699" class="stm run hide_run"><a href="#n699">699</a></p>
<p id="n700" class="stm run hide_run"><a href="#n700">700</a></p>
<p id="n701" class="stm mis"><a href="#n701">701</a></p>
<p id="n702" class="pln"><a href="#n702">702</a></p>
<p id="n703" class="stm run hide_run"><a href="#n703">703</a></p>
<p id="n704" class="stm run hide_run"><a href="#n704">704</a></p>
<p id="n705" class="stm run hide_run"><a href="#n705">705</a></p>
<p id="n706" class="stm run hide_run"><a href="#n706">706</a></p>
<p id="n707" class="pln"><a href="#n707">707</a></p>
<p id="n708" class="stm run hide_run"><a href="#n708">708</a></p>
<p id="n709" class="stm run hide_run"><a href="#n709">709</a></p>
<p id="n710" class="stm run hide_run"><a href="#n710">710</a></p>
<p id="n711" class="stm mis"><a href="#n711">711</a></p>
<p id="n712" class="stm run hide_run"><a href="#n712">712</a></p>
<p id="n713" class="stm run hide_run"><a href="#n713">713</a></p>
<p id="n714" class="pln"><a href="#n714">714</a></p>
<p id="n715" class="stm run hide_run"><a href="#n715">715</a></p>
<p id="n716" class="stm run hide_run"><a href="#n716">716</a></p>
<p id="n717" class="pln"><a href="#n717">717</a></p>
<p id="n718" class="stm run hide_run"><a href="#n718">718</a></p>
<p id="n719" class="stm run hide_run"><a href="#n719">719</a></p>
<p id="n720" class="stm run hide_run"><a href="#n720">720</a></p>
<p id="n721" class="stm run hide_run"><a href="#n721">721</a></p>
<p id="n722" class="pln"><a href="#n722">722</a></p>
<p id="n723" class="stm run hide_run"><a href="#n723">723</a></p>
<p id="n724" class="stm run hide_run"><a href="#n724">724</a></p>
<p id="n725" class="stm run hide_run"><a href="#n725">725</a></p>
<p id="n726" class="stm run hide_run"><a href="#n726">726</a></p>
<p id="n727" class="pln"><a href="#n727">727</a></p>
<p id="n728" class="stm mis"><a href="#n728">728</a></p>
<p id="n729" class="stm mis"><a href="#n729">729</a></p>
<p id="n730" class="pln"><a href="#n730">730</a></p>
<p id="n731" class="stm run hide_run"><a href="#n731">731</a></p>
<p id="n732" class="stm run hide_run"><a href="#n732">732</a></p>
<p id="n733" class="stm run hide_run"><a href="#n733">733</a></p>
<p id="n734" class="stm run hide_run"><a href="#n734">734</a></p>
<p id="n735" class="stm mis"><a href="#n735">735</a></p>
<p id="n736" class="stm mis"><a href="#n736">736</a></p>
<p id="n737" class="pln"><a href="#n737">737</a></p>
<p id="n738" class="stm run hide_run"><a href="#n738">738</a></p>
<p id="n739" class="stm run hide_run"><a href="#n739">739</a></p>
<p id="n740" class="pln"><a href="#n740">740</a></p>
<p id="n741" class="stm run hide_run"><a href="#n741">741</a></p>
<p id="n742" class="pln"><a href="#n742">742</a></p>
<p id="n743" class="pln"><a href="#n743">743</a></p>
<p id="n744" class="pln"><a href="#n744">744</a></p>
<p id="n745" class="pln"><a href="#n745">745</a></p>
<p id="n746" class="stm run hide_run"><a href="#n746">746</a></p>
<p id="n747" class="stm run hide_run"><a href="#n747">747</a></p>
<p id="n748" class="pln"><a href="#n748">748</a></p>
<p id="n749" class="stm run hide_run"><a href="#n749">749</a></p>
<p id="n750" class="stm run hide_run"><a href="#n750">750</a></p>
<p id="n751" class="stm run hide_run"><a href="#n751">751</a></p>
<p id="n752" class="stm run hide_run"><a href="#n752">752</a></p>
<p id="n753" class="stm run hide_run"><a href="#n753">753</a></p>
<p id="n754" class="stm run hide_run"><a href="#n754">754</a></p>
<p id="n755" class="stm run hide_run"><a href="#n755">755</a></p>
<p id="n756" class="stm run hide_run"><a href="#n756">756</a></p>
<p id="n757" class="pln"><a href="#n757">757</a></p>
<p id="n758" class="stm mis"><a href="#n758">758</a></p>
<p id="n759" class="pln"><a href="#n759">759</a></p>
<p id="n760" class="pln"><a href="#n760">760</a></p>
<p id="n761" class="pln"><a href="#n761">761</a></p>
<p id="n762" class="stm run hide_run"><a href="#n762">762</a></p>
<p id="n763" class="pln"><a href="#n763">763</a></p>
<p id="n764" class="stm run hide_run"><a href="#n764">764</a></p>
<p id="n765" class="pln"><a href="#n765">765</a></p>
<p id="n766" class="stm mis"><a href="#n766">766</a></p>
<p id="n767" class="pln"><a href="#n767">767</a></p>
<p id="n768" class="stm run hide_run"><a href="#n768">768</a></p>
<p id="n769" class="stm run hide_run"><a href="#n769">769</a></p>
<p id="n770" class="pln"><a href="#n770">770</a></p>
<p id="n771" class="stm mis"><a href="#n771">771</a></p>
<p id="n772" class="pln"><a href="#n772">772</a></p>
<p id="n773" class="pln"><a href="#n773">773</a></p>
<p id="n774" class="pln"><a href="#n774">774</a></p>
<p id="n775" class="stm run hide_run"><a href="#n775">775</a></p>
<p id="n776" class="pln"><a href="#n776">776</a></p>
<p id="n777" class="stm run hide_run"><a href="#n777">777</a></p>
<p id="n778" class="pln"><a href="#n778">778</a></p>
<p id="n779" class="stm run hide_run"><a href="#n779">779</a></p>
<p id="n780" class="pln"><a href="#n780">780</a></p>
<p id="n781" class="pln"><a href="#n781">781</a></p>
<p id="n782" class="pln"><a href="#n782">782</a></p>
<p id="n783" class="stm run hide_run"><a href="#n783">783</a></p>
<p id="n784" class="stm run hide_run"><a href="#n784">784</a></p>
<p id="n785" class="stm run hide_run"><a href="#n785">785</a></p>
<p id="n786" class="stm mis"><a href="#n786">786</a></p>
<p id="n787" class="stm mis"><a href="#n787">787</a></p>
<p id="n788" class="pln"><a href="#n788">788</a></p>
<p id="n789" class="stm mis"><a href="#n789">789</a></p>
<p id="n790" class="pln"><a href="#n790">790</a></p>
<p id="n791" class="stm run hide_run"><a href="#n791">791</a></p>
<p id="n792" class="stm run hide_run"><a href="#n792">792</a></p>
<p id="n793" class="stm run hide_run"><a href="#n793">793</a></p>
<p id="n794" class="pln"><a href="#n794">794</a></p>
<p id="n795" class="pln"><a href="#n795">795</a></p>
<p id="n796" class="stm run hide_run"><a href="#n796">796</a></p>
<p id="n797" class="pln"><a href="#n797">797</a></p>
<p id="n798" class="pln"><a href="#n798">798</a></p>
<p id="n799" class="pln"><a href="#n799">799</a></p>
<p id="n800" class="pln"><a href="#n800">800</a></p>
<p id="n801" class="pln"><a href="#n801">801</a></p>
<p id="n802" class="pln"><a href="#n802">802</a></p>
<p id="n803" class="pln"><a href="#n803">803</a></p>
<p id="n804" class="pln"><a href="#n804">804</a></p>
<p id="n805" class="pln"><a href="#n805">805</a></p>
<p id="n806" class="pln"><a href="#n806">806</a></p>
<p id="n807" class="pln"><a href="#n807">807</a></p>
<p id="n808" class="pln"><a href="#n808">808</a></p>
<p id="n809" class="pln"><a href="#n809">809</a></p>
<p id="n810" class="pln"><a href="#n810">810</a></p>
<p id="n811" class="pln"><a href="#n811">811</a></p>
<p id="n812" class="pln"><a href="#n812">812</a></p>
<p id="n813" class="pln"><a href="#n813">813</a></p>
<p id="n814" class="pln"><a href="#n814">814</a></p>
<p id="n815" class="pln"><a href="#n815">815</a></p>
<p id="n816" class="pln"><a href="#n816">816</a></p>
<p id="n817" class="pln"><a href="#n817">817</a></p>
<p id="n818" class="pln"><a href="#n818">818</a></p>
<p id="n819" class="pln"><a href="#n819">819</a></p>
<p id="n820" class="pln"><a href="#n820">820</a></p>
<p id="n821" class="pln"><a href="#n821">821</a></p>
<p id="n822" class="pln"><a href="#n822">822</a></p>
<p id="n823" class="pln"><a href="#n823">823</a></p>
<p id="n824" class="pln"><a href="#n824">824</a></p>
<p id="n825" class="pln"><a href="#n825">825</a></p>
<p id="n826" class="pln"><a href="#n826">826</a></p>
<p id="n827" class="pln"><a href="#n827">827</a></p>
<p id="n828" class="pln"><a href="#n828">828</a></p>
<p id="n829" class="pln"><a href="#n829">829</a></p>
<p id="n830" class="pln"><a href="#n830">830</a></p>
<p id="n831" class="pln"><a href="#n831">831</a></p>
<p id="n832" class="pln"><a href="#n832">832</a></p>
<p id="n833" class="pln"><a href="#n833">833</a></p>
<p id="n834" class="pln"><a href="#n834">834</a></p>
<p id="n835" class="pln"><a href="#n835">835</a></p>
<p id="n836" class="pln"><a href="#n836">836</a></p>
<p id="n837" class="pln"><a href="#n837">837</a></p>
<p id="n838" class="pln"><a href="#n838">838</a></p>
<p id="n839" class="pln"><a href="#n839">839</a></p>
<p id="n840" class="pln"><a href="#n840">840</a></p>
<p id="n841" class="pln"><a href="#n841">841</a></p>
<p id="n842" class="pln"><a href="#n842">842</a></p>
<p id="n843" class="pln"><a href="#n843">843</a></p>
<p id="n844" class="pln"><a href="#n844">844</a></p>
<p id="n845" class="pln"><a href="#n845">845</a></p>
<p id="n846" class="pln"><a href="#n846">846</a></p>
<p id="n847" class="pln"><a href="#n847">847</a></p>
<p id="n848" class="pln"><a href="#n848">848</a></p>
<p id="n849" class="pln"><a href="#n849">849</a></p>
<p id="n850" class="pln"><a href="#n850">850</a></p>
<p id="n851" class="pln"><a href="#n851">851</a></p>
<p id="n852" class="pln"><a href="#n852">852</a></p>
<p id="n853" class="pln"><a href="#n853">853</a></p>
<p id="n854" class="pln"><a href="#n854">854</a></p>
<p id="n855" class="pln"><a href="#n855">855</a></p>
<p id="n856" class="pln"><a href="#n856">856</a></p>
<p id="n857" class="pln"><a href="#n857">857</a></p>
<p id="n858" class="pln"><a href="#n858">858</a></p>
<p id="n859" class="stm run hide_run"><a href="#n859">859</a></p>
<p id="n860" class="stm run hide_run"><a href="#n860">860</a></p>
<p id="n861" class="pln"><a href="#n861">861</a></p>
<p id="n862" class="pln"><a href="#n862">862</a></p>
<p id="n863" class="pln"><a href="#n863">863</a></p>
<p id="n864" class="pln"><a href="#n864">864</a></p>
<p id="n865" class="pln"><a href="#n865">865</a></p>
<p id="n866" class="pln"><a href="#n866">866</a></p>
<p id="n867" class="pln"><a href="#n867">867</a></p>
<p id="n868" class="pln"><a href="#n868">868</a></p>
<p id="n869" class="pln"><a href="#n869">869</a></p>
<p id="n870" class="pln"><a href="#n870">870</a></p>
<p id="n871" class="stm run hide_run"><a href="#n871">871</a></p>
<p id="n872" class="stm run hide_run"><a href="#n872">872</a></p>
<p id="n873" class="stm run hide_run"><a href="#n873">873</a></p>
<p id="n874" class="stm run hide_run"><a href="#n874">874</a></p>
<p id="n875" class="stm run hide_run"><a href="#n875">875</a></p>
<p id="n876" class="stm run hide_run"><a href="#n876">876</a></p>
<p id="n877" class="stm run hide_run"><a href="#n877">877</a></p>
<p id="n878" class="stm run hide_run"><a href="#n878">878</a></p>
<p id="n879" class="stm run hide_run"><a href="#n879">879</a></p>
<p id="n880" class="stm run hide_run"><a href="#n880">880</a></p>
<p id="n881" class="stm run hide_run"><a href="#n881">881</a></p>
<p id="n882" class="stm run hide_run"><a href="#n882">882</a></p>
<p id="n883" class="stm run hide_run"><a href="#n883">883</a></p>
<p id="n884" class="stm run hide_run"><a href="#n884">884</a></p>
<p id="n885" class="stm run hide_run"><a href="#n885">885</a></p>
<p id="n886" class="pln"><a href="#n886">886</a></p>
<p id="n887" class="stm run hide_run"><a href="#n887">887</a></p>
<p id="n888" class="stm run hide_run"><a href="#n888">888</a></p>
<p id="n889" class="stm run hide_run"><a href="#n889">889</a></p>
<p id="n890" class="pln"><a href="#n890">890</a></p>
<p id="n891" class="stm run hide_run"><a href="#n891">891</a></p>
<p id="n892" class="pln"><a href="#n892">892</a></p>
<p id="n893" class="pln"><a href="#n893">893</a></p>
<p id="n894" class="pln"><a href="#n894">894</a></p>
<p id="n895" class="pln"><a href="#n895">895</a></p>
<p id="n896" class="stm run hide_run"><a href="#n896">896</a></p>
<p id="n897" class="stm run hide_run"><a href="#n897">897</a></p>
<p id="n898" class="pln"><a href="#n898">898</a></p>
<p id="n899" class="pln"><a href="#n899">899</a></p>
<p id="n900" class="pln"><a href="#n900">900</a></p>
<p id="n901" class="pln"><a href="#n901">901</a></p>
<p id="n902" class="pln"><a href="#n902">902</a></p>
<p id="n903" class="stm run hide_run"><a href="#n903">903</a></p>
<p id="n904" class="stm run hide_run"><a href="#n904">904</a></p>
<p id="n905" class="stm run hide_run"><a href="#n905">905</a></p>
<p id="n906" class="pln"><a href="#n906">906</a></p>
<p id="n907" class="stm run hide_run"><a href="#n907">907</a></p>
<p id="n908" class="stm run hide_run"><a href="#n908">908</a></p>
<p id="n909" class="stm run hide_run"><a href="#n909">909</a></p>
<p id="n910" class="stm run hide_run"><a href="#n910">910</a></p>
<p id="n911" class="stm run hide_run"><a href="#n911">911</a></p>
<p id="n912" class="stm run hide_run"><a href="#n912">912</a></p>
<p id="n913" class="stm run hide_run"><a href="#n913">913</a></p>
<p id="n914" class="pln"><a href="#n914">914</a></p>
<p id="n915" class="stm run hide_run"><a href="#n915">915</a></p>
<p id="n916" class="stm run hide_run"><a href="#n916">916</a></p>
<p id="n917" class="stm run hide_run"><a href="#n917">917</a></p>
<p id="n918" class="stm run hide_run"><a href="#n918">918</a></p>
<p id="n919" class="stm run hide_run"><a href="#n919">919</a></p>
<p id="n920" class="stm run hide_run"><a href="#n920">920</a></p>
<p id="n921" class="pln"><a href="#n921">921</a></p>
<p id="n922" class="stm run hide_run"><a href="#n922">922</a></p>
<p id="n923" class="stm run hide_run"><a href="#n923">923</a></p>
<p id="n924" class="pln"><a href="#n924">924</a></p>
<p id="n925" class="pln"><a href="#n925">925</a></p>
<p id="n926" class="pln"><a href="#n926">926</a></p>
<p id="n927" class="pln"><a href="#n927">927</a></p>
<p id="n928" class="pln"><a href="#n928">928</a></p>
<p id="n929" class="pln"><a href="#n929">929</a></p>
<p id="n930" class="pln"><a href="#n930">930</a></p>
<p id="n931" class="pln"><a href="#n931">931</a></p>
<p id="n932" class="pln"><a href="#n932">932</a></p>
<p id="n933" class="pln"><a href="#n933">933</a></p>
<p id="n934" class="pln"><a href="#n934">934</a></p>
<p id="n935" class="pln"><a href="#n935">935</a></p>
<p id="n936" class="stm run hide_run"><a href="#n936">936</a></p>
<p id="n937" class="stm run hide_run"><a href="#n937">937</a></p>
<p id="n938" class="pln"><a href="#n938">938</a></p>
<p id="n939" class="pln"><a href="#n939">939</a></p>
<p id="n940" class="stm run hide_run"><a href="#n940">940</a></p>
<p id="n941" class="pln"><a href="#n941">941</a></p>
<p id="n942" class="pln"><a href="#n942">942</a></p>
<p id="n943" class="pln"><a href="#n943">943</a></p>
<p id="n944" class="pln"><a href="#n944">944</a></p>
<p id="n945" class="pln"><a href="#n945">945</a></p>
<p id="n946" class="pln"><a href="#n946">946</a></p>
<p id="n947" class="pln"><a href="#n947">947</a></p>
<p id="n948" class="pln"><a href="#n948">948</a></p>
<p id="n949" class="pln"><a href="#n949">949</a></p>
<p id="n950" class="pln"><a href="#n950">950</a></p>
<p id="n951" class="pln"><a href="#n951">951</a></p>
<p id="n952" class="pln"><a href="#n952">952</a></p>
<p id="n953" class="pln"><a href="#n953">953</a></p>
<p id="n954" class="pln"><a href="#n954">954</a></p>
<p id="n955" class="pln"><a href="#n955">955</a></p>
<p id="n956" class="stm run hide_run"><a href="#n956">956</a></p>
<p id="n957" class="stm run hide_run"><a href="#n957">957</a></p>
<p id="n958" class="stm run hide_run"><a href="#n958">958</a></p>
<p id="n959" class="stm run hide_run"><a href="#n959">959</a></p>
<p id="n960" class="stm run hide_run"><a href="#n960">960</a></p>
<p id="n961" class="stm run hide_run"><a href="#n961">961</a></p>
<p id="n962" class="pln"><a href="#n962">962</a></p>
<p id="n963" class="stm run hide_run"><a href="#n963">963</a></p>
<p id="n964" class="stm run hide_run"><a href="#n964">964</a></p>
<p id="n965" class="pln"><a href="#n965">965</a></p>
<p id="n966" class="stm run hide_run"><a href="#n966">966</a></p>
<p id="n967" class="stm run hide_run"><a href="#n967">967</a></p>
<p id="n968" class="pln"><a href="#n968">968</a></p>
<p id="n969" class="stm run hide_run"><a href="#n969">969</a></p>
<p id="n970" class="stm run hide_run"><a href="#n970">970</a></p>

            </td>
            <td class="text">
<p id="t1" class="pln"><span class="com"># -*- coding: utf-8 -*-</span><span class="strut">&nbsp;</span></p>
<p id="t2" class="stm run hide_run"><span class="str">"""Core Keras layers.</span><span class="strut">&nbsp;</span></p>
<p id="t3" class="pln"><span class="str">"""</span><span class="strut">&nbsp;</span></p>
<p id="t4" class="stm run hide_run"><span class="key">from</span> <span class="nam">__future__</span> <span class="key">import</span> <span class="nam">absolute_import</span><span class="strut">&nbsp;</span></p>
<p id="t5" class="stm run hide_run"><span class="key">from</span> <span class="nam">__future__</span> <span class="key">import</span> <span class="nam">division</span><span class="strut">&nbsp;</span></p>
<p id="t6" class="stm run hide_run"><span class="key">from</span> <span class="nam">__future__</span> <span class="key">import</span> <span class="nam">print_function</span><span class="strut">&nbsp;</span></p>
<p id="t7" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t8" class="stm run hide_run"><span class="key">import</span> <span class="nam">numpy</span> <span class="key">as</span> <span class="nam">np</span><span class="strut">&nbsp;</span></p>
<p id="t9" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t10" class="stm run hide_run"><span class="key">import</span> <span class="nam">copy</span><span class="strut">&nbsp;</span></p>
<p id="t11" class="stm run hide_run"><span class="key">import</span> <span class="nam">types</span> <span class="key">as</span> <span class="nam">python_types</span><span class="strut">&nbsp;</span></p>
<p id="t12" class="stm run hide_run"><span class="key">import</span> <span class="nam">warnings</span><span class="strut">&nbsp;</span></p>
<p id="t13" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t14" class="stm run hide_run"><span class="key">from</span> <span class="op">.</span><span class="op">.</span> <span class="key">import</span> <span class="nam">backend</span> <span class="key">as</span> <span class="nam">K</span><span class="strut">&nbsp;</span></p>
<p id="t15" class="stm run hide_run"><span class="key">from</span> <span class="op">.</span><span class="op">.</span> <span class="key">import</span> <span class="nam">activations</span><span class="strut">&nbsp;</span></p>
<p id="t16" class="stm run hide_run"><span class="key">from</span> <span class="op">.</span><span class="op">.</span> <span class="key">import</span> <span class="nam">initializers</span><span class="strut">&nbsp;</span></p>
<p id="t17" class="stm run hide_run"><span class="key">from</span> <span class="op">.</span><span class="op">.</span> <span class="key">import</span> <span class="nam">regularizers</span><span class="strut">&nbsp;</span></p>
<p id="t18" class="stm run hide_run"><span class="key">from</span> <span class="op">.</span><span class="op">.</span> <span class="key">import</span> <span class="nam">constraints</span><span class="strut">&nbsp;</span></p>
<p id="t19" class="stm run hide_run"><span class="key">from</span> <span class="op">.</span><span class="op">.</span><span class="nam">engine</span><span class="op">.</span><span class="nam">base_layer</span> <span class="key">import</span> <span class="nam">InputSpec</span><span class="strut">&nbsp;</span></p>
<p id="t20" class="stm run hide_run"><span class="key">from</span> <span class="op">.</span><span class="op">.</span><span class="nam">engine</span><span class="op">.</span><span class="nam">base_layer</span> <span class="key">import</span> <span class="nam">Layer</span><span class="strut">&nbsp;</span></p>
<p id="t21" class="stm run hide_run"><span class="key">from</span> <span class="op">.</span><span class="op">.</span><span class="nam">utils</span><span class="op">.</span><span class="nam">generic_utils</span> <span class="key">import</span> <span class="nam">func_dump</span><span class="strut">&nbsp;</span></p>
<p id="t22" class="stm run hide_run"><span class="key">from</span> <span class="op">.</span><span class="op">.</span><span class="nam">utils</span><span class="op">.</span><span class="nam">generic_utils</span> <span class="key">import</span> <span class="nam">func_load</span><span class="strut">&nbsp;</span></p>
<p id="t23" class="stm run hide_run"><span class="key">from</span> <span class="op">.</span><span class="op">.</span><span class="nam">utils</span><span class="op">.</span><span class="nam">generic_utils</span> <span class="key">import</span> <span class="nam">deserialize_keras_object</span><span class="strut">&nbsp;</span></p>
<p id="t24" class="stm run hide_run"><span class="key">from</span> <span class="op">.</span><span class="op">.</span><span class="nam">utils</span><span class="op">.</span><span class="nam">generic_utils</span> <span class="key">import</span> <span class="nam">has_arg</span><span class="strut">&nbsp;</span></p>
<p id="t25" class="stm run hide_run"><span class="key">from</span> <span class="op">.</span><span class="op">.</span><span class="nam">legacy</span> <span class="key">import</span> <span class="nam">interfaces</span><span class="strut">&nbsp;</span></p>
<p id="t26" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t27" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t28" class="stm run hide_run"><span class="key">class</span> <span class="nam">Masking</span><span class="op">(</span><span class="nam">Layer</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t29" class="pln">    <span class="str">"""Masks a sequence by using a mask value to skip timesteps.</span><span class="strut">&nbsp;</span></p>
<p id="t30" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t31" class="pln"><span class="str">    If all features for a given sample timestep are equal to `mask_value`,</span><span class="strut">&nbsp;</span></p>
<p id="t32" class="pln"><span class="str">    then the sample timestep will be masked (skipped) in all downstream layers</span><span class="strut">&nbsp;</span></p>
<p id="t33" class="pln"><span class="str">    (as long as they support masking).</span><span class="strut">&nbsp;</span></p>
<p id="t34" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t35" class="pln"><span class="str">    If any downstream layer does not support masking yet receives such</span><span class="strut">&nbsp;</span></p>
<p id="t36" class="pln"><span class="str">    an input mask, an exception will be raised.</span><span class="strut">&nbsp;</span></p>
<p id="t37" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t38" class="pln"><span class="str">    # Example</span><span class="strut">&nbsp;</span></p>
<p id="t39" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t40" class="pln"><span class="str">    Consider a Numpy data array `x` of shape `(samples, timesteps, features)`,</span><span class="strut">&nbsp;</span></p>
<p id="t41" class="pln"><span class="str">    to be fed to an LSTM layer.</span><span class="strut">&nbsp;</span></p>
<p id="t42" class="pln"><span class="str">    You want to mask sample #0 at timestep #3, and sample #2 at timestep #5,</span><span class="strut">&nbsp;</span></p>
<p id="t43" class="pln"><span class="str">    because you lack features for these sample timesteps. You can do:</span><span class="strut">&nbsp;</span></p>
<p id="t44" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t45" class="pln"><span class="str">        - set `x[0, 3, :] = 0.` and `x[2, 5, :] = 0.`</span><span class="strut">&nbsp;</span></p>
<p id="t46" class="pln"><span class="str">        - insert a `Masking` layer with `mask_value=0.` before the LSTM layer:</span><span class="strut">&nbsp;</span></p>
<p id="t47" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t48" class="pln"><span class="str">    ```python</span><span class="strut">&nbsp;</span></p>
<p id="t49" class="pln"><span class="str">        model = Sequential()</span><span class="strut">&nbsp;</span></p>
<p id="t50" class="pln"><span class="str">        model.add(Masking(mask_value=0., input_shape=(timesteps, features)))</span><span class="strut">&nbsp;</span></p>
<p id="t51" class="pln"><span class="str">        model.add(LSTM(32))</span><span class="strut">&nbsp;</span></p>
<p id="t52" class="pln"><span class="str">    ```</span><span class="strut">&nbsp;</span></p>
<p id="t53" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t54" class="pln"><span class="str">    # Arguments</span><span class="strut">&nbsp;</span></p>
<p id="t55" class="pln"><span class="str">        mask_value: Either None or mask value to skip</span><span class="strut">&nbsp;</span></p>
<p id="t56" class="pln"><span class="str">    """</span><span class="strut">&nbsp;</span></p>
<p id="t57" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t58" class="stm run hide_run">    <span class="key">def</span> <span class="nam">__init__</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">mask_value</span><span class="op">=</span><span class="num">0.</span><span class="op">,</span> <span class="op">**</span><span class="nam">kwargs</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t59" class="stm run hide_run">        <span class="nam">super</span><span class="op">(</span><span class="nam">Masking</span><span class="op">,</span> <span class="nam">self</span><span class="op">)</span><span class="op">.</span><span class="nam">__init__</span><span class="op">(</span><span class="op">**</span><span class="nam">kwargs</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t60" class="stm run hide_run">        <span class="nam">self</span><span class="op">.</span><span class="nam">supports_masking</span> <span class="op">=</span> <span class="key">True</span><span class="strut">&nbsp;</span></p>
<p id="t61" class="stm run hide_run">        <span class="nam">self</span><span class="op">.</span><span class="nam">mask_value</span> <span class="op">=</span> <span class="nam">mask_value</span><span class="strut">&nbsp;</span></p>
<p id="t62" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t63" class="stm run hide_run">    <span class="key">def</span> <span class="nam">compute_mask</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">inputs</span><span class="op">,</span> <span class="nam">mask</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t64" class="stm run hide_run">        <span class="nam">output_mask</span> <span class="op">=</span> <span class="nam">K</span><span class="op">.</span><span class="nam">any</span><span class="op">(</span><span class="nam">K</span><span class="op">.</span><span class="nam">not_equal</span><span class="op">(</span><span class="nam">inputs</span><span class="op">,</span> <span class="nam">self</span><span class="op">.</span><span class="nam">mask_value</span><span class="op">)</span><span class="op">,</span> <span class="nam">axis</span><span class="op">=</span><span class="op">-</span><span class="num">1</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t65" class="stm run hide_run">        <span class="key">return</span> <span class="nam">output_mask</span><span class="strut">&nbsp;</span></p>
<p id="t66" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t67" class="stm run hide_run">    <span class="key">def</span> <span class="nam">call</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">inputs</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t68" class="stm run hide_run">        <span class="nam">boolean_mask</span> <span class="op">=</span> <span class="nam">K</span><span class="op">.</span><span class="nam">any</span><span class="op">(</span><span class="nam">K</span><span class="op">.</span><span class="nam">not_equal</span><span class="op">(</span><span class="nam">inputs</span><span class="op">,</span> <span class="nam">self</span><span class="op">.</span><span class="nam">mask_value</span><span class="op">)</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t69" class="pln">                             <span class="nam">axis</span><span class="op">=</span><span class="op">-</span><span class="num">1</span><span class="op">,</span> <span class="nam">keepdims</span><span class="op">=</span><span class="key">True</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t70" class="stm run hide_run">        <span class="key">return</span> <span class="nam">inputs</span> <span class="op">*</span> <span class="nam">K</span><span class="op">.</span><span class="nam">cast</span><span class="op">(</span><span class="nam">boolean_mask</span><span class="op">,</span> <span class="nam">K</span><span class="op">.</span><span class="nam">dtype</span><span class="op">(</span><span class="nam">inputs</span><span class="op">)</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t71" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t72" class="stm run hide_run">    <span class="key">def</span> <span class="nam">get_config</span><span class="op">(</span><span class="nam">self</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t73" class="stm run hide_run">        <span class="nam">config</span> <span class="op">=</span> <span class="op">{</span><span class="str">'mask_value'</span><span class="op">:</span> <span class="nam">self</span><span class="op">.</span><span class="nam">mask_value</span><span class="op">}</span><span class="strut">&nbsp;</span></p>
<p id="t74" class="stm run hide_run">        <span class="nam">base_config</span> <span class="op">=</span> <span class="nam">super</span><span class="op">(</span><span class="nam">Masking</span><span class="op">,</span> <span class="nam">self</span><span class="op">)</span><span class="op">.</span><span class="nam">get_config</span><span class="op">(</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t75" class="stm run hide_run">        <span class="key">return</span> <span class="nam">dict</span><span class="op">(</span><span class="nam">list</span><span class="op">(</span><span class="nam">base_config</span><span class="op">.</span><span class="nam">items</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> <span class="nam">list</span><span class="op">(</span><span class="nam">config</span><span class="op">.</span><span class="nam">items</span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t76" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t77" class="stm run hide_run">    <span class="key">def</span> <span class="nam">compute_output_shape</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">input_shape</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t78" class="stm run hide_run">        <span class="key">return</span> <span class="nam">input_shape</span><span class="strut">&nbsp;</span></p>
<p id="t79" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t80" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t81" class="stm run hide_run"><span class="key">class</span> <span class="nam">Dropout</span><span class="op">(</span><span class="nam">Layer</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t82" class="pln">    <span class="str">"""Applies Dropout to the input.</span><span class="strut">&nbsp;</span></p>
<p id="t83" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t84" class="pln"><span class="str">    Dropout consists in randomly setting</span><span class="strut">&nbsp;</span></p>
<p id="t85" class="pln"><span class="str">    a fraction `rate` of input units to 0 at each update during training time,</span><span class="strut">&nbsp;</span></p>
<p id="t86" class="pln"><span class="str">    which helps prevent overfitting.</span><span class="strut">&nbsp;</span></p>
<p id="t87" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t88" class="pln"><span class="str">    # Arguments</span><span class="strut">&nbsp;</span></p>
<p id="t89" class="pln"><span class="str">        rate: float between 0 and 1. Fraction of the input units to drop.</span><span class="strut">&nbsp;</span></p>
<p id="t90" class="pln"><span class="str">        noise_shape: 1D integer tensor representing the shape of the</span><span class="strut">&nbsp;</span></p>
<p id="t91" class="pln"><span class="str">            binary dropout mask that will be multiplied with the input.</span><span class="strut">&nbsp;</span></p>
<p id="t92" class="pln"><span class="str">            For instance, if your inputs have shape</span><span class="strut">&nbsp;</span></p>
<p id="t93" class="pln"><span class="str">            `(batch_size, timesteps, features)` and</span><span class="strut">&nbsp;</span></p>
<p id="t94" class="pln"><span class="str">            you want the dropout mask to be the same for all timesteps,</span><span class="strut">&nbsp;</span></p>
<p id="t95" class="pln"><span class="str">            you can use `noise_shape=(batch_size, 1, features)`.</span><span class="strut">&nbsp;</span></p>
<p id="t96" class="pln"><span class="str">        seed: A Python integer to use as random seed.</span><span class="strut">&nbsp;</span></p>
<p id="t97" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t98" class="pln"><span class="str">    # References</span><span class="strut">&nbsp;</span></p>
<p id="t99" class="pln"><span class="str">        - [Dropout: A Simple Way to Prevent Neural Networks from Overfitting](</span><span class="strut">&nbsp;</span></p>
<p id="t100" class="pln"><span class="str">           http://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf)</span><span class="strut">&nbsp;</span></p>
<p id="t101" class="pln"><span class="str">    """</span><span class="strut">&nbsp;</span></p>
<p id="t102" class="stm run hide_run">    <span class="op">@</span><span class="nam">interfaces</span><span class="op">.</span><span class="nam">legacy_dropout_support</span><span class="strut">&nbsp;</span></p>
<p id="t103" class="stm run hide_run">    <span class="key">def</span> <span class="nam">__init__</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">rate</span><span class="op">,</span> <span class="nam">noise_shape</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">seed</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="op">**</span><span class="nam">kwargs</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t104" class="stm run hide_run">        <span class="nam">super</span><span class="op">(</span><span class="nam">Dropout</span><span class="op">,</span> <span class="nam">self</span><span class="op">)</span><span class="op">.</span><span class="nam">__init__</span><span class="op">(</span><span class="op">**</span><span class="nam">kwargs</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t105" class="stm run hide_run">        <span class="nam">self</span><span class="op">.</span><span class="nam">rate</span> <span class="op">=</span> <span class="nam">min</span><span class="op">(</span><span class="num">1.</span><span class="op">,</span> <span class="nam">max</span><span class="op">(</span><span class="num">0.</span><span class="op">,</span> <span class="nam">rate</span><span class="op">)</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t106" class="stm run hide_run">        <span class="nam">self</span><span class="op">.</span><span class="nam">noise_shape</span> <span class="op">=</span> <span class="nam">noise_shape</span><span class="strut">&nbsp;</span></p>
<p id="t107" class="stm run hide_run">        <span class="nam">self</span><span class="op">.</span><span class="nam">seed</span> <span class="op">=</span> <span class="nam">seed</span><span class="strut">&nbsp;</span></p>
<p id="t108" class="stm run hide_run">        <span class="nam">self</span><span class="op">.</span><span class="nam">supports_masking</span> <span class="op">=</span> <span class="key">True</span><span class="strut">&nbsp;</span></p>
<p id="t109" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t110" class="stm run hide_run">    <span class="key">def</span> <span class="nam">_get_noise_shape</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">inputs</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t111" class="stm run hide_run">        <span class="key">if</span> <span class="nam">self</span><span class="op">.</span><span class="nam">noise_shape</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t112" class="stm run hide_run">            <span class="key">return</span> <span class="nam">self</span><span class="op">.</span><span class="nam">noise_shape</span><span class="strut">&nbsp;</span></p>
<p id="t113" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t114" class="stm run hide_run">        <span class="nam">symbolic_shape</span> <span class="op">=</span> <span class="nam">K</span><span class="op">.</span><span class="nam">shape</span><span class="op">(</span><span class="nam">inputs</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t115" class="stm run hide_run">        <span class="nam">noise_shape</span> <span class="op">=</span> <span class="op">[</span><span class="nam">symbolic_shape</span><span class="op">[</span><span class="nam">axis</span><span class="op">]</span> <span class="key">if</span> <span class="nam">shape</span> <span class="key">is</span> <span class="key">None</span> <span class="key">else</span> <span class="nam">shape</span><span class="strut">&nbsp;</span></p>
<p id="t116" class="pln">                       <span class="key">for</span> <span class="nam">axis</span><span class="op">,</span> <span class="nam">shape</span> <span class="key">in</span> <span class="nam">enumerate</span><span class="op">(</span><span class="nam">self</span><span class="op">.</span><span class="nam">noise_shape</span><span class="op">)</span><span class="op">]</span><span class="strut">&nbsp;</span></p>
<p id="t117" class="stm run hide_run">        <span class="key">return</span> <span class="nam">tuple</span><span class="op">(</span><span class="nam">noise_shape</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t118" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t119" class="stm run hide_run">    <span class="key">def</span> <span class="nam">call</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">inputs</span><span class="op">,</span> <span class="nam">training</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t120" class="stm run hide_run">        <span class="key">if</span> <span class="num">0.</span> <span class="op">&lt;</span> <span class="nam">self</span><span class="op">.</span><span class="nam">rate</span> <span class="op">&lt;</span> <span class="num">1.</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t121" class="stm run hide_run">            <span class="nam">noise_shape</span> <span class="op">=</span> <span class="nam">self</span><span class="op">.</span><span class="nam">_get_noise_shape</span><span class="op">(</span><span class="nam">inputs</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t122" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t123" class="stm run hide_run">            <span class="key">def</span> <span class="nam">dropped_inputs</span><span class="op">(</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t124" class="stm run hide_run">                <span class="key">return</span> <span class="nam">K</span><span class="op">.</span><span class="nam">dropout</span><span class="op">(</span><span class="nam">inputs</span><span class="op">,</span> <span class="nam">self</span><span class="op">.</span><span class="nam">rate</span><span class="op">,</span> <span class="nam">noise_shape</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t125" class="pln">                                 <span class="nam">seed</span><span class="op">=</span><span class="nam">self</span><span class="op">.</span><span class="nam">seed</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t126" class="stm run hide_run">            <span class="key">return</span> <span class="nam">K</span><span class="op">.</span><span class="nam">in_train_phase</span><span class="op">(</span><span class="nam">dropped_inputs</span><span class="op">,</span> <span class="nam">inputs</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t127" class="pln">                                    <span class="nam">training</span><span class="op">=</span><span class="nam">training</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t128" class="stm mis">        <span class="key">return</span> <span class="nam">inputs</span><span class="strut">&nbsp;</span></p>
<p id="t129" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t130" class="stm run hide_run">    <span class="key">def</span> <span class="nam">get_config</span><span class="op">(</span><span class="nam">self</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t131" class="stm run hide_run">        <span class="nam">config</span> <span class="op">=</span> <span class="op">{</span><span class="str">'rate'</span><span class="op">:</span> <span class="nam">self</span><span class="op">.</span><span class="nam">rate</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t132" class="pln">                  <span class="str">'noise_shape'</span><span class="op">:</span> <span class="nam">self</span><span class="op">.</span><span class="nam">noise_shape</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t133" class="pln">                  <span class="str">'seed'</span><span class="op">:</span> <span class="nam">self</span><span class="op">.</span><span class="nam">seed</span><span class="op">}</span><span class="strut">&nbsp;</span></p>
<p id="t134" class="stm run hide_run">        <span class="nam">base_config</span> <span class="op">=</span> <span class="nam">super</span><span class="op">(</span><span class="nam">Dropout</span><span class="op">,</span> <span class="nam">self</span><span class="op">)</span><span class="op">.</span><span class="nam">get_config</span><span class="op">(</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t135" class="stm run hide_run">        <span class="key">return</span> <span class="nam">dict</span><span class="op">(</span><span class="nam">list</span><span class="op">(</span><span class="nam">base_config</span><span class="op">.</span><span class="nam">items</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> <span class="nam">list</span><span class="op">(</span><span class="nam">config</span><span class="op">.</span><span class="nam">items</span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t136" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t137" class="stm run hide_run">    <span class="key">def</span> <span class="nam">compute_output_shape</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">input_shape</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t138" class="stm run hide_run">        <span class="key">return</span> <span class="nam">input_shape</span><span class="strut">&nbsp;</span></p>
<p id="t139" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t140" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t141" class="stm run hide_run"><span class="key">class</span> <span class="nam">SpatialDropout1D</span><span class="op">(</span><span class="nam">Dropout</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t142" class="pln">    <span class="str">"""Spatial 1D version of Dropout.</span><span class="strut">&nbsp;</span></p>
<p id="t143" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t144" class="pln"><span class="str">    This version performs the same function as Dropout, however it drops</span><span class="strut">&nbsp;</span></p>
<p id="t145" class="pln"><span class="str">    entire 1D feature maps instead of individual elements. If adjacent frames</span><span class="strut">&nbsp;</span></p>
<p id="t146" class="pln"><span class="str">    within feature maps are strongly correlated (as is normally the case in</span><span class="strut">&nbsp;</span></p>
<p id="t147" class="pln"><span class="str">    early convolution layers) then regular dropout will not regularize the</span><span class="strut">&nbsp;</span></p>
<p id="t148" class="pln"><span class="str">    activations and will otherwise just result in an effective learning rate</span><span class="strut">&nbsp;</span></p>
<p id="t149" class="pln"><span class="str">    decrease. In this case, SpatialDropout1D will help promote independence</span><span class="strut">&nbsp;</span></p>
<p id="t150" class="pln"><span class="str">    between feature maps and should be used instead.</span><span class="strut">&nbsp;</span></p>
<p id="t151" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t152" class="pln"><span class="str">    # Arguments</span><span class="strut">&nbsp;</span></p>
<p id="t153" class="pln"><span class="str">        rate: float between 0 and 1. Fraction of the input units to drop.</span><span class="strut">&nbsp;</span></p>
<p id="t154" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t155" class="pln"><span class="str">    # Input shape</span><span class="strut">&nbsp;</span></p>
<p id="t156" class="pln"><span class="str">        3D tensor with shape:</span><span class="strut">&nbsp;</span></p>
<p id="t157" class="pln"><span class="str">        `(samples, timesteps, channels)`</span><span class="strut">&nbsp;</span></p>
<p id="t158" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t159" class="pln"><span class="str">    # Output shape</span><span class="strut">&nbsp;</span></p>
<p id="t160" class="pln"><span class="str">        Same as input</span><span class="strut">&nbsp;</span></p>
<p id="t161" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t162" class="pln"><span class="str">    # References</span><span class="strut">&nbsp;</span></p>
<p id="t163" class="pln"><span class="str">        - [Efficient Object Localization Using Convolutional Networks](</span><span class="strut">&nbsp;</span></p>
<p id="t164" class="pln"><span class="str">           https://arxiv.org/abs/1411.4280)</span><span class="strut">&nbsp;</span></p>
<p id="t165" class="pln"><span class="str">    """</span><span class="strut">&nbsp;</span></p>
<p id="t166" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t167" class="stm run hide_run">    <span class="op">@</span><span class="nam">interfaces</span><span class="op">.</span><span class="nam">legacy_spatialdropout1d_support</span><span class="strut">&nbsp;</span></p>
<p id="t168" class="pln">    <span class="key">def</span> <span class="nam">__init__</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">rate</span><span class="op">,</span> <span class="op">**</span><span class="nam">kwargs</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t169" class="stm run hide_run">        <span class="nam">super</span><span class="op">(</span><span class="nam">SpatialDropout1D</span><span class="op">,</span> <span class="nam">self</span><span class="op">)</span><span class="op">.</span><span class="nam">__init__</span><span class="op">(</span><span class="nam">rate</span><span class="op">,</span> <span class="op">**</span><span class="nam">kwargs</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t170" class="stm run hide_run">        <span class="nam">self</span><span class="op">.</span><span class="nam">input_spec</span> <span class="op">=</span> <span class="nam">InputSpec</span><span class="op">(</span><span class="nam">ndim</span><span class="op">=</span><span class="num">3</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t171" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t172" class="stm run hide_run">    <span class="key">def</span> <span class="nam">_get_noise_shape</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">inputs</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t173" class="stm run hide_run">        <span class="nam">input_shape</span> <span class="op">=</span> <span class="nam">K</span><span class="op">.</span><span class="nam">shape</span><span class="op">(</span><span class="nam">inputs</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t174" class="stm run hide_run">        <span class="nam">noise_shape</span> <span class="op">=</span> <span class="op">(</span><span class="nam">input_shape</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">,</span> <span class="num">1</span><span class="op">,</span> <span class="nam">input_shape</span><span class="op">[</span><span class="num">2</span><span class="op">]</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t175" class="stm run hide_run">        <span class="key">return</span> <span class="nam">noise_shape</span><span class="strut">&nbsp;</span></p>
<p id="t176" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t177" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t178" class="stm run hide_run"><span class="key">class</span> <span class="nam">SpatialDropout2D</span><span class="op">(</span><span class="nam">Dropout</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t179" class="pln">    <span class="str">"""Spatial 2D version of Dropout.</span><span class="strut">&nbsp;</span></p>
<p id="t180" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t181" class="pln"><span class="str">    This version performs the same function as Dropout, however it drops</span><span class="strut">&nbsp;</span></p>
<p id="t182" class="pln"><span class="str">    entire 2D feature maps instead of individual elements. If adjacent pixels</span><span class="strut">&nbsp;</span></p>
<p id="t183" class="pln"><span class="str">    within feature maps are strongly correlated (as is normally the case in</span><span class="strut">&nbsp;</span></p>
<p id="t184" class="pln"><span class="str">    early convolution layers) then regular dropout will not regularize the</span><span class="strut">&nbsp;</span></p>
<p id="t185" class="pln"><span class="str">    activations and will otherwise just result in an effective learning rate</span><span class="strut">&nbsp;</span></p>
<p id="t186" class="pln"><span class="str">    decrease. In this case, SpatialDropout2D will help promote independence</span><span class="strut">&nbsp;</span></p>
<p id="t187" class="pln"><span class="str">    between feature maps and should be used instead.</span><span class="strut">&nbsp;</span></p>
<p id="t188" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t189" class="pln"><span class="str">    # Arguments</span><span class="strut">&nbsp;</span></p>
<p id="t190" class="pln"><span class="str">        rate: float between 0 and 1. Fraction of the input units to drop.</span><span class="strut">&nbsp;</span></p>
<p id="t191" class="pln"><span class="str">        data_format: 'channels_first' or 'channels_last'.</span><span class="strut">&nbsp;</span></p>
<p id="t192" class="pln"><span class="str">            In 'channels_first' mode, the channels dimension</span><span class="strut">&nbsp;</span></p>
<p id="t193" class="pln"><span class="str">            (the depth) is at index 1,</span><span class="strut">&nbsp;</span></p>
<p id="t194" class="pln"><span class="str">            in 'channels_last' mode is it at index 3.</span><span class="strut">&nbsp;</span></p>
<p id="t195" class="pln"><span class="str">            It defaults to the `image_data_format` value found in your</span><span class="strut">&nbsp;</span></p>
<p id="t196" class="pln"><span class="str">            Keras config file at `~/.keras/keras.json`.</span><span class="strut">&nbsp;</span></p>
<p id="t197" class="pln"><span class="str">            If you never set it, then it will be "channels_last".</span><span class="strut">&nbsp;</span></p>
<p id="t198" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t199" class="pln"><span class="str">    # Input shape</span><span class="strut">&nbsp;</span></p>
<p id="t200" class="pln"><span class="str">        4D tensor with shape:</span><span class="strut">&nbsp;</span></p>
<p id="t201" class="pln"><span class="str">        `(samples, channels, rows, cols)` if data_format='channels_first'</span><span class="strut">&nbsp;</span></p>
<p id="t202" class="pln"><span class="str">        or 4D tensor with shape:</span><span class="strut">&nbsp;</span></p>
<p id="t203" class="pln"><span class="str">        `(samples, rows, cols, channels)` if data_format='channels_last'.</span><span class="strut">&nbsp;</span></p>
<p id="t204" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t205" class="pln"><span class="str">    # Output shape</span><span class="strut">&nbsp;</span></p>
<p id="t206" class="pln"><span class="str">        Same as input</span><span class="strut">&nbsp;</span></p>
<p id="t207" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t208" class="pln"><span class="str">    # References</span><span class="strut">&nbsp;</span></p>
<p id="t209" class="pln"><span class="str">        - [Efficient Object Localization Using Convolutional Networks](</span><span class="strut">&nbsp;</span></p>
<p id="t210" class="pln"><span class="str">           https://arxiv.org/abs/1411.4280)</span><span class="strut">&nbsp;</span></p>
<p id="t211" class="pln"><span class="str">    """</span><span class="strut">&nbsp;</span></p>
<p id="t212" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t213" class="stm run hide_run">    <span class="op">@</span><span class="nam">interfaces</span><span class="op">.</span><span class="nam">legacy_spatialdropoutNd_support</span><span class="strut">&nbsp;</span></p>
<p id="t214" class="stm run hide_run">    <span class="key">def</span> <span class="nam">__init__</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">rate</span><span class="op">,</span> <span class="nam">data_format</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="op">**</span><span class="nam">kwargs</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t215" class="stm run hide_run">        <span class="nam">super</span><span class="op">(</span><span class="nam">SpatialDropout2D</span><span class="op">,</span> <span class="nam">self</span><span class="op">)</span><span class="op">.</span><span class="nam">__init__</span><span class="op">(</span><span class="nam">rate</span><span class="op">,</span> <span class="op">**</span><span class="nam">kwargs</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t216" class="stm run hide_run">        <span class="nam">self</span><span class="op">.</span><span class="nam">data_format</span> <span class="op">=</span> <span class="nam">K</span><span class="op">.</span><span class="nam">normalize_data_format</span><span class="op">(</span><span class="nam">data_format</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t217" class="stm run hide_run">        <span class="nam">self</span><span class="op">.</span><span class="nam">input_spec</span> <span class="op">=</span> <span class="nam">InputSpec</span><span class="op">(</span><span class="nam">ndim</span><span class="op">=</span><span class="num">4</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t218" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t219" class="stm run hide_run">    <span class="key">def</span> <span class="nam">_get_noise_shape</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">inputs</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t220" class="stm run hide_run">        <span class="nam">input_shape</span> <span class="op">=</span> <span class="nam">K</span><span class="op">.</span><span class="nam">shape</span><span class="op">(</span><span class="nam">inputs</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t221" class="stm run hide_run">        <span class="key">if</span> <span class="nam">self</span><span class="op">.</span><span class="nam">data_format</span> <span class="op">==</span> <span class="str">'channels_first'</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t222" class="stm run hide_run">            <span class="nam">noise_shape</span> <span class="op">=</span> <span class="op">(</span><span class="nam">input_shape</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">,</span> <span class="nam">input_shape</span><span class="op">[</span><span class="num">1</span><span class="op">]</span><span class="op">,</span> <span class="num">1</span><span class="op">,</span> <span class="num">1</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t223" class="pln">        <span class="key">else</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t224" class="stm run hide_run">            <span class="nam">noise_shape</span> <span class="op">=</span> <span class="op">(</span><span class="nam">input_shape</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">,</span> <span class="num">1</span><span class="op">,</span> <span class="num">1</span><span class="op">,</span> <span class="nam">input_shape</span><span class="op">[</span><span class="num">3</span><span class="op">]</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t225" class="stm run hide_run">        <span class="key">return</span> <span class="nam">noise_shape</span><span class="strut">&nbsp;</span></p>
<p id="t226" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t227" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t228" class="stm run hide_run"><span class="key">class</span> <span class="nam">SpatialDropout3D</span><span class="op">(</span><span class="nam">Dropout</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t229" class="pln">    <span class="str">"""Spatial 3D version of Dropout.</span><span class="strut">&nbsp;</span></p>
<p id="t230" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t231" class="pln"><span class="str">    This version performs the same function as Dropout, however it drops</span><span class="strut">&nbsp;</span></p>
<p id="t232" class="pln"><span class="str">    entire 3D feature maps instead of individual elements. If adjacent voxels</span><span class="strut">&nbsp;</span></p>
<p id="t233" class="pln"><span class="str">    within feature maps are strongly correlated (as is normally the case in</span><span class="strut">&nbsp;</span></p>
<p id="t234" class="pln"><span class="str">    early convolution layers) then regular dropout will not regularize the</span><span class="strut">&nbsp;</span></p>
<p id="t235" class="pln"><span class="str">    activations and will otherwise just result in an effective learning rate</span><span class="strut">&nbsp;</span></p>
<p id="t236" class="pln"><span class="str">    decrease. In this case, SpatialDropout3D will help promote independence</span><span class="strut">&nbsp;</span></p>
<p id="t237" class="pln"><span class="str">    between feature maps and should be used instead.</span><span class="strut">&nbsp;</span></p>
<p id="t238" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t239" class="pln"><span class="str">    # Arguments</span><span class="strut">&nbsp;</span></p>
<p id="t240" class="pln"><span class="str">        rate: float between 0 and 1. Fraction of the input units to drop.</span><span class="strut">&nbsp;</span></p>
<p id="t241" class="pln"><span class="str">        data_format: 'channels_first' or 'channels_last'.</span><span class="strut">&nbsp;</span></p>
<p id="t242" class="pln"><span class="str">            In 'channels_first' mode, the channels dimension (the depth)</span><span class="strut">&nbsp;</span></p>
<p id="t243" class="pln"><span class="str">            is at index 1, in 'channels_last' mode is it at index 4.</span><span class="strut">&nbsp;</span></p>
<p id="t244" class="pln"><span class="str">            It defaults to the `image_data_format` value found in your</span><span class="strut">&nbsp;</span></p>
<p id="t245" class="pln"><span class="str">            Keras config file at `~/.keras/keras.json`.</span><span class="strut">&nbsp;</span></p>
<p id="t246" class="pln"><span class="str">            If you never set it, then it will be "channels_last".</span><span class="strut">&nbsp;</span></p>
<p id="t247" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t248" class="pln"><span class="str">    # Input shape</span><span class="strut">&nbsp;</span></p>
<p id="t249" class="pln"><span class="str">        5D tensor with shape:</span><span class="strut">&nbsp;</span></p>
<p id="t250" class="pln"><span class="str">        `(samples, channels, dim1, dim2, dim3)` if data_format='channels_first'</span><span class="strut">&nbsp;</span></p>
<p id="t251" class="pln"><span class="str">        or 5D tensor with shape:</span><span class="strut">&nbsp;</span></p>
<p id="t252" class="pln"><span class="str">        `(samples, dim1, dim2, dim3, channels)` if data_format='channels_last'.</span><span class="strut">&nbsp;</span></p>
<p id="t253" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t254" class="pln"><span class="str">    # Output shape</span><span class="strut">&nbsp;</span></p>
<p id="t255" class="pln"><span class="str">        Same as input</span><span class="strut">&nbsp;</span></p>
<p id="t256" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t257" class="pln"><span class="str">    # References</span><span class="strut">&nbsp;</span></p>
<p id="t258" class="pln"><span class="str">        - [Efficient Object Localization Using Convolutional Networks](</span><span class="strut">&nbsp;</span></p>
<p id="t259" class="pln"><span class="str">           https://arxiv.org/abs/1411.4280)</span><span class="strut">&nbsp;</span></p>
<p id="t260" class="pln"><span class="str">    """</span><span class="strut">&nbsp;</span></p>
<p id="t261" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t262" class="stm run hide_run">    <span class="op">@</span><span class="nam">interfaces</span><span class="op">.</span><span class="nam">legacy_spatialdropoutNd_support</span><span class="strut">&nbsp;</span></p>
<p id="t263" class="stm run hide_run">    <span class="key">def</span> <span class="nam">__init__</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">rate</span><span class="op">,</span> <span class="nam">data_format</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="op">**</span><span class="nam">kwargs</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t264" class="stm run hide_run">        <span class="nam">super</span><span class="op">(</span><span class="nam">SpatialDropout3D</span><span class="op">,</span> <span class="nam">self</span><span class="op">)</span><span class="op">.</span><span class="nam">__init__</span><span class="op">(</span><span class="nam">rate</span><span class="op">,</span> <span class="op">**</span><span class="nam">kwargs</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t265" class="stm run hide_run">        <span class="nam">self</span><span class="op">.</span><span class="nam">data_format</span> <span class="op">=</span> <span class="nam">K</span><span class="op">.</span><span class="nam">normalize_data_format</span><span class="op">(</span><span class="nam">data_format</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t266" class="stm run hide_run">        <span class="nam">self</span><span class="op">.</span><span class="nam">input_spec</span> <span class="op">=</span> <span class="nam">InputSpec</span><span class="op">(</span><span class="nam">ndim</span><span class="op">=</span><span class="num">5</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t267" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t268" class="stm run hide_run">    <span class="key">def</span> <span class="nam">_get_noise_shape</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">inputs</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t269" class="stm run hide_run">        <span class="nam">input_shape</span> <span class="op">=</span> <span class="nam">K</span><span class="op">.</span><span class="nam">shape</span><span class="op">(</span><span class="nam">inputs</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t270" class="stm run hide_run">        <span class="key">if</span> <span class="nam">self</span><span class="op">.</span><span class="nam">data_format</span> <span class="op">==</span> <span class="str">'channels_first'</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t271" class="stm run hide_run">            <span class="nam">noise_shape</span> <span class="op">=</span> <span class="op">(</span><span class="nam">input_shape</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">,</span> <span class="nam">input_shape</span><span class="op">[</span><span class="num">1</span><span class="op">]</span><span class="op">,</span> <span class="num">1</span><span class="op">,</span> <span class="num">1</span><span class="op">,</span> <span class="num">1</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t272" class="pln">        <span class="key">else</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t273" class="stm run hide_run">            <span class="nam">noise_shape</span> <span class="op">=</span> <span class="op">(</span><span class="nam">input_shape</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">,</span> <span class="num">1</span><span class="op">,</span> <span class="num">1</span><span class="op">,</span> <span class="num">1</span><span class="op">,</span> <span class="nam">input_shape</span><span class="op">[</span><span class="num">4</span><span class="op">]</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t274" class="stm run hide_run">        <span class="key">return</span> <span class="nam">noise_shape</span><span class="strut">&nbsp;</span></p>
<p id="t275" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t276" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t277" class="stm run hide_run"><span class="key">class</span> <span class="nam">Activation</span><span class="op">(</span><span class="nam">Layer</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t278" class="pln">    <span class="str">"""Applies an activation function to an output.</span><span class="strut">&nbsp;</span></p>
<p id="t279" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t280" class="pln"><span class="str">    # Arguments</span><span class="strut">&nbsp;</span></p>
<p id="t281" class="pln"><span class="str">        activation: name of activation function to use</span><span class="strut">&nbsp;</span></p>
<p id="t282" class="pln"><span class="str">            (see: [activations](../activations.md)),</span><span class="strut">&nbsp;</span></p>
<p id="t283" class="pln"><span class="str">            or alternatively, a Theano or TensorFlow operation.</span><span class="strut">&nbsp;</span></p>
<p id="t284" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t285" class="pln"><span class="str">    # Input shape</span><span class="strut">&nbsp;</span></p>
<p id="t286" class="pln"><span class="str">        Arbitrary. Use the keyword argument `input_shape`</span><span class="strut">&nbsp;</span></p>
<p id="t287" class="pln"><span class="str">        (tuple of integers, does not include the samples axis)</span><span class="strut">&nbsp;</span></p>
<p id="t288" class="pln"><span class="str">        when using this layer as the first layer in a model.</span><span class="strut">&nbsp;</span></p>
<p id="t289" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t290" class="pln"><span class="str">    # Output shape</span><span class="strut">&nbsp;</span></p>
<p id="t291" class="pln"><span class="str">        Same shape as input.</span><span class="strut">&nbsp;</span></p>
<p id="t292" class="pln"><span class="str">    """</span><span class="strut">&nbsp;</span></p>
<p id="t293" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t294" class="stm run hide_run">    <span class="key">def</span> <span class="nam">__init__</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">activation</span><span class="op">,</span> <span class="op">**</span><span class="nam">kwargs</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t295" class="stm run hide_run">        <span class="nam">super</span><span class="op">(</span><span class="nam">Activation</span><span class="op">,</span> <span class="nam">self</span><span class="op">)</span><span class="op">.</span><span class="nam">__init__</span><span class="op">(</span><span class="op">**</span><span class="nam">kwargs</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t296" class="stm run hide_run">        <span class="nam">self</span><span class="op">.</span><span class="nam">supports_masking</span> <span class="op">=</span> <span class="key">True</span><span class="strut">&nbsp;</span></p>
<p id="t297" class="stm run hide_run">        <span class="nam">self</span><span class="op">.</span><span class="nam">activation</span> <span class="op">=</span> <span class="nam">activations</span><span class="op">.</span><span class="nam">get</span><span class="op">(</span><span class="nam">activation</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t298" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t299" class="stm run hide_run">    <span class="key">def</span> <span class="nam">call</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">inputs</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t300" class="stm run hide_run">        <span class="key">return</span> <span class="nam">self</span><span class="op">.</span><span class="nam">activation</span><span class="op">(</span><span class="nam">inputs</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t301" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t302" class="stm run hide_run">    <span class="key">def</span> <span class="nam">get_config</span><span class="op">(</span><span class="nam">self</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t303" class="stm run hide_run">        <span class="nam">config</span> <span class="op">=</span> <span class="op">{</span><span class="str">'activation'</span><span class="op">:</span> <span class="nam">activations</span><span class="op">.</span><span class="nam">serialize</span><span class="op">(</span><span class="nam">self</span><span class="op">.</span><span class="nam">activation</span><span class="op">)</span><span class="op">}</span><span class="strut">&nbsp;</span></p>
<p id="t304" class="stm run hide_run">        <span class="nam">base_config</span> <span class="op">=</span> <span class="nam">super</span><span class="op">(</span><span class="nam">Activation</span><span class="op">,</span> <span class="nam">self</span><span class="op">)</span><span class="op">.</span><span class="nam">get_config</span><span class="op">(</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t305" class="stm run hide_run">        <span class="key">return</span> <span class="nam">dict</span><span class="op">(</span><span class="nam">list</span><span class="op">(</span><span class="nam">base_config</span><span class="op">.</span><span class="nam">items</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> <span class="nam">list</span><span class="op">(</span><span class="nam">config</span><span class="op">.</span><span class="nam">items</span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t306" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t307" class="stm run hide_run">    <span class="key">def</span> <span class="nam">compute_output_shape</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">input_shape</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t308" class="stm run hide_run">        <span class="key">return</span> <span class="nam">input_shape</span><span class="strut">&nbsp;</span></p>
<p id="t309" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t310" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t311" class="stm run hide_run"><span class="key">class</span> <span class="nam">Reshape</span><span class="op">(</span><span class="nam">Layer</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t312" class="pln">    <span class="str">"""Reshapes an output to a certain shape.</span><span class="strut">&nbsp;</span></p>
<p id="t313" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t314" class="pln"><span class="str">    # Arguments</span><span class="strut">&nbsp;</span></p>
<p id="t315" class="pln"><span class="str">        target_shape: target shape. Tuple of integers.</span><span class="strut">&nbsp;</span></p>
<p id="t316" class="pln"><span class="str">            Does not include the batch axis.</span><span class="strut">&nbsp;</span></p>
<p id="t317" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t318" class="pln"><span class="str">    # Input shape</span><span class="strut">&nbsp;</span></p>
<p id="t319" class="pln"><span class="str">        Arbitrary, although all dimensions in the input shaped must be fixed.</span><span class="strut">&nbsp;</span></p>
<p id="t320" class="pln"><span class="str">        Use the keyword argument `input_shape`</span><span class="strut">&nbsp;</span></p>
<p id="t321" class="pln"><span class="str">        (tuple of integers, does not include the batch axis)</span><span class="strut">&nbsp;</span></p>
<p id="t322" class="pln"><span class="str">        when using this layer as the first layer in a model.</span><span class="strut">&nbsp;</span></p>
<p id="t323" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t324" class="pln"><span class="str">    # Output shape</span><span class="strut">&nbsp;</span></p>
<p id="t325" class="pln"><span class="str">        `(batch_size,) + target_shape`</span><span class="strut">&nbsp;</span></p>
<p id="t326" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t327" class="pln"><span class="str">    # Example</span><span class="strut">&nbsp;</span></p>
<p id="t328" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t329" class="pln"><span class="str">    ```python</span><span class="strut">&nbsp;</span></p>
<p id="t330" class="pln"><span class="str">        # as first layer in a Sequential model</span><span class="strut">&nbsp;</span></p>
<p id="t331" class="pln"><span class="str">        model = Sequential()</span><span class="strut">&nbsp;</span></p>
<p id="t332" class="pln"><span class="str">        model.add(Reshape((3, 4), input_shape=(12,)))</span><span class="strut">&nbsp;</span></p>
<p id="t333" class="pln"><span class="str">        # now: model.output_shape == (None, 3, 4)</span><span class="strut">&nbsp;</span></p>
<p id="t334" class="pln"><span class="str">        # note: `None` is the batch dimension</span><span class="strut">&nbsp;</span></p>
<p id="t335" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t336" class="pln"><span class="str">        # as intermediate layer in a Sequential model</span><span class="strut">&nbsp;</span></p>
<p id="t337" class="pln"><span class="str">        model.add(Reshape((6, 2)))</span><span class="strut">&nbsp;</span></p>
<p id="t338" class="pln"><span class="str">        # now: model.output_shape == (None, 6, 2)</span><span class="strut">&nbsp;</span></p>
<p id="t339" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t340" class="pln"><span class="str">        # also supports shape inference using `-1` as dimension</span><span class="strut">&nbsp;</span></p>
<p id="t341" class="pln"><span class="str">        model.add(Reshape((-1, 2, 2)))</span><span class="strut">&nbsp;</span></p>
<p id="t342" class="pln"><span class="str">        # now: model.output_shape == (None, 3, 2, 2)</span><span class="strut">&nbsp;</span></p>
<p id="t343" class="pln"><span class="str">    ```</span><span class="strut">&nbsp;</span></p>
<p id="t344" class="pln"><span class="str">    """</span><span class="strut">&nbsp;</span></p>
<p id="t345" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t346" class="stm run hide_run">    <span class="key">def</span> <span class="nam">__init__</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">target_shape</span><span class="op">,</span> <span class="op">**</span><span class="nam">kwargs</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t347" class="stm run hide_run">        <span class="nam">super</span><span class="op">(</span><span class="nam">Reshape</span><span class="op">,</span> <span class="nam">self</span><span class="op">)</span><span class="op">.</span><span class="nam">__init__</span><span class="op">(</span><span class="op">**</span><span class="nam">kwargs</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t348" class="stm run hide_run">        <span class="nam">self</span><span class="op">.</span><span class="nam">target_shape</span> <span class="op">=</span> <span class="nam">tuple</span><span class="op">(</span><span class="nam">target_shape</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t349" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t350" class="stm run hide_run">    <span class="key">def</span> <span class="nam">_fix_unknown_dimension</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">input_shape</span><span class="op">,</span> <span class="nam">output_shape</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t351" class="pln">        <span class="str">"""Finds and replaces a missing dimension in an output shape.</span><span class="strut">&nbsp;</span></p>
<p id="t352" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t353" class="pln"><span class="str">        This is a near direct port of the internal Numpy function</span><span class="strut">&nbsp;</span></p>
<p id="t354" class="pln"><span class="str">        `_fix_unknown_dimension` in `numpy/core/src/multiarray/shape.c`</span><span class="strut">&nbsp;</span></p>
<p id="t355" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t356" class="pln"><span class="str">        # Arguments</span><span class="strut">&nbsp;</span></p>
<p id="t357" class="pln"><span class="str">            input_shape: original shape of array being reshaped</span><span class="strut">&nbsp;</span></p>
<p id="t358" class="pln"><span class="str">            output_shape: target shape of the array, with at most</span><span class="strut">&nbsp;</span></p>
<p id="t359" class="pln"><span class="str">                a single -1 which indicates a dimension that should be</span><span class="strut">&nbsp;</span></p>
<p id="t360" class="pln"><span class="str">                derived from the input shape.</span><span class="strut">&nbsp;</span></p>
<p id="t361" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t362" class="pln"><span class="str">        # Returns</span><span class="strut">&nbsp;</span></p>
<p id="t363" class="pln"><span class="str">            The new output shape with a `-1` replaced with its computed value.</span><span class="strut">&nbsp;</span></p>
<p id="t364" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t365" class="pln"><span class="str">        # Raises</span><span class="strut">&nbsp;</span></p>
<p id="t366" class="pln"><span class="str">            ValueError: if `input_shape` and `output_shape` do not match.</span><span class="strut">&nbsp;</span></p>
<p id="t367" class="pln"><span class="str">        """</span><span class="strut">&nbsp;</span></p>
<p id="t368" class="stm run hide_run">        <span class="nam">output_shape</span> <span class="op">=</span> <span class="nam">list</span><span class="op">(</span><span class="nam">output_shape</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t369" class="stm run hide_run">        <span class="nam">msg</span> <span class="op">=</span> <span class="str">'total size of new array must be unchanged'</span><span class="strut">&nbsp;</span></p>
<p id="t370" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t371" class="stm run hide_run">        <span class="nam">known</span><span class="op">,</span> <span class="nam">unknown</span> <span class="op">=</span> <span class="num">1</span><span class="op">,</span> <span class="key">None</span><span class="strut">&nbsp;</span></p>
<p id="t372" class="stm run hide_run">        <span class="key">for</span> <span class="nam">index</span><span class="op">,</span> <span class="nam">dim</span> <span class="key">in</span> <span class="nam">enumerate</span><span class="op">(</span><span class="nam">output_shape</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t373" class="stm run hide_run">            <span class="key">if</span> <span class="nam">dim</span> <span class="op">&lt;</span> <span class="num">0</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t374" class="stm run hide_run">                <span class="key">if</span> <span class="nam">unknown</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t375" class="stm run hide_run">                    <span class="nam">unknown</span> <span class="op">=</span> <span class="nam">index</span><span class="strut">&nbsp;</span></p>
<p id="t376" class="pln">                <span class="key">else</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t377" class="stm mis">                    <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">'Can only specify one unknown dimension.'</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t378" class="pln">            <span class="key">else</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t379" class="stm run hide_run">                <span class="nam">known</span> <span class="op">*=</span> <span class="nam">dim</span><span class="strut">&nbsp;</span></p>
<p id="t380" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t381" class="stm run hide_run">        <span class="nam">original</span> <span class="op">=</span> <span class="nam">np</span><span class="op">.</span><span class="nam">prod</span><span class="op">(</span><span class="nam">input_shape</span><span class="op">,</span> <span class="nam">dtype</span><span class="op">=</span><span class="nam">int</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t382" class="stm run hide_run">        <span class="key">if</span> <span class="nam">unknown</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t383" class="stm run hide_run">            <span class="key">if</span> <span class="nam">known</span> <span class="op">==</span> <span class="num">0</span> <span class="key">or</span> <span class="nam">original</span> <span class="op">%</span> <span class="nam">known</span> <span class="op">!=</span> <span class="num">0</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t384" class="stm mis">                <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="nam">msg</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t385" class="stm run hide_run">            <span class="nam">output_shape</span><span class="op">[</span><span class="nam">unknown</span><span class="op">]</span> <span class="op">=</span> <span class="nam">original</span> <span class="op">//</span> <span class="nam">known</span><span class="strut">&nbsp;</span></p>
<p id="t386" class="stm run hide_run">        <span class="key">elif</span> <span class="nam">original</span> <span class="op">!=</span> <span class="nam">known</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t387" class="stm mis">            <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="nam">msg</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t388" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t389" class="stm run hide_run">        <span class="key">return</span> <span class="nam">tuple</span><span class="op">(</span><span class="nam">output_shape</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t390" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t391" class="stm run hide_run">    <span class="key">def</span> <span class="nam">compute_output_shape</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">input_shape</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t392" class="stm run hide_run">        <span class="key">if</span> <span class="key">None</span> <span class="key">in</span> <span class="nam">input_shape</span><span class="op">[</span><span class="num">1</span><span class="op">:</span><span class="op">]</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t393" class="pln">            <span class="com"># input shape (partially) unknown? replace -1's with None's</span><span class="strut">&nbsp;</span></p>
<p id="t394" class="stm run hide_run">            <span class="key">return</span> <span class="op">(</span><span class="op">(</span><span class="nam">input_shape</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">,</span><span class="op">)</span> <span class="op">+</span><span class="strut">&nbsp;</span></p>
<p id="t395" class="pln">                    <span class="nam">tuple</span><span class="op">(</span><span class="nam">s</span> <span class="key">if</span> <span class="nam">s</span> <span class="op">!=</span> <span class="op">-</span><span class="num">1</span> <span class="key">else</span> <span class="key">None</span> <span class="key">for</span> <span class="nam">s</span> <span class="key">in</span> <span class="nam">self</span><span class="op">.</span><span class="nam">target_shape</span><span class="op">)</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t396" class="pln">        <span class="key">else</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t397" class="pln">            <span class="com"># input shape known? then we can compute the output shape</span><span class="strut">&nbsp;</span></p>
<p id="t398" class="stm run hide_run">            <span class="key">return</span> <span class="op">(</span><span class="nam">input_shape</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">,</span><span class="op">)</span> <span class="op">+</span> <span class="nam">self</span><span class="op">.</span><span class="nam">_fix_unknown_dimension</span><span class="op">(</span><span class="strut">&nbsp;</span></p>
<p id="t399" class="pln">                <span class="nam">input_shape</span><span class="op">[</span><span class="num">1</span><span class="op">:</span><span class="op">]</span><span class="op">,</span> <span class="nam">self</span><span class="op">.</span><span class="nam">target_shape</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t400" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t401" class="stm run hide_run">    <span class="key">def</span> <span class="nam">call</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">inputs</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t402" class="stm run hide_run">        <span class="key">return</span> <span class="nam">K</span><span class="op">.</span><span class="nam">reshape</span><span class="op">(</span><span class="nam">inputs</span><span class="op">,</span> <span class="op">(</span><span class="nam">K</span><span class="op">.</span><span class="nam">shape</span><span class="op">(</span><span class="nam">inputs</span><span class="op">)</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">,</span><span class="op">)</span> <span class="op">+</span> <span class="nam">self</span><span class="op">.</span><span class="nam">target_shape</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t403" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t404" class="stm run hide_run">    <span class="key">def</span> <span class="nam">get_config</span><span class="op">(</span><span class="nam">self</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t405" class="stm run hide_run">        <span class="nam">config</span> <span class="op">=</span> <span class="op">{</span><span class="str">'target_shape'</span><span class="op">:</span> <span class="nam">self</span><span class="op">.</span><span class="nam">target_shape</span><span class="op">}</span><span class="strut">&nbsp;</span></p>
<p id="t406" class="stm run hide_run">        <span class="nam">base_config</span> <span class="op">=</span> <span class="nam">super</span><span class="op">(</span><span class="nam">Reshape</span><span class="op">,</span> <span class="nam">self</span><span class="op">)</span><span class="op">.</span><span class="nam">get_config</span><span class="op">(</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t407" class="stm run hide_run">        <span class="key">return</span> <span class="nam">dict</span><span class="op">(</span><span class="nam">list</span><span class="op">(</span><span class="nam">base_config</span><span class="op">.</span><span class="nam">items</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> <span class="nam">list</span><span class="op">(</span><span class="nam">config</span><span class="op">.</span><span class="nam">items</span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t408" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t409" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t410" class="stm run hide_run"><span class="key">class</span> <span class="nam">Permute</span><span class="op">(</span><span class="nam">Layer</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t411" class="pln">    <span class="str">"""Permutes the dimensions of the input according to a given pattern.</span><span class="strut">&nbsp;</span></p>
<p id="t412" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t413" class="pln"><span class="str">    Useful for e.g. connecting RNNs and convnets together.</span><span class="strut">&nbsp;</span></p>
<p id="t414" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t415" class="pln"><span class="str">    # Example</span><span class="strut">&nbsp;</span></p>
<p id="t416" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t417" class="pln"><span class="str">    ```python</span><span class="strut">&nbsp;</span></p>
<p id="t418" class="pln"><span class="str">        model = Sequential()</span><span class="strut">&nbsp;</span></p>
<p id="t419" class="pln"><span class="str">        model.add(Permute((2, 1), input_shape=(10, 64)))</span><span class="strut">&nbsp;</span></p>
<p id="t420" class="pln"><span class="str">        # now: model.output_shape == (None, 64, 10)</span><span class="strut">&nbsp;</span></p>
<p id="t421" class="pln"><span class="str">        # note: `None` is the batch dimension</span><span class="strut">&nbsp;</span></p>
<p id="t422" class="pln"><span class="str">    ```</span><span class="strut">&nbsp;</span></p>
<p id="t423" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t424" class="pln"><span class="str">    # Arguments</span><span class="strut">&nbsp;</span></p>
<p id="t425" class="pln"><span class="str">        dims: Tuple of integers. Permutation pattern, does not include the</span><span class="strut">&nbsp;</span></p>
<p id="t426" class="pln"><span class="str">            samples dimension. Indexing starts at 1.</span><span class="strut">&nbsp;</span></p>
<p id="t427" class="pln"><span class="str">            For instance, `(2, 1)` permutes the first and second dimension</span><span class="strut">&nbsp;</span></p>
<p id="t428" class="pln"><span class="str">            of the input.</span><span class="strut">&nbsp;</span></p>
<p id="t429" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t430" class="pln"><span class="str">    # Input shape</span><span class="strut">&nbsp;</span></p>
<p id="t431" class="pln"><span class="str">        Arbitrary. Use the keyword argument `input_shape`</span><span class="strut">&nbsp;</span></p>
<p id="t432" class="pln"><span class="str">        (tuple of integers, does not include the samples axis)</span><span class="strut">&nbsp;</span></p>
<p id="t433" class="pln"><span class="str">        when using this layer as the first layer in a model.</span><span class="strut">&nbsp;</span></p>
<p id="t434" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t435" class="pln"><span class="str">    # Output shape</span><span class="strut">&nbsp;</span></p>
<p id="t436" class="pln"><span class="str">        Same as the input shape, but with the dimensions re-ordered according</span><span class="strut">&nbsp;</span></p>
<p id="t437" class="pln"><span class="str">        to the specified pattern.</span><span class="strut">&nbsp;</span></p>
<p id="t438" class="pln"><span class="str">    """</span><span class="strut">&nbsp;</span></p>
<p id="t439" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t440" class="stm run hide_run">    <span class="key">def</span> <span class="nam">__init__</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">dims</span><span class="op">,</span> <span class="op">**</span><span class="nam">kwargs</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t441" class="stm run hide_run">        <span class="nam">super</span><span class="op">(</span><span class="nam">Permute</span><span class="op">,</span> <span class="nam">self</span><span class="op">)</span><span class="op">.</span><span class="nam">__init__</span><span class="op">(</span><span class="op">**</span><span class="nam">kwargs</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t442" class="stm run hide_run">        <span class="nam">self</span><span class="op">.</span><span class="nam">dims</span> <span class="op">=</span> <span class="nam">tuple</span><span class="op">(</span><span class="nam">dims</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t443" class="stm run hide_run">        <span class="nam">self</span><span class="op">.</span><span class="nam">input_spec</span> <span class="op">=</span> <span class="nam">InputSpec</span><span class="op">(</span><span class="nam">ndim</span><span class="op">=</span><span class="nam">len</span><span class="op">(</span><span class="nam">self</span><span class="op">.</span><span class="nam">dims</span><span class="op">)</span> <span class="op">+</span> <span class="num">1</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t444" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t445" class="stm run hide_run">    <span class="key">def</span> <span class="nam">compute_output_shape</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">input_shape</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t446" class="stm run hide_run">        <span class="nam">input_shape</span> <span class="op">=</span> <span class="nam">list</span><span class="op">(</span><span class="nam">input_shape</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t447" class="stm run hide_run">        <span class="nam">output_shape</span> <span class="op">=</span> <span class="nam">copy</span><span class="op">.</span><span class="nam">copy</span><span class="op">(</span><span class="nam">input_shape</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t448" class="stm run hide_run">        <span class="key">for</span> <span class="nam">i</span><span class="op">,</span> <span class="nam">dim</span> <span class="key">in</span> <span class="nam">enumerate</span><span class="op">(</span><span class="nam">self</span><span class="op">.</span><span class="nam">dims</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t449" class="stm run hide_run">            <span class="nam">target_dim</span> <span class="op">=</span> <span class="nam">input_shape</span><span class="op">[</span><span class="nam">dim</span><span class="op">]</span><span class="strut">&nbsp;</span></p>
<p id="t450" class="stm run hide_run">            <span class="nam">output_shape</span><span class="op">[</span><span class="nam">i</span> <span class="op">+</span> <span class="num">1</span><span class="op">]</span> <span class="op">=</span> <span class="nam">target_dim</span><span class="strut">&nbsp;</span></p>
<p id="t451" class="stm run hide_run">        <span class="key">return</span> <span class="nam">tuple</span><span class="op">(</span><span class="nam">output_shape</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t452" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t453" class="stm run hide_run">    <span class="key">def</span> <span class="nam">call</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">inputs</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t454" class="stm run hide_run">        <span class="key">return</span> <span class="nam">K</span><span class="op">.</span><span class="nam">permute_dimensions</span><span class="op">(</span><span class="nam">inputs</span><span class="op">,</span> <span class="op">(</span><span class="num">0</span><span class="op">,</span><span class="op">)</span> <span class="op">+</span> <span class="nam">self</span><span class="op">.</span><span class="nam">dims</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t455" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t456" class="stm run hide_run">    <span class="key">def</span> <span class="nam">get_config</span><span class="op">(</span><span class="nam">self</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t457" class="stm run hide_run">        <span class="nam">config</span> <span class="op">=</span> <span class="op">{</span><span class="str">'dims'</span><span class="op">:</span> <span class="nam">self</span><span class="op">.</span><span class="nam">dims</span><span class="op">}</span><span class="strut">&nbsp;</span></p>
<p id="t458" class="stm run hide_run">        <span class="nam">base_config</span> <span class="op">=</span> <span class="nam">super</span><span class="op">(</span><span class="nam">Permute</span><span class="op">,</span> <span class="nam">self</span><span class="op">)</span><span class="op">.</span><span class="nam">get_config</span><span class="op">(</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t459" class="stm run hide_run">        <span class="key">return</span> <span class="nam">dict</span><span class="op">(</span><span class="nam">list</span><span class="op">(</span><span class="nam">base_config</span><span class="op">.</span><span class="nam">items</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> <span class="nam">list</span><span class="op">(</span><span class="nam">config</span><span class="op">.</span><span class="nam">items</span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t460" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t461" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t462" class="stm run hide_run"><span class="key">class</span> <span class="nam">Flatten</span><span class="op">(</span><span class="nam">Layer</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t463" class="pln">    <span class="str">"""Flattens the input. Does not affect the batch size.</span><span class="strut">&nbsp;</span></p>
<p id="t464" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t465" class="pln"><span class="str">    # Arguments</span><span class="strut">&nbsp;</span></p>
<p id="t466" class="pln"><span class="str">        data_format: A string,</span><span class="strut">&nbsp;</span></p>
<p id="t467" class="pln"><span class="str">            one of `channels_last` (default) or `channels_first`.</span><span class="strut">&nbsp;</span></p>
<p id="t468" class="pln"><span class="str">            The ordering of the dimensions in the inputs.</span><span class="strut">&nbsp;</span></p>
<p id="t469" class="pln"><span class="str">            The purpose of this argument is to preserve weight</span><span class="strut">&nbsp;</span></p>
<p id="t470" class="pln"><span class="str">            ordering when switching a model from one data format</span><span class="strut">&nbsp;</span></p>
<p id="t471" class="pln"><span class="str">            to another.</span><span class="strut">&nbsp;</span></p>
<p id="t472" class="pln"><span class="str">            `channels_last` corresponds to inputs with shape</span><span class="strut">&nbsp;</span></p>
<p id="t473" class="pln"><span class="str">            `(batch, ..., channels)` while `channels_first` corresponds to</span><span class="strut">&nbsp;</span></p>
<p id="t474" class="pln"><span class="str">            inputs with shape `(batch, channels, ...)`.</span><span class="strut">&nbsp;</span></p>
<p id="t475" class="pln"><span class="str">            It defaults to the `image_data_format` value found in your</span><span class="strut">&nbsp;</span></p>
<p id="t476" class="pln"><span class="str">            Keras config file at `~/.keras/keras.json`.</span><span class="strut">&nbsp;</span></p>
<p id="t477" class="pln"><span class="str">            If you never set it, then it will be "channels_last".</span><span class="strut">&nbsp;</span></p>
<p id="t478" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t479" class="pln"><span class="str">    # Example</span><span class="strut">&nbsp;</span></p>
<p id="t480" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t481" class="pln"><span class="str">    ```python</span><span class="strut">&nbsp;</span></p>
<p id="t482" class="pln"><span class="str">        model = Sequential()</span><span class="strut">&nbsp;</span></p>
<p id="t483" class="pln"><span class="str">        model.add(Conv2D(64, (3, 3),</span><span class="strut">&nbsp;</span></p>
<p id="t484" class="pln"><span class="str">                         input_shape=(3, 32, 32), padding='same',))</span><span class="strut">&nbsp;</span></p>
<p id="t485" class="pln"><span class="str">        # now: model.output_shape == (None, 64, 32, 32)</span><span class="strut">&nbsp;</span></p>
<p id="t486" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t487" class="pln"><span class="str">        model.add(Flatten())</span><span class="strut">&nbsp;</span></p>
<p id="t488" class="pln"><span class="str">        # now: model.output_shape == (None, 65536)</span><span class="strut">&nbsp;</span></p>
<p id="t489" class="pln"><span class="str">    ```</span><span class="strut">&nbsp;</span></p>
<p id="t490" class="pln"><span class="str">    """</span><span class="strut">&nbsp;</span></p>
<p id="t491" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t492" class="stm run hide_run">    <span class="key">def</span> <span class="nam">__init__</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">data_format</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="op">**</span><span class="nam">kwargs</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t493" class="stm run hide_run">        <span class="nam">super</span><span class="op">(</span><span class="nam">Flatten</span><span class="op">,</span> <span class="nam">self</span><span class="op">)</span><span class="op">.</span><span class="nam">__init__</span><span class="op">(</span><span class="op">**</span><span class="nam">kwargs</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t494" class="stm run hide_run">        <span class="nam">self</span><span class="op">.</span><span class="nam">input_spec</span> <span class="op">=</span> <span class="nam">InputSpec</span><span class="op">(</span><span class="nam">min_ndim</span><span class="op">=</span><span class="num">3</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t495" class="stm run hide_run">        <span class="nam">self</span><span class="op">.</span><span class="nam">data_format</span> <span class="op">=</span> <span class="nam">K</span><span class="op">.</span><span class="nam">normalize_data_format</span><span class="op">(</span><span class="nam">data_format</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t496" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t497" class="stm run hide_run">    <span class="key">def</span> <span class="nam">compute_output_shape</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">input_shape</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t498" class="stm run hide_run">        <span class="key">if</span> <span class="key">not</span> <span class="nam">all</span><span class="op">(</span><span class="nam">input_shape</span><span class="op">[</span><span class="num">1</span><span class="op">:</span><span class="op">]</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t499" class="stm mis">            <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">'The shape of the input to "Flatten" '</span><span class="strut">&nbsp;</span></p>
<p id="t500" class="pln">                             <span class="str">'is not fully defined '</span><span class="strut">&nbsp;</span></p>
<p id="t501" class="pln">                             <span class="str">'(got '</span> <span class="op">+</span> <span class="nam">str</span><span class="op">(</span><span class="nam">input_shape</span><span class="op">[</span><span class="num">1</span><span class="op">:</span><span class="op">]</span><span class="op">)</span> <span class="op">+</span> <span class="str">'. '</span><span class="strut">&nbsp;</span></p>
<p id="t502" class="pln">                             <span class="str">'Make sure to pass a complete "input_shape" '</span><span class="strut">&nbsp;</span></p>
<p id="t503" class="pln">                             <span class="str">'or "batch_input_shape" argument to the first '</span><span class="strut">&nbsp;</span></p>
<p id="t504" class="pln">                             <span class="str">'layer in your model.'</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t505" class="stm run hide_run">        <span class="key">return</span> <span class="op">(</span><span class="nam">input_shape</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">,</span> <span class="nam">np</span><span class="op">.</span><span class="nam">prod</span><span class="op">(</span><span class="nam">input_shape</span><span class="op">[</span><span class="num">1</span><span class="op">:</span><span class="op">]</span><span class="op">)</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t506" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t507" class="stm run hide_run">    <span class="key">def</span> <span class="nam">call</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">inputs</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t508" class="stm run hide_run">        <span class="key">if</span> <span class="nam">self</span><span class="op">.</span><span class="nam">data_format</span> <span class="op">==</span> <span class="str">'channels_first'</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t509" class="pln">            <span class="com"># Ensure works for any dim</span><span class="strut">&nbsp;</span></p>
<p id="t510" class="stm run hide_run">            <span class="nam">permutation</span> <span class="op">=</span> <span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="strut">&nbsp;</span></p>
<p id="t511" class="stm run hide_run">            <span class="nam">permutation</span><span class="op">.</span><span class="nam">extend</span><span class="op">(</span><span class="op">[</span><span class="nam">i</span> <span class="key">for</span> <span class="nam">i</span> <span class="key">in</span><span class="strut">&nbsp;</span></p>
<p id="t512" class="pln">                                <span class="nam">range</span><span class="op">(</span><span class="num">2</span><span class="op">,</span> <span class="nam">K</span><span class="op">.</span><span class="nam">ndim</span><span class="op">(</span><span class="nam">inputs</span><span class="op">)</span><span class="op">)</span><span class="op">]</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t513" class="stm run hide_run">            <span class="nam">permutation</span><span class="op">.</span><span class="nam">append</span><span class="op">(</span><span class="num">1</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t514" class="stm run hide_run">            <span class="nam">inputs</span> <span class="op">=</span> <span class="nam">K</span><span class="op">.</span><span class="nam">permute_dimensions</span><span class="op">(</span><span class="nam">inputs</span><span class="op">,</span> <span class="nam">permutation</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t515" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t516" class="stm run hide_run">        <span class="key">return</span> <span class="nam">K</span><span class="op">.</span><span class="nam">batch_flatten</span><span class="op">(</span><span class="nam">inputs</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t517" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t518" class="stm run hide_run">    <span class="key">def</span> <span class="nam">get_config</span><span class="op">(</span><span class="nam">self</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t519" class="stm run hide_run">        <span class="nam">config</span> <span class="op">=</span> <span class="op">{</span><span class="str">'data_format'</span><span class="op">:</span> <span class="nam">self</span><span class="op">.</span><span class="nam">data_format</span><span class="op">}</span><span class="strut">&nbsp;</span></p>
<p id="t520" class="stm run hide_run">        <span class="nam">base_config</span> <span class="op">=</span> <span class="nam">super</span><span class="op">(</span><span class="nam">Flatten</span><span class="op">,</span> <span class="nam">self</span><span class="op">)</span><span class="op">.</span><span class="nam">get_config</span><span class="op">(</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t521" class="stm run hide_run">        <span class="key">return</span> <span class="nam">dict</span><span class="op">(</span><span class="nam">list</span><span class="op">(</span><span class="nam">base_config</span><span class="op">.</span><span class="nam">items</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> <span class="nam">list</span><span class="op">(</span><span class="nam">config</span><span class="op">.</span><span class="nam">items</span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t522" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t523" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t524" class="stm run hide_run"><span class="key">class</span> <span class="nam">RepeatVector</span><span class="op">(</span><span class="nam">Layer</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t525" class="pln">    <span class="str">"""Repeats the input n times.</span><span class="strut">&nbsp;</span></p>
<p id="t526" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t527" class="pln"><span class="str">    # Example</span><span class="strut">&nbsp;</span></p>
<p id="t528" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t529" class="pln"><span class="str">    ```python</span><span class="strut">&nbsp;</span></p>
<p id="t530" class="pln"><span class="str">        model = Sequential()</span><span class="strut">&nbsp;</span></p>
<p id="t531" class="pln"><span class="str">        model.add(Dense(32, input_dim=32))</span><span class="strut">&nbsp;</span></p>
<p id="t532" class="pln"><span class="str">        # now: model.output_shape == (None, 32)</span><span class="strut">&nbsp;</span></p>
<p id="t533" class="pln"><span class="str">        # note: `None` is the batch dimension</span><span class="strut">&nbsp;</span></p>
<p id="t534" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t535" class="pln"><span class="str">        model.add(RepeatVector(3))</span><span class="strut">&nbsp;</span></p>
<p id="t536" class="pln"><span class="str">        # now: model.output_shape == (None, 3, 32)</span><span class="strut">&nbsp;</span></p>
<p id="t537" class="pln"><span class="str">    ```</span><span class="strut">&nbsp;</span></p>
<p id="t538" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t539" class="pln"><span class="str">    # Arguments</span><span class="strut">&nbsp;</span></p>
<p id="t540" class="pln"><span class="str">        n: integer, repetition factor.</span><span class="strut">&nbsp;</span></p>
<p id="t541" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t542" class="pln"><span class="str">    # Input shape</span><span class="strut">&nbsp;</span></p>
<p id="t543" class="pln"><span class="str">        2D tensor of shape `(num_samples, features)`.</span><span class="strut">&nbsp;</span></p>
<p id="t544" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t545" class="pln"><span class="str">    # Output shape</span><span class="strut">&nbsp;</span></p>
<p id="t546" class="pln"><span class="str">        3D tensor of shape `(num_samples, n, features)`.</span><span class="strut">&nbsp;</span></p>
<p id="t547" class="pln"><span class="str">    """</span><span class="strut">&nbsp;</span></p>
<p id="t548" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t549" class="stm run hide_run">    <span class="key">def</span> <span class="nam">__init__</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">n</span><span class="op">,</span> <span class="op">**</span><span class="nam">kwargs</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t550" class="stm run hide_run">        <span class="nam">super</span><span class="op">(</span><span class="nam">RepeatVector</span><span class="op">,</span> <span class="nam">self</span><span class="op">)</span><span class="op">.</span><span class="nam">__init__</span><span class="op">(</span><span class="op">**</span><span class="nam">kwargs</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t551" class="stm run hide_run">        <span class="nam">self</span><span class="op">.</span><span class="nam">n</span> <span class="op">=</span> <span class="nam">n</span><span class="strut">&nbsp;</span></p>
<p id="t552" class="stm run hide_run">        <span class="nam">self</span><span class="op">.</span><span class="nam">input_spec</span> <span class="op">=</span> <span class="nam">InputSpec</span><span class="op">(</span><span class="nam">ndim</span><span class="op">=</span><span class="num">2</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t553" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t554" class="stm run hide_run">    <span class="key">def</span> <span class="nam">compute_output_shape</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">input_shape</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t555" class="stm run hide_run">        <span class="key">return</span> <span class="op">(</span><span class="nam">input_shape</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">,</span> <span class="nam">self</span><span class="op">.</span><span class="nam">n</span><span class="op">,</span> <span class="nam">input_shape</span><span class="op">[</span><span class="num">1</span><span class="op">]</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t556" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t557" class="stm run hide_run">    <span class="key">def</span> <span class="nam">call</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">inputs</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t558" class="stm run hide_run">        <span class="key">return</span> <span class="nam">K</span><span class="op">.</span><span class="nam">repeat</span><span class="op">(</span><span class="nam">inputs</span><span class="op">,</span> <span class="nam">self</span><span class="op">.</span><span class="nam">n</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t559" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t560" class="stm run hide_run">    <span class="key">def</span> <span class="nam">get_config</span><span class="op">(</span><span class="nam">self</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t561" class="stm run hide_run">        <span class="nam">config</span> <span class="op">=</span> <span class="op">{</span><span class="str">'n'</span><span class="op">:</span> <span class="nam">self</span><span class="op">.</span><span class="nam">n</span><span class="op">}</span><span class="strut">&nbsp;</span></p>
<p id="t562" class="stm run hide_run">        <span class="nam">base_config</span> <span class="op">=</span> <span class="nam">super</span><span class="op">(</span><span class="nam">RepeatVector</span><span class="op">,</span> <span class="nam">self</span><span class="op">)</span><span class="op">.</span><span class="nam">get_config</span><span class="op">(</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t563" class="stm run hide_run">        <span class="key">return</span> <span class="nam">dict</span><span class="op">(</span><span class="nam">list</span><span class="op">(</span><span class="nam">base_config</span><span class="op">.</span><span class="nam">items</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> <span class="nam">list</span><span class="op">(</span><span class="nam">config</span><span class="op">.</span><span class="nam">items</span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t564" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t565" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t566" class="stm run hide_run"><span class="key">class</span> <span class="nam">Lambda</span><span class="op">(</span><span class="nam">Layer</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t567" class="pln">    <span class="str">"""Wraps arbitrary expression as a `Layer` object.</span><span class="strut">&nbsp;</span></p>
<p id="t568" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t569" class="pln"><span class="str">    # Examples</span><span class="strut">&nbsp;</span></p>
<p id="t570" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t571" class="pln"><span class="str">    ```python</span><span class="strut">&nbsp;</span></p>
<p id="t572" class="pln"><span class="str">        # add a x -> x^2 layer</span><span class="strut">&nbsp;</span></p>
<p id="t573" class="pln"><span class="str">        model.add(Lambda(lambda x: x ** 2))</span><span class="strut">&nbsp;</span></p>
<p id="t574" class="pln"><span class="str">    ```</span><span class="strut">&nbsp;</span></p>
<p id="t575" class="pln"><span class="str">    ```python</span><span class="strut">&nbsp;</span></p>
<p id="t576" class="pln"><span class="str">        # add a layer that returns the concatenation</span><span class="strut">&nbsp;</span></p>
<p id="t577" class="pln"><span class="str">        # of the positive part of the input and</span><span class="strut">&nbsp;</span></p>
<p id="t578" class="pln"><span class="str">        # the opposite of the negative part</span><span class="strut">&nbsp;</span></p>
<p id="t579" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t580" class="pln"><span class="str">        def antirectifier(x):</span><span class="strut">&nbsp;</span></p>
<p id="t581" class="pln"><span class="str">            x -= K.mean(x, axis=1, keepdims=True)</span><span class="strut">&nbsp;</span></p>
<p id="t582" class="pln"><span class="str">            x = K.l2_normalize(x, axis=1)</span><span class="strut">&nbsp;</span></p>
<p id="t583" class="pln"><span class="str">            pos = K.relu(x)</span><span class="strut">&nbsp;</span></p>
<p id="t584" class="pln"><span class="str">            neg = K.relu(-x)</span><span class="strut">&nbsp;</span></p>
<p id="t585" class="pln"><span class="str">            return K.concatenate([pos, neg], axis=1)</span><span class="strut">&nbsp;</span></p>
<p id="t586" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t587" class="pln"><span class="str">        def antirectifier_output_shape(input_shape):</span><span class="strut">&nbsp;</span></p>
<p id="t588" class="pln"><span class="str">            shape = list(input_shape)</span><span class="strut">&nbsp;</span></p>
<p id="t589" class="pln"><span class="str">            assert len(shape) == 2  # only valid for 2D tensors</span><span class="strut">&nbsp;</span></p>
<p id="t590" class="pln"><span class="str">            shape[-1] *= 2</span><span class="strut">&nbsp;</span></p>
<p id="t591" class="pln"><span class="str">            return tuple(shape)</span><span class="strut">&nbsp;</span></p>
<p id="t592" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t593" class="pln"><span class="str">        model.add(Lambda(antirectifier,</span><span class="strut">&nbsp;</span></p>
<p id="t594" class="pln"><span class="str">                         output_shape=antirectifier_output_shape))</span><span class="strut">&nbsp;</span></p>
<p id="t595" class="pln"><span class="str">    ```</span><span class="strut">&nbsp;</span></p>
<p id="t596" class="pln"><span class="str">    ```python</span><span class="strut">&nbsp;</span></p>
<p id="t597" class="pln"><span class="str">        # add a layer that returns the hadamard product</span><span class="strut">&nbsp;</span></p>
<p id="t598" class="pln"><span class="str">        # and sum of it from two input tensors</span><span class="strut">&nbsp;</span></p>
<p id="t599" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t600" class="pln"><span class="str">        def hadamard_product_sum(tensors):</span><span class="strut">&nbsp;</span></p>
<p id="t601" class="pln"><span class="str">            out1 = tensors[0] * tensors[1]</span><span class="strut">&nbsp;</span></p>
<p id="t602" class="pln"><span class="str">            out2 = K.sum(out1, axis=-1)</span><span class="strut">&nbsp;</span></p>
<p id="t603" class="pln"><span class="str">            return [out1, out2]</span><span class="strut">&nbsp;</span></p>
<p id="t604" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t605" class="pln"><span class="str">        def hadamard_product_sum_output_shape(input_shapes):</span><span class="strut">&nbsp;</span></p>
<p id="t606" class="pln"><span class="str">            shape1 = list(input_shapes[0])</span><span class="strut">&nbsp;</span></p>
<p id="t607" class="pln"><span class="str">            shape2 = list(input_shapes[1])</span><span class="strut">&nbsp;</span></p>
<p id="t608" class="pln"><span class="str">            assert shape1 == shape2  # else hadamard product isn't possible</span><span class="strut">&nbsp;</span></p>
<p id="t609" class="pln"><span class="str">            return [tuple(shape1), tuple(shape2[:-1])]</span><span class="strut">&nbsp;</span></p>
<p id="t610" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t611" class="pln"><span class="str">        x1 = Dense(32)(input_1)</span><span class="strut">&nbsp;</span></p>
<p id="t612" class="pln"><span class="str">        x2 = Dense(32)(input_2)</span><span class="strut">&nbsp;</span></p>
<p id="t613" class="pln"><span class="str">        layer = Lambda(hadamard_product_sum, hadamard_product_sum_output_shape)</span><span class="strut">&nbsp;</span></p>
<p id="t614" class="pln"><span class="str">        x_hadamard, x_sum = layer([x1, x2])</span><span class="strut">&nbsp;</span></p>
<p id="t615" class="pln"><span class="str">    ```</span><span class="strut">&nbsp;</span></p>
<p id="t616" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t617" class="pln"><span class="str">    # Arguments</span><span class="strut">&nbsp;</span></p>
<p id="t618" class="pln"><span class="str">        function: The function to be evaluated.</span><span class="strut">&nbsp;</span></p>
<p id="t619" class="pln"><span class="str">            Takes input tensor or list of tensors as first argument.</span><span class="strut">&nbsp;</span></p>
<p id="t620" class="pln"><span class="str">        output_shape: Expected output shape from function.</span><span class="strut">&nbsp;</span></p>
<p id="t621" class="pln"><span class="str">            Only relevant when using Theano.</span><span class="strut">&nbsp;</span></p>
<p id="t622" class="pln"><span class="str">            Can be a tuple or function.</span><span class="strut">&nbsp;</span></p>
<p id="t623" class="pln"><span class="str">            If a tuple, it only specifies the first dimension onward;</span><span class="strut">&nbsp;</span></p>
<p id="t624" class="pln"><span class="str">                 sample dimension is assumed either the same as the input:</span><span class="strut">&nbsp;</span></p>
<p id="t625" class="pln"><span class="str">                 `output_shape = (input_shape[0], ) + output_shape`</span><span class="strut">&nbsp;</span></p>
<p id="t626" class="pln"><span class="str">                 or, the input is `None` and</span><span class="strut">&nbsp;</span></p>
<p id="t627" class="pln"><span class="str">                 the sample dimension is also `None`:</span><span class="strut">&nbsp;</span></p>
<p id="t628" class="pln"><span class="str">                 `output_shape = (None, ) + output_shape`</span><span class="strut">&nbsp;</span></p>
<p id="t629" class="pln"><span class="str">            If a function, it specifies the entire shape as a function of the</span><span class="strut">&nbsp;</span></p>
<p id="t630" class="pln"><span class="str">            input shape: `output_shape = f(input_shape)`</span><span class="strut">&nbsp;</span></p>
<p id="t631" class="pln"><span class="str">        mask: Either None (indicating no masking) or a Tensor indicating the</span><span class="strut">&nbsp;</span></p>
<p id="t632" class="pln"><span class="str">          input mask for Embedding.</span><span class="strut">&nbsp;</span></p>
<p id="t633" class="pln"><span class="str">        arguments: optional dictionary of keyword arguments to be passed</span><span class="strut">&nbsp;</span></p>
<p id="t634" class="pln"><span class="str">            to the function.</span><span class="strut">&nbsp;</span></p>
<p id="t635" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t636" class="pln"><span class="str">    # Input shape</span><span class="strut">&nbsp;</span></p>
<p id="t637" class="pln"><span class="str">        Arbitrary. Use the keyword argument input_shape</span><span class="strut">&nbsp;</span></p>
<p id="t638" class="pln"><span class="str">        (tuple of integers, does not include the samples axis)</span><span class="strut">&nbsp;</span></p>
<p id="t639" class="pln"><span class="str">        when using this layer as the first layer in a model.</span><span class="strut">&nbsp;</span></p>
<p id="t640" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t641" class="pln"><span class="str">    # Output shape</span><span class="strut">&nbsp;</span></p>
<p id="t642" class="pln"><span class="str">        Specified by `output_shape` argument</span><span class="strut">&nbsp;</span></p>
<p id="t643" class="pln"><span class="str">        (or auto-inferred when using TensorFlow or CNTK).</span><span class="strut">&nbsp;</span></p>
<p id="t644" class="pln"><span class="str">    """</span><span class="strut">&nbsp;</span></p>
<p id="t645" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t646" class="stm run hide_run">    <span class="op">@</span><span class="nam">interfaces</span><span class="op">.</span><span class="nam">legacy_lambda_support</span><span class="strut">&nbsp;</span></p>
<p id="t647" class="stm run hide_run">    <span class="key">def</span> <span class="nam">__init__</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">function</span><span class="op">,</span> <span class="nam">output_shape</span><span class="op">=</span><span class="key">None</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t648" class="pln">                 <span class="nam">mask</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="nam">arguments</span><span class="op">=</span><span class="key">None</span><span class="op">,</span> <span class="op">**</span><span class="nam">kwargs</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t649" class="stm run hide_run">        <span class="nam">super</span><span class="op">(</span><span class="nam">Lambda</span><span class="op">,</span> <span class="nam">self</span><span class="op">)</span><span class="op">.</span><span class="nam">__init__</span><span class="op">(</span><span class="op">**</span><span class="nam">kwargs</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t650" class="stm run hide_run">        <span class="nam">self</span><span class="op">.</span><span class="nam">function</span> <span class="op">=</span> <span class="nam">function</span><span class="strut">&nbsp;</span></p>
<p id="t651" class="stm run hide_run">        <span class="nam">self</span><span class="op">.</span><span class="nam">_input_dtypes</span> <span class="op">=</span> <span class="key">None</span><span class="strut">&nbsp;</span></p>
<p id="t652" class="stm run hide_run">        <span class="nam">self</span><span class="op">.</span><span class="nam">arguments</span> <span class="op">=</span> <span class="nam">arguments</span> <span class="key">if</span> <span class="nam">arguments</span> <span class="key">else</span> <span class="op">{</span><span class="op">}</span><span class="strut">&nbsp;</span></p>
<p id="t653" class="stm run hide_run">        <span class="key">if</span> <span class="nam">mask</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t654" class="stm run hide_run">            <span class="nam">self</span><span class="op">.</span><span class="nam">supports_masking</span> <span class="op">=</span> <span class="key">True</span><span class="strut">&nbsp;</span></p>
<p id="t655" class="stm run hide_run">        <span class="nam">self</span><span class="op">.</span><span class="nam">mask</span> <span class="op">=</span> <span class="nam">mask</span><span class="strut">&nbsp;</span></p>
<p id="t656" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t657" class="stm run hide_run">        <span class="key">if</span> <span class="nam">output_shape</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t658" class="stm run hide_run">            <span class="nam">self</span><span class="op">.</span><span class="nam">_output_shape</span> <span class="op">=</span> <span class="key">None</span><span class="strut">&nbsp;</span></p>
<p id="t659" class="stm run hide_run">        <span class="key">elif</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">output_shape</span><span class="op">,</span> <span class="op">(</span><span class="nam">tuple</span><span class="op">,</span> <span class="nam">list</span><span class="op">)</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t660" class="stm run hide_run">            <span class="nam">self</span><span class="op">.</span><span class="nam">_output_shape</span> <span class="op">=</span> <span class="nam">tuple</span><span class="op">(</span><span class="nam">output_shape</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t661" class="pln">        <span class="key">else</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t662" class="stm run hide_run">            <span class="key">if</span> <span class="key">not</span> <span class="nam">callable</span><span class="op">(</span><span class="nam">output_shape</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t663" class="stm mis">                <span class="key">raise</span> <span class="nam">TypeError</span><span class="op">(</span><span class="str">'In Lambda, `output_shape` '</span><span class="strut">&nbsp;</span></p>
<p id="t664" class="pln">                                <span class="str">'must be a list, a tuple, or a function.'</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t665" class="stm run hide_run">            <span class="nam">self</span><span class="op">.</span><span class="nam">_output_shape</span> <span class="op">=</span> <span class="nam">output_shape</span><span class="strut">&nbsp;</span></p>
<p id="t666" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t667" class="stm run hide_run">    <span class="key">def</span> <span class="nam">compute_output_shape</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">input_shape</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t668" class="stm run hide_run">        <span class="key">if</span> <span class="nam">self</span><span class="op">.</span><span class="nam">_output_shape</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t669" class="pln">            <span class="com"># With TensorFlow or CNTK, we can infer the output shape directly:</span><span class="strut">&nbsp;</span></p>
<p id="t670" class="stm run hide_run">            <span class="key">if</span> <span class="nam">K</span><span class="op">.</span><span class="nam">backend</span><span class="op">(</span><span class="op">)</span> <span class="key">in</span> <span class="op">(</span><span class="str">'tensorflow'</span><span class="op">,</span> <span class="str">'cntk'</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t671" class="stm run hide_run">                <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">input_shape</span><span class="op">,</span> <span class="nam">list</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t672" class="stm run hide_run">                    <span class="nam">xs</span> <span class="op">=</span> <span class="op">[</span><span class="nam">K</span><span class="op">.</span><span class="nam">placeholder</span><span class="op">(</span><span class="nam">shape</span><span class="op">=</span><span class="nam">shape</span><span class="op">,</span> <span class="nam">dtype</span><span class="op">=</span><span class="nam">dtype</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t673" class="pln">                          <span class="key">for</span> <span class="nam">shape</span><span class="op">,</span> <span class="nam">dtype</span> <span class="key">in</span> <span class="nam">zip</span><span class="op">(</span><span class="nam">input_shape</span><span class="op">,</span> <span class="nam">self</span><span class="op">.</span><span class="nam">_input_dtypes</span><span class="op">)</span><span class="op">]</span><span class="strut">&nbsp;</span></p>
<p id="t674" class="stm run hide_run">                    <span class="nam">x</span> <span class="op">=</span> <span class="nam">self</span><span class="op">.</span><span class="nam">call</span><span class="op">(</span><span class="nam">xs</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t675" class="pln">                <span class="key">else</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t676" class="stm run hide_run">                    <span class="nam">x</span> <span class="op">=</span> <span class="nam">K</span><span class="op">.</span><span class="nam">placeholder</span><span class="op">(</span><span class="nam">shape</span><span class="op">=</span><span class="nam">input_shape</span><span class="op">,</span> <span class="nam">dtype</span><span class="op">=</span><span class="nam">self</span><span class="op">.</span><span class="nam">_input_dtypes</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t677" class="stm run hide_run">                    <span class="nam">x</span> <span class="op">=</span> <span class="nam">self</span><span class="op">.</span><span class="nam">call</span><span class="op">(</span><span class="nam">x</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t678" class="stm run hide_run">                <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="nam">list</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t679" class="stm run hide_run">                    <span class="key">return</span> <span class="op">[</span><span class="nam">K</span><span class="op">.</span><span class="nam">int_shape</span><span class="op">(</span><span class="nam">x_elem</span><span class="op">)</span> <span class="key">for</span> <span class="nam">x_elem</span> <span class="key">in</span> <span class="nam">x</span><span class="op">]</span><span class="strut">&nbsp;</span></p>
<p id="t680" class="pln">                <span class="key">else</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t681" class="stm run hide_run">                    <span class="key">return</span> <span class="nam">K</span><span class="op">.</span><span class="nam">int_shape</span><span class="op">(</span><span class="nam">x</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t682" class="pln">            <span class="com"># Otherwise, we default to the input shape.</span><span class="strut">&nbsp;</span></p>
<p id="t683" class="stm mis">            <span class="nam">warnings</span><span class="op">.</span><span class="nam">warn</span><span class="op">(</span><span class="str">'`output_shape` argument not specified for layer {} '</span><span class="strut">&nbsp;</span></p>
<p id="t684" class="pln">                          <span class="str">'and cannot be automatically inferred '</span><span class="strut">&nbsp;</span></p>
<p id="t685" class="pln">                          <span class="str">'with the Theano backend. '</span><span class="strut">&nbsp;</span></p>
<p id="t686" class="pln">                          <span class="str">'Defaulting to output shape `{}` '</span><span class="strut">&nbsp;</span></p>
<p id="t687" class="pln">                          <span class="str">'(same as input shape). '</span><span class="strut">&nbsp;</span></p>
<p id="t688" class="pln">                          <span class="str">'If the expected output shape is different, '</span><span class="strut">&nbsp;</span></p>
<p id="t689" class="pln">                          <span class="str">'specify it via the `output_shape` argument.'</span><span class="strut">&nbsp;</span></p>
<p id="t690" class="pln">                          <span class="op">.</span><span class="nam">format</span><span class="op">(</span><span class="nam">self</span><span class="op">.</span><span class="nam">name</span><span class="op">,</span> <span class="nam">input_shape</span><span class="op">)</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t691" class="stm mis">            <span class="key">return</span> <span class="nam">input_shape</span><span class="strut">&nbsp;</span></p>
<p id="t692" class="stm run hide_run">        <span class="key">elif</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">self</span><span class="op">.</span><span class="nam">_output_shape</span><span class="op">,</span> <span class="op">(</span><span class="nam">tuple</span><span class="op">,</span> <span class="nam">list</span><span class="op">)</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t693" class="stm run hide_run">            <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">input_shape</span><span class="op">,</span> <span class="nam">list</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t694" class="stm run hide_run">                <span class="nam">num_samples</span> <span class="op">=</span> <span class="nam">input_shape</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="strut">&nbsp;</span></p>
<p id="t695" class="pln">            <span class="key">else</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t696" class="stm run hide_run">                <span class="nam">num_samples</span> <span class="op">=</span> <span class="nam">input_shape</span><span class="op">[</span><span class="num">0</span><span class="op">]</span> <span class="key">if</span> <span class="nam">input_shape</span> <span class="key">else</span> <span class="key">None</span><span class="strut">&nbsp;</span></p>
<p id="t697" class="stm run hide_run">            <span class="key">return</span> <span class="op">(</span><span class="nam">num_samples</span><span class="op">,</span><span class="op">)</span> <span class="op">+</span> <span class="nam">tuple</span><span class="op">(</span><span class="nam">self</span><span class="op">.</span><span class="nam">_output_shape</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t698" class="pln">        <span class="key">else</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t699" class="stm run hide_run">            <span class="nam">shape</span> <span class="op">=</span> <span class="nam">self</span><span class="op">.</span><span class="nam">_output_shape</span><span class="op">(</span><span class="nam">input_shape</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t700" class="stm run hide_run">            <span class="key">if</span> <span class="key">not</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">shape</span><span class="op">,</span> <span class="op">(</span><span class="nam">list</span><span class="op">,</span> <span class="nam">tuple</span><span class="op">)</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t701" class="stm mis">                <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">'`output_shape` function must return a tuple or '</span><span class="strut">&nbsp;</span></p>
<p id="t702" class="pln">                                 <span class="str">'a list of tuples.'</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t703" class="stm run hide_run">            <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">shape</span><span class="op">,</span> <span class="nam">list</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t704" class="stm run hide_run">                <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">shape</span><span class="op">[</span><span class="num">0</span><span class="op">]</span><span class="op">,</span> <span class="nam">int</span><span class="op">)</span> <span class="key">or</span> <span class="nam">shape</span><span class="op">[</span><span class="num">0</span><span class="op">]</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t705" class="stm run hide_run">                    <span class="nam">shape</span> <span class="op">=</span> <span class="nam">tuple</span><span class="op">(</span><span class="nam">shape</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t706" class="stm run hide_run">            <span class="key">return</span> <span class="nam">shape</span><span class="strut">&nbsp;</span></p>
<p id="t707" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t708" class="stm run hide_run">    <span class="key">def</span> <span class="nam">call</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">inputs</span><span class="op">,</span> <span class="nam">mask</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t709" class="stm run hide_run">        <span class="nam">arguments</span> <span class="op">=</span> <span class="nam">self</span><span class="op">.</span><span class="nam">arguments</span><span class="strut">&nbsp;</span></p>
<p id="t710" class="stm run hide_run">        <span class="key">if</span> <span class="nam">has_arg</span><span class="op">(</span><span class="nam">self</span><span class="op">.</span><span class="nam">function</span><span class="op">,</span> <span class="str">'mask'</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t711" class="stm mis">            <span class="nam">arguments</span><span class="op">[</span><span class="str">'mask'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">mask</span><span class="strut">&nbsp;</span></p>
<p id="t712" class="stm run hide_run">        <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">inputs</span><span class="op">,</span> <span class="nam">list</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t713" class="stm run hide_run">            <span class="nam">self</span><span class="op">.</span><span class="nam">_input_dtypes</span> <span class="op">=</span> <span class="op">[</span><span class="nam">K</span><span class="op">.</span><span class="nam">dtype</span><span class="op">(</span><span class="nam">x</span><span class="op">)</span> <span class="key">for</span> <span class="nam">x</span> <span class="key">in</span> <span class="nam">inputs</span><span class="op">]</span><span class="strut">&nbsp;</span></p>
<p id="t714" class="pln">        <span class="key">else</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t715" class="stm run hide_run">            <span class="nam">self</span><span class="op">.</span><span class="nam">_input_dtypes</span> <span class="op">=</span> <span class="nam">K</span><span class="op">.</span><span class="nam">dtype</span><span class="op">(</span><span class="nam">inputs</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t716" class="stm run hide_run">        <span class="key">return</span> <span class="nam">self</span><span class="op">.</span><span class="nam">function</span><span class="op">(</span><span class="nam">inputs</span><span class="op">,</span> <span class="op">**</span><span class="nam">arguments</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t717" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t718" class="stm run hide_run">    <span class="key">def</span> <span class="nam">compute_mask</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">inputs</span><span class="op">,</span> <span class="nam">mask</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t719" class="stm run hide_run">        <span class="key">if</span> <span class="nam">callable</span><span class="op">(</span><span class="nam">self</span><span class="op">.</span><span class="nam">mask</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t720" class="stm run hide_run">            <span class="key">return</span> <span class="nam">self</span><span class="op">.</span><span class="nam">mask</span><span class="op">(</span><span class="nam">inputs</span><span class="op">,</span> <span class="nam">mask</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t721" class="stm run hide_run">        <span class="key">return</span> <span class="nam">self</span><span class="op">.</span><span class="nam">mask</span><span class="strut">&nbsp;</span></p>
<p id="t722" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t723" class="stm run hide_run">    <span class="key">def</span> <span class="nam">get_config</span><span class="op">(</span><span class="nam">self</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t724" class="stm run hide_run">        <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">self</span><span class="op">.</span><span class="nam">function</span><span class="op">,</span> <span class="nam">python_types</span><span class="op">.</span><span class="nam">LambdaType</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t725" class="stm run hide_run">            <span class="nam">function</span> <span class="op">=</span> <span class="nam">func_dump</span><span class="op">(</span><span class="nam">self</span><span class="op">.</span><span class="nam">function</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t726" class="stm run hide_run">            <span class="nam">function_type</span> <span class="op">=</span> <span class="str">'lambda'</span><span class="strut">&nbsp;</span></p>
<p id="t727" class="pln">        <span class="key">else</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t728" class="stm mis">            <span class="nam">function</span> <span class="op">=</span> <span class="nam">self</span><span class="op">.</span><span class="nam">function</span><span class="op">.</span><span class="nam">__name__</span><span class="strut">&nbsp;</span></p>
<p id="t729" class="stm mis">            <span class="nam">function_type</span> <span class="op">=</span> <span class="str">'function'</span><span class="strut">&nbsp;</span></p>
<p id="t730" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t731" class="stm run hide_run">        <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">self</span><span class="op">.</span><span class="nam">_output_shape</span><span class="op">,</span> <span class="nam">python_types</span><span class="op">.</span><span class="nam">LambdaType</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t732" class="stm run hide_run">            <span class="nam">output_shape</span> <span class="op">=</span> <span class="nam">func_dump</span><span class="op">(</span><span class="nam">self</span><span class="op">.</span><span class="nam">_output_shape</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t733" class="stm run hide_run">            <span class="nam">output_shape_type</span> <span class="op">=</span> <span class="str">'lambda'</span><span class="strut">&nbsp;</span></p>
<p id="t734" class="stm run hide_run">        <span class="key">elif</span> <span class="nam">callable</span><span class="op">(</span><span class="nam">self</span><span class="op">.</span><span class="nam">_output_shape</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t735" class="stm mis">            <span class="nam">output_shape</span> <span class="op">=</span> <span class="nam">self</span><span class="op">.</span><span class="nam">_output_shape</span><span class="op">.</span><span class="nam">__name__</span><span class="strut">&nbsp;</span></p>
<p id="t736" class="stm mis">            <span class="nam">output_shape_type</span> <span class="op">=</span> <span class="str">'function'</span><span class="strut">&nbsp;</span></p>
<p id="t737" class="pln">        <span class="key">else</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t738" class="stm run hide_run">            <span class="nam">output_shape</span> <span class="op">=</span> <span class="nam">self</span><span class="op">.</span><span class="nam">_output_shape</span><span class="strut">&nbsp;</span></p>
<p id="t739" class="stm run hide_run">            <span class="nam">output_shape_type</span> <span class="op">=</span> <span class="str">'raw'</span><span class="strut">&nbsp;</span></p>
<p id="t740" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t741" class="stm run hide_run">        <span class="nam">config</span> <span class="op">=</span> <span class="op">{</span><span class="str">'function'</span><span class="op">:</span> <span class="nam">function</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t742" class="pln">                  <span class="str">'function_type'</span><span class="op">:</span> <span class="nam">function_type</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t743" class="pln">                  <span class="str">'output_shape'</span><span class="op">:</span> <span class="nam">output_shape</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t744" class="pln">                  <span class="str">'output_shape_type'</span><span class="op">:</span> <span class="nam">output_shape_type</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t745" class="pln">                  <span class="str">'arguments'</span><span class="op">:</span> <span class="nam">self</span><span class="op">.</span><span class="nam">arguments</span><span class="op">}</span><span class="strut">&nbsp;</span></p>
<p id="t746" class="stm run hide_run">        <span class="nam">base_config</span> <span class="op">=</span> <span class="nam">super</span><span class="op">(</span><span class="nam">Lambda</span><span class="op">,</span> <span class="nam">self</span><span class="op">)</span><span class="op">.</span><span class="nam">get_config</span><span class="op">(</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t747" class="stm run hide_run">        <span class="key">return</span> <span class="nam">dict</span><span class="op">(</span><span class="nam">list</span><span class="op">(</span><span class="nam">base_config</span><span class="op">.</span><span class="nam">items</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> <span class="nam">list</span><span class="op">(</span><span class="nam">config</span><span class="op">.</span><span class="nam">items</span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t748" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t749" class="stm run hide_run">    <span class="op">@</span><span class="nam">classmethod</span><span class="strut">&nbsp;</span></p>
<p id="t750" class="stm run hide_run">    <span class="key">def</span> <span class="nam">from_config</span><span class="op">(</span><span class="nam">cls</span><span class="op">,</span> <span class="nam">config</span><span class="op">,</span> <span class="nam">custom_objects</span><span class="op">=</span><span class="key">None</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t751" class="stm run hide_run">        <span class="nam">config</span> <span class="op">=</span> <span class="nam">config</span><span class="op">.</span><span class="nam">copy</span><span class="op">(</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t752" class="stm run hide_run">        <span class="nam">globs</span> <span class="op">=</span> <span class="nam">globals</span><span class="op">(</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t753" class="stm run hide_run">        <span class="key">if</span> <span class="nam">custom_objects</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t754" class="stm run hide_run">            <span class="nam">globs</span> <span class="op">=</span> <span class="nam">dict</span><span class="op">(</span><span class="nam">list</span><span class="op">(</span><span class="nam">globs</span><span class="op">.</span><span class="nam">items</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> <span class="nam">list</span><span class="op">(</span><span class="nam">custom_objects</span><span class="op">.</span><span class="nam">items</span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t755" class="stm run hide_run">        <span class="nam">function_type</span> <span class="op">=</span> <span class="nam">config</span><span class="op">.</span><span class="nam">pop</span><span class="op">(</span><span class="str">'function_type'</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t756" class="stm run hide_run">        <span class="key">if</span> <span class="nam">function_type</span> <span class="op">==</span> <span class="str">'function'</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t757" class="pln">            <span class="com"># Simple lookup in custom objects</span><span class="strut">&nbsp;</span></p>
<p id="t758" class="stm mis">            <span class="nam">function</span> <span class="op">=</span> <span class="nam">deserialize_keras_object</span><span class="op">(</span><span class="strut">&nbsp;</span></p>
<p id="t759" class="pln">                <span class="nam">config</span><span class="op">[</span><span class="str">'function'</span><span class="op">]</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t760" class="pln">                <span class="nam">custom_objects</span><span class="op">=</span><span class="nam">custom_objects</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t761" class="pln">                <span class="nam">printable_module_name</span><span class="op">=</span><span class="str">'function in Lambda layer'</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t762" class="stm run hide_run">        <span class="key">elif</span> <span class="nam">function_type</span> <span class="op">==</span> <span class="str">'lambda'</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t763" class="pln">            <span class="com"># Unsafe deserialization from bytecode</span><span class="strut">&nbsp;</span></p>
<p id="t764" class="stm run hide_run">            <span class="nam">function</span> <span class="op">=</span> <span class="nam">func_load</span><span class="op">(</span><span class="nam">config</span><span class="op">[</span><span class="str">'function'</span><span class="op">]</span><span class="op">,</span> <span class="nam">globs</span><span class="op">=</span><span class="nam">globs</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t765" class="pln">        <span class="key">else</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t766" class="stm mis">            <span class="key">raise</span> <span class="nam">TypeError</span><span class="op">(</span><span class="str">'Unknown function type:'</span><span class="op">,</span> <span class="nam">function_type</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t767" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t768" class="stm run hide_run">        <span class="nam">output_shape_type</span> <span class="op">=</span> <span class="nam">config</span><span class="op">.</span><span class="nam">pop</span><span class="op">(</span><span class="str">'output_shape_type'</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t769" class="stm run hide_run">        <span class="key">if</span> <span class="nam">output_shape_type</span> <span class="op">==</span> <span class="str">'function'</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t770" class="pln">            <span class="com"># Simple lookup in custom objects</span><span class="strut">&nbsp;</span></p>
<p id="t771" class="stm mis">            <span class="nam">output_shape</span> <span class="op">=</span> <span class="nam">deserialize_keras_object</span><span class="op">(</span><span class="strut">&nbsp;</span></p>
<p id="t772" class="pln">                <span class="nam">config</span><span class="op">[</span><span class="str">'output_shape'</span><span class="op">]</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t773" class="pln">                <span class="nam">custom_objects</span><span class="op">=</span><span class="nam">custom_objects</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t774" class="pln">                <span class="nam">printable_module_name</span><span class="op">=</span><span class="str">'output_shape function in Lambda layer'</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t775" class="stm run hide_run">        <span class="key">elif</span> <span class="nam">output_shape_type</span> <span class="op">==</span> <span class="str">'lambda'</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t776" class="pln">            <span class="com"># Unsafe deserialization from bytecode</span><span class="strut">&nbsp;</span></p>
<p id="t777" class="stm run hide_run">            <span class="nam">output_shape</span> <span class="op">=</span> <span class="nam">func_load</span><span class="op">(</span><span class="nam">config</span><span class="op">[</span><span class="str">'output_shape'</span><span class="op">]</span><span class="op">,</span> <span class="nam">globs</span><span class="op">=</span><span class="nam">globs</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t778" class="pln">        <span class="key">else</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t779" class="stm run hide_run">            <span class="nam">output_shape</span> <span class="op">=</span> <span class="nam">config</span><span class="op">[</span><span class="str">'output_shape'</span><span class="op">]</span><span class="strut">&nbsp;</span></p>
<p id="t780" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t781" class="pln">        <span class="com"># If arguments were numpy array, they have been saved as</span><span class="strut">&nbsp;</span></p>
<p id="t782" class="pln">        <span class="com"># list. We need to recover the ndarray</span><span class="strut">&nbsp;</span></p>
<p id="t783" class="stm run hide_run">        <span class="key">if</span> <span class="str">'arguments'</span> <span class="key">in</span> <span class="nam">config</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t784" class="stm run hide_run">            <span class="key">for</span> <span class="nam">key</span> <span class="key">in</span> <span class="nam">config</span><span class="op">[</span><span class="str">'arguments'</span><span class="op">]</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t785" class="stm run hide_run">                <span class="key">if</span> <span class="nam">isinstance</span><span class="op">(</span><span class="nam">config</span><span class="op">[</span><span class="str">'arguments'</span><span class="op">]</span><span class="op">[</span><span class="nam">key</span><span class="op">]</span><span class="op">,</span> <span class="nam">dict</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t786" class="stm mis">                    <span class="nam">arg_dict</span> <span class="op">=</span> <span class="nam">config</span><span class="op">[</span><span class="str">'arguments'</span><span class="op">]</span><span class="op">[</span><span class="nam">key</span><span class="op">]</span><span class="strut">&nbsp;</span></p>
<p id="t787" class="stm mis">                    <span class="key">if</span> <span class="str">'type'</span> <span class="key">in</span> <span class="nam">arg_dict</span> <span class="key">and</span> <span class="nam">arg_dict</span><span class="op">[</span><span class="str">'type'</span><span class="op">]</span> <span class="op">==</span> <span class="str">'ndarray'</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t788" class="pln">                        <span class="com"># Overwrite the argument with its numpy translation</span><span class="strut">&nbsp;</span></p>
<p id="t789" class="stm mis">                        <span class="nam">config</span><span class="op">[</span><span class="str">'arguments'</span><span class="op">]</span><span class="op">[</span><span class="nam">key</span><span class="op">]</span> <span class="op">=</span> <span class="nam">np</span><span class="op">.</span><span class="nam">array</span><span class="op">(</span><span class="nam">arg_dict</span><span class="op">[</span><span class="str">'value'</span><span class="op">]</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t790" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t791" class="stm run hide_run">        <span class="nam">config</span><span class="op">[</span><span class="str">'function'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">function</span><span class="strut">&nbsp;</span></p>
<p id="t792" class="stm run hide_run">        <span class="nam">config</span><span class="op">[</span><span class="str">'output_shape'</span><span class="op">]</span> <span class="op">=</span> <span class="nam">output_shape</span><span class="strut">&nbsp;</span></p>
<p id="t793" class="stm run hide_run">        <span class="key">return</span> <span class="nam">cls</span><span class="op">(</span><span class="op">**</span><span class="nam">config</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t794" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t795" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t796" class="stm run hide_run"><span class="key">class</span> <span class="nam">Dense</span><span class="op">(</span><span class="nam">Layer</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t797" class="pln">    <span class="str">"""Just your regular densely-connected NN layer.</span><span class="strut">&nbsp;</span></p>
<p id="t798" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t799" class="pln"><span class="str">    `Dense` implements the operation:</span><span class="strut">&nbsp;</span></p>
<p id="t800" class="pln"><span class="str">    `output = activation(dot(input, kernel) + bias)`</span><span class="strut">&nbsp;</span></p>
<p id="t801" class="pln"><span class="str">    where `activation` is the element-wise activation function</span><span class="strut">&nbsp;</span></p>
<p id="t802" class="pln"><span class="str">    passed as the `activation` argument, `kernel` is a weights matrix</span><span class="strut">&nbsp;</span></p>
<p id="t803" class="pln"><span class="str">    created by the layer, and `bias` is a bias vector created by the layer</span><span class="strut">&nbsp;</span></p>
<p id="t804" class="pln"><span class="str">    (only applicable if `use_bias` is `True`).</span><span class="strut">&nbsp;</span></p>
<p id="t805" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t806" class="pln"><span class="str">    Note: if the input to the layer has a rank greater than 2, then</span><span class="strut">&nbsp;</span></p>
<p id="t807" class="pln"><span class="str">    it is flattened prior to the initial dot product with `kernel`.</span><span class="strut">&nbsp;</span></p>
<p id="t808" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t809" class="pln"><span class="str">    # Example</span><span class="strut">&nbsp;</span></p>
<p id="t810" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t811" class="pln"><span class="str">    ```python</span><span class="strut">&nbsp;</span></p>
<p id="t812" class="pln"><span class="str">        # as first layer in a sequential model:</span><span class="strut">&nbsp;</span></p>
<p id="t813" class="pln"><span class="str">        model = Sequential()</span><span class="strut">&nbsp;</span></p>
<p id="t814" class="pln"><span class="str">        model.add(Dense(32, input_shape=(16,)))</span><span class="strut">&nbsp;</span></p>
<p id="t815" class="pln"><span class="str">        # now the model will take as input arrays of shape (*, 16)</span><span class="strut">&nbsp;</span></p>
<p id="t816" class="pln"><span class="str">        # and output arrays of shape (*, 32)</span><span class="strut">&nbsp;</span></p>
<p id="t817" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t818" class="pln"><span class="str">        # after the first layer, you don't need to specify</span><span class="strut">&nbsp;</span></p>
<p id="t819" class="pln"><span class="str">        # the size of the input anymore:</span><span class="strut">&nbsp;</span></p>
<p id="t820" class="pln"><span class="str">        model.add(Dense(32))</span><span class="strut">&nbsp;</span></p>
<p id="t821" class="pln"><span class="str">    ```</span><span class="strut">&nbsp;</span></p>
<p id="t822" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t823" class="pln"><span class="str">    # Arguments</span><span class="strut">&nbsp;</span></p>
<p id="t824" class="pln"><span class="str">        units: Positive integer, dimensionality of the output space.</span><span class="strut">&nbsp;</span></p>
<p id="t825" class="pln"><span class="str">        activation: Activation function to use</span><span class="strut">&nbsp;</span></p>
<p id="t826" class="pln"><span class="str">            (see [activations](../activations.md)).</span><span class="strut">&nbsp;</span></p>
<p id="t827" class="pln"><span class="str">            If you don't specify anything, no activation is applied</span><span class="strut">&nbsp;</span></p>
<p id="t828" class="pln"><span class="str">            (ie. "linear" activation: `a(x) = x`).</span><span class="strut">&nbsp;</span></p>
<p id="t829" class="pln"><span class="str">        use_bias: Boolean, whether the layer uses a bias vector.</span><span class="strut">&nbsp;</span></p>
<p id="t830" class="pln"><span class="str">        kernel_initializer: Initializer for the `kernel` weights matrix</span><span class="strut">&nbsp;</span></p>
<p id="t831" class="pln"><span class="str">            (see [initializers](../initializers.md)).</span><span class="strut">&nbsp;</span></p>
<p id="t832" class="pln"><span class="str">        bias_initializer: Initializer for the bias vector</span><span class="strut">&nbsp;</span></p>
<p id="t833" class="pln"><span class="str">            (see [initializers](../initializers.md)).</span><span class="strut">&nbsp;</span></p>
<p id="t834" class="pln"><span class="str">        kernel_regularizer: Regularizer function applied to</span><span class="strut">&nbsp;</span></p>
<p id="t835" class="pln"><span class="str">            the `kernel` weights matrix</span><span class="strut">&nbsp;</span></p>
<p id="t836" class="pln"><span class="str">            (see [regularizer](../regularizers.md)).</span><span class="strut">&nbsp;</span></p>
<p id="t837" class="pln"><span class="str">        bias_regularizer: Regularizer function applied to the bias vector</span><span class="strut">&nbsp;</span></p>
<p id="t838" class="pln"><span class="str">            (see [regularizer](../regularizers.md)).</span><span class="strut">&nbsp;</span></p>
<p id="t839" class="pln"><span class="str">        activity_regularizer: Regularizer function applied to</span><span class="strut">&nbsp;</span></p>
<p id="t840" class="pln"><span class="str">            the output of the layer (its "activation").</span><span class="strut">&nbsp;</span></p>
<p id="t841" class="pln"><span class="str">            (see [regularizer](../regularizers.md)).</span><span class="strut">&nbsp;</span></p>
<p id="t842" class="pln"><span class="str">        kernel_constraint: Constraint function applied to</span><span class="strut">&nbsp;</span></p>
<p id="t843" class="pln"><span class="str">            the `kernel` weights matrix</span><span class="strut">&nbsp;</span></p>
<p id="t844" class="pln"><span class="str">            (see [constraints](../constraints.md)).</span><span class="strut">&nbsp;</span></p>
<p id="t845" class="pln"><span class="str">        bias_constraint: Constraint function applied to the bias vector</span><span class="strut">&nbsp;</span></p>
<p id="t846" class="pln"><span class="str">            (see [constraints](../constraints.md)).</span><span class="strut">&nbsp;</span></p>
<p id="t847" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t848" class="pln"><span class="str">    # Input shape</span><span class="strut">&nbsp;</span></p>
<p id="t849" class="pln"><span class="str">        nD tensor with shape: `(batch_size, ..., input_dim)`.</span><span class="strut">&nbsp;</span></p>
<p id="t850" class="pln"><span class="str">        The most common situation would be</span><span class="strut">&nbsp;</span></p>
<p id="t851" class="pln"><span class="str">        a 2D input with shape `(batch_size, input_dim)`.</span><span class="strut">&nbsp;</span></p>
<p id="t852" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t853" class="pln"><span class="str">    # Output shape</span><span class="strut">&nbsp;</span></p>
<p id="t854" class="pln"><span class="str">        nD tensor with shape: `(batch_size, ..., units)`.</span><span class="strut">&nbsp;</span></p>
<p id="t855" class="pln"><span class="str">        For instance, for a 2D input with shape `(batch_size, input_dim)`,</span><span class="strut">&nbsp;</span></p>
<p id="t856" class="pln"><span class="str">        the output would have shape `(batch_size, units)`.</span><span class="strut">&nbsp;</span></p>
<p id="t857" class="pln"><span class="str">    """</span><span class="strut">&nbsp;</span></p>
<p id="t858" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t859" class="stm run hide_run">    <span class="op">@</span><span class="nam">interfaces</span><span class="op">.</span><span class="nam">legacy_dense_support</span><span class="strut">&nbsp;</span></p>
<p id="t860" class="stm run hide_run">    <span class="key">def</span> <span class="nam">__init__</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">units</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t861" class="pln">                 <span class="nam">activation</span><span class="op">=</span><span class="key">None</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t862" class="pln">                 <span class="nam">use_bias</span><span class="op">=</span><span class="key">True</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t863" class="pln">                 <span class="nam">kernel_initializer</span><span class="op">=</span><span class="str">'glorot_uniform'</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t864" class="pln">                 <span class="nam">bias_initializer</span><span class="op">=</span><span class="str">'zeros'</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t865" class="pln">                 <span class="nam">kernel_regularizer</span><span class="op">=</span><span class="key">None</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t866" class="pln">                 <span class="nam">bias_regularizer</span><span class="op">=</span><span class="key">None</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t867" class="pln">                 <span class="nam">activity_regularizer</span><span class="op">=</span><span class="key">None</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t868" class="pln">                 <span class="nam">kernel_constraint</span><span class="op">=</span><span class="key">None</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t869" class="pln">                 <span class="nam">bias_constraint</span><span class="op">=</span><span class="key">None</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t870" class="pln">                 <span class="op">**</span><span class="nam">kwargs</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t871" class="stm run hide_run">        <span class="key">if</span> <span class="str">'input_shape'</span> <span class="key">not</span> <span class="key">in</span> <span class="nam">kwargs</span> <span class="key">and</span> <span class="str">'input_dim'</span> <span class="key">in</span> <span class="nam">kwargs</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t872" class="stm run hide_run">            <span class="nam">kwargs</span><span class="op">[</span><span class="str">'input_shape'</span><span class="op">]</span> <span class="op">=</span> <span class="op">(</span><span class="nam">kwargs</span><span class="op">.</span><span class="nam">pop</span><span class="op">(</span><span class="str">'input_dim'</span><span class="op">)</span><span class="op">,</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t873" class="stm run hide_run">        <span class="nam">super</span><span class="op">(</span><span class="nam">Dense</span><span class="op">,</span> <span class="nam">self</span><span class="op">)</span><span class="op">.</span><span class="nam">__init__</span><span class="op">(</span><span class="op">**</span><span class="nam">kwargs</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t874" class="stm run hide_run">        <span class="nam">self</span><span class="op">.</span><span class="nam">units</span> <span class="op">=</span> <span class="nam">units</span><span class="strut">&nbsp;</span></p>
<p id="t875" class="stm run hide_run">        <span class="nam">self</span><span class="op">.</span><span class="nam">activation</span> <span class="op">=</span> <span class="nam">activations</span><span class="op">.</span><span class="nam">get</span><span class="op">(</span><span class="nam">activation</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t876" class="stm run hide_run">        <span class="nam">self</span><span class="op">.</span><span class="nam">use_bias</span> <span class="op">=</span> <span class="nam">use_bias</span><span class="strut">&nbsp;</span></p>
<p id="t877" class="stm run hide_run">        <span class="nam">self</span><span class="op">.</span><span class="nam">kernel_initializer</span> <span class="op">=</span> <span class="nam">initializers</span><span class="op">.</span><span class="nam">get</span><span class="op">(</span><span class="nam">kernel_initializer</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t878" class="stm run hide_run">        <span class="nam">self</span><span class="op">.</span><span class="nam">bias_initializer</span> <span class="op">=</span> <span class="nam">initializers</span><span class="op">.</span><span class="nam">get</span><span class="op">(</span><span class="nam">bias_initializer</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t879" class="stm run hide_run">        <span class="nam">self</span><span class="op">.</span><span class="nam">kernel_regularizer</span> <span class="op">=</span> <span class="nam">regularizers</span><span class="op">.</span><span class="nam">get</span><span class="op">(</span><span class="nam">kernel_regularizer</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t880" class="stm run hide_run">        <span class="nam">self</span><span class="op">.</span><span class="nam">bias_regularizer</span> <span class="op">=</span> <span class="nam">regularizers</span><span class="op">.</span><span class="nam">get</span><span class="op">(</span><span class="nam">bias_regularizer</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t881" class="stm run hide_run">        <span class="nam">self</span><span class="op">.</span><span class="nam">activity_regularizer</span> <span class="op">=</span> <span class="nam">regularizers</span><span class="op">.</span><span class="nam">get</span><span class="op">(</span><span class="nam">activity_regularizer</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t882" class="stm run hide_run">        <span class="nam">self</span><span class="op">.</span><span class="nam">kernel_constraint</span> <span class="op">=</span> <span class="nam">constraints</span><span class="op">.</span><span class="nam">get</span><span class="op">(</span><span class="nam">kernel_constraint</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t883" class="stm run hide_run">        <span class="nam">self</span><span class="op">.</span><span class="nam">bias_constraint</span> <span class="op">=</span> <span class="nam">constraints</span><span class="op">.</span><span class="nam">get</span><span class="op">(</span><span class="nam">bias_constraint</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t884" class="stm run hide_run">        <span class="nam">self</span><span class="op">.</span><span class="nam">input_spec</span> <span class="op">=</span> <span class="nam">InputSpec</span><span class="op">(</span><span class="nam">min_ndim</span><span class="op">=</span><span class="num">2</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t885" class="stm run hide_run">        <span class="nam">self</span><span class="op">.</span><span class="nam">supports_masking</span> <span class="op">=</span> <span class="key">True</span><span class="strut">&nbsp;</span></p>
<p id="t886" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t887" class="stm run hide_run">    <span class="key">def</span> <span class="nam">build</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">input_shape</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t888" class="stm run hide_run">        <span class="key">assert</span> <span class="nam">len</span><span class="op">(</span><span class="nam">input_shape</span><span class="op">)</span> <span class="op">>=</span> <span class="num">2</span><span class="strut">&nbsp;</span></p>
<p id="t889" class="stm run hide_run">        <span class="nam">input_dim</span> <span class="op">=</span> <span class="nam">input_shape</span><span class="op">[</span><span class="op">-</span><span class="num">1</span><span class="op">]</span><span class="strut">&nbsp;</span></p>
<p id="t890" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t891" class="stm run hide_run">        <span class="nam">self</span><span class="op">.</span><span class="nam">kernel</span> <span class="op">=</span> <span class="nam">self</span><span class="op">.</span><span class="nam">add_weight</span><span class="op">(</span><span class="nam">shape</span><span class="op">=</span><span class="op">(</span><span class="nam">input_dim</span><span class="op">,</span> <span class="nam">self</span><span class="op">.</span><span class="nam">units</span><span class="op">)</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t892" class="pln">                                      <span class="nam">initializer</span><span class="op">=</span><span class="nam">self</span><span class="op">.</span><span class="nam">kernel_initializer</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t893" class="pln">                                      <span class="nam">name</span><span class="op">=</span><span class="str">'kernel'</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t894" class="pln">                                      <span class="nam">regularizer</span><span class="op">=</span><span class="nam">self</span><span class="op">.</span><span class="nam">kernel_regularizer</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t895" class="pln">                                      <span class="nam">constraint</span><span class="op">=</span><span class="nam">self</span><span class="op">.</span><span class="nam">kernel_constraint</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t896" class="stm run hide_run">        <span class="key">if</span> <span class="nam">self</span><span class="op">.</span><span class="nam">use_bias</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t897" class="stm run hide_run">            <span class="nam">self</span><span class="op">.</span><span class="nam">bias</span> <span class="op">=</span> <span class="nam">self</span><span class="op">.</span><span class="nam">add_weight</span><span class="op">(</span><span class="nam">shape</span><span class="op">=</span><span class="op">(</span><span class="nam">self</span><span class="op">.</span><span class="nam">units</span><span class="op">,</span><span class="op">)</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t898" class="pln">                                        <span class="nam">initializer</span><span class="op">=</span><span class="nam">self</span><span class="op">.</span><span class="nam">bias_initializer</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t899" class="pln">                                        <span class="nam">name</span><span class="op">=</span><span class="str">'bias'</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t900" class="pln">                                        <span class="nam">regularizer</span><span class="op">=</span><span class="nam">self</span><span class="op">.</span><span class="nam">bias_regularizer</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t901" class="pln">                                        <span class="nam">constraint</span><span class="op">=</span><span class="nam">self</span><span class="op">.</span><span class="nam">bias_constraint</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t902" class="pln">        <span class="key">else</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t903" class="stm run hide_run">            <span class="nam">self</span><span class="op">.</span><span class="nam">bias</span> <span class="op">=</span> <span class="key">None</span><span class="strut">&nbsp;</span></p>
<p id="t904" class="stm run hide_run">        <span class="nam">self</span><span class="op">.</span><span class="nam">input_spec</span> <span class="op">=</span> <span class="nam">InputSpec</span><span class="op">(</span><span class="nam">min_ndim</span><span class="op">=</span><span class="num">2</span><span class="op">,</span> <span class="nam">axes</span><span class="op">=</span><span class="op">{</span><span class="op">-</span><span class="num">1</span><span class="op">:</span> <span class="nam">input_dim</span><span class="op">}</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t905" class="stm run hide_run">        <span class="nam">self</span><span class="op">.</span><span class="nam">built</span> <span class="op">=</span> <span class="key">True</span><span class="strut">&nbsp;</span></p>
<p id="t906" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t907" class="stm run hide_run">    <span class="key">def</span> <span class="nam">call</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">inputs</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t908" class="stm run hide_run">        <span class="nam">output</span> <span class="op">=</span> <span class="nam">K</span><span class="op">.</span><span class="nam">dot</span><span class="op">(</span><span class="nam">inputs</span><span class="op">,</span> <span class="nam">self</span><span class="op">.</span><span class="nam">kernel</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t909" class="stm run hide_run">        <span class="key">if</span> <span class="nam">self</span><span class="op">.</span><span class="nam">use_bias</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t910" class="stm run hide_run">            <span class="nam">output</span> <span class="op">=</span> <span class="nam">K</span><span class="op">.</span><span class="nam">bias_add</span><span class="op">(</span><span class="nam">output</span><span class="op">,</span> <span class="nam">self</span><span class="op">.</span><span class="nam">bias</span><span class="op">,</span> <span class="nam">data_format</span><span class="op">=</span><span class="str">'channels_last'</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t911" class="stm run hide_run">        <span class="key">if</span> <span class="nam">self</span><span class="op">.</span><span class="nam">activation</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t912" class="stm run hide_run">            <span class="nam">output</span> <span class="op">=</span> <span class="nam">self</span><span class="op">.</span><span class="nam">activation</span><span class="op">(</span><span class="nam">output</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t913" class="stm run hide_run">        <span class="key">return</span> <span class="nam">output</span><span class="strut">&nbsp;</span></p>
<p id="t914" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t915" class="stm run hide_run">    <span class="key">def</span> <span class="nam">compute_output_shape</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">input_shape</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t916" class="stm run hide_run">        <span class="key">assert</span> <span class="nam">input_shape</span> <span class="key">and</span> <span class="nam">len</span><span class="op">(</span><span class="nam">input_shape</span><span class="op">)</span> <span class="op">>=</span> <span class="num">2</span><span class="strut">&nbsp;</span></p>
<p id="t917" class="stm run hide_run">        <span class="key">assert</span> <span class="nam">input_shape</span><span class="op">[</span><span class="op">-</span><span class="num">1</span><span class="op">]</span><span class="strut">&nbsp;</span></p>
<p id="t918" class="stm run hide_run">        <span class="nam">output_shape</span> <span class="op">=</span> <span class="nam">list</span><span class="op">(</span><span class="nam">input_shape</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t919" class="stm run hide_run">        <span class="nam">output_shape</span><span class="op">[</span><span class="op">-</span><span class="num">1</span><span class="op">]</span> <span class="op">=</span> <span class="nam">self</span><span class="op">.</span><span class="nam">units</span><span class="strut">&nbsp;</span></p>
<p id="t920" class="stm run hide_run">        <span class="key">return</span> <span class="nam">tuple</span><span class="op">(</span><span class="nam">output_shape</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t921" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t922" class="stm run hide_run">    <span class="key">def</span> <span class="nam">get_config</span><span class="op">(</span><span class="nam">self</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t923" class="stm run hide_run">        <span class="nam">config</span> <span class="op">=</span> <span class="op">{</span><span class="strut">&nbsp;</span></p>
<p id="t924" class="pln">            <span class="str">'units'</span><span class="op">:</span> <span class="nam">self</span><span class="op">.</span><span class="nam">units</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t925" class="pln">            <span class="str">'activation'</span><span class="op">:</span> <span class="nam">activations</span><span class="op">.</span><span class="nam">serialize</span><span class="op">(</span><span class="nam">self</span><span class="op">.</span><span class="nam">activation</span><span class="op">)</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t926" class="pln">            <span class="str">'use_bias'</span><span class="op">:</span> <span class="nam">self</span><span class="op">.</span><span class="nam">use_bias</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t927" class="pln">            <span class="str">'kernel_initializer'</span><span class="op">:</span> <span class="nam">initializers</span><span class="op">.</span><span class="nam">serialize</span><span class="op">(</span><span class="nam">self</span><span class="op">.</span><span class="nam">kernel_initializer</span><span class="op">)</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t928" class="pln">            <span class="str">'bias_initializer'</span><span class="op">:</span> <span class="nam">initializers</span><span class="op">.</span><span class="nam">serialize</span><span class="op">(</span><span class="nam">self</span><span class="op">.</span><span class="nam">bias_initializer</span><span class="op">)</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t929" class="pln">            <span class="str">'kernel_regularizer'</span><span class="op">:</span> <span class="nam">regularizers</span><span class="op">.</span><span class="nam">serialize</span><span class="op">(</span><span class="nam">self</span><span class="op">.</span><span class="nam">kernel_regularizer</span><span class="op">)</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t930" class="pln">            <span class="str">'bias_regularizer'</span><span class="op">:</span> <span class="nam">regularizers</span><span class="op">.</span><span class="nam">serialize</span><span class="op">(</span><span class="nam">self</span><span class="op">.</span><span class="nam">bias_regularizer</span><span class="op">)</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t931" class="pln">            <span class="str">'activity_regularizer'</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t932" class="pln">                <span class="nam">regularizers</span><span class="op">.</span><span class="nam">serialize</span><span class="op">(</span><span class="nam">self</span><span class="op">.</span><span class="nam">activity_regularizer</span><span class="op">)</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t933" class="pln">            <span class="str">'kernel_constraint'</span><span class="op">:</span> <span class="nam">constraints</span><span class="op">.</span><span class="nam">serialize</span><span class="op">(</span><span class="nam">self</span><span class="op">.</span><span class="nam">kernel_constraint</span><span class="op">)</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t934" class="pln">            <span class="str">'bias_constraint'</span><span class="op">:</span> <span class="nam">constraints</span><span class="op">.</span><span class="nam">serialize</span><span class="op">(</span><span class="nam">self</span><span class="op">.</span><span class="nam">bias_constraint</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t935" class="pln">        <span class="op">}</span><span class="strut">&nbsp;</span></p>
<p id="t936" class="stm run hide_run">        <span class="nam">base_config</span> <span class="op">=</span> <span class="nam">super</span><span class="op">(</span><span class="nam">Dense</span><span class="op">,</span> <span class="nam">self</span><span class="op">)</span><span class="op">.</span><span class="nam">get_config</span><span class="op">(</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t937" class="stm run hide_run">        <span class="key">return</span> <span class="nam">dict</span><span class="op">(</span><span class="nam">list</span><span class="op">(</span><span class="nam">base_config</span><span class="op">.</span><span class="nam">items</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> <span class="nam">list</span><span class="op">(</span><span class="nam">config</span><span class="op">.</span><span class="nam">items</span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t938" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t939" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t940" class="stm run hide_run"><span class="key">class</span> <span class="nam">ActivityRegularization</span><span class="op">(</span><span class="nam">Layer</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t941" class="pln">    <span class="str">"""Layer that applies an update to the cost function based input activity.</span><span class="strut">&nbsp;</span></p>
<p id="t942" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t943" class="pln"><span class="str">    # Arguments</span><span class="strut">&nbsp;</span></p>
<p id="t944" class="pln"><span class="str">        l1: L1 regularization factor (positive float).</span><span class="strut">&nbsp;</span></p>
<p id="t945" class="pln"><span class="str">        l2: L2 regularization factor (positive float).</span><span class="strut">&nbsp;</span></p>
<p id="t946" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t947" class="pln"><span class="str">    # Input shape</span><span class="strut">&nbsp;</span></p>
<p id="t948" class="pln"><span class="str">        Arbitrary. Use the keyword argument `input_shape`</span><span class="strut">&nbsp;</span></p>
<p id="t949" class="pln"><span class="str">        (tuple of integers, does not include the samples axis)</span><span class="strut">&nbsp;</span></p>
<p id="t950" class="pln"><span class="str">        when using this layer as the first layer in a model.</span><span class="strut">&nbsp;</span></p>
<p id="t951" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t952" class="pln"><span class="str">    # Output shape</span><span class="strut">&nbsp;</span></p>
<p id="t953" class="pln"><span class="str">        Same shape as input.</span><span class="strut">&nbsp;</span></p>
<p id="t954" class="pln"><span class="str">    """</span><span class="strut">&nbsp;</span></p>
<p id="t955" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t956" class="stm run hide_run">    <span class="key">def</span> <span class="nam">__init__</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">l1</span><span class="op">=</span><span class="num">0.</span><span class="op">,</span> <span class="nam">l2</span><span class="op">=</span><span class="num">0.</span><span class="op">,</span> <span class="op">**</span><span class="nam">kwargs</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t957" class="stm run hide_run">        <span class="nam">super</span><span class="op">(</span><span class="nam">ActivityRegularization</span><span class="op">,</span> <span class="nam">self</span><span class="op">)</span><span class="op">.</span><span class="nam">__init__</span><span class="op">(</span><span class="op">**</span><span class="nam">kwargs</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t958" class="stm run hide_run">        <span class="nam">self</span><span class="op">.</span><span class="nam">supports_masking</span> <span class="op">=</span> <span class="key">True</span><span class="strut">&nbsp;</span></p>
<p id="t959" class="stm run hide_run">        <span class="nam">self</span><span class="op">.</span><span class="nam">l1</span> <span class="op">=</span> <span class="nam">l1</span><span class="strut">&nbsp;</span></p>
<p id="t960" class="stm run hide_run">        <span class="nam">self</span><span class="op">.</span><span class="nam">l2</span> <span class="op">=</span> <span class="nam">l2</span><span class="strut">&nbsp;</span></p>
<p id="t961" class="stm run hide_run">        <span class="nam">self</span><span class="op">.</span><span class="nam">activity_regularizer</span> <span class="op">=</span> <span class="nam">regularizers</span><span class="op">.</span><span class="nam">L1L2</span><span class="op">(</span><span class="nam">l1</span><span class="op">=</span><span class="nam">l1</span><span class="op">,</span> <span class="nam">l2</span><span class="op">=</span><span class="nam">l2</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t962" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t963" class="stm run hide_run">    <span class="key">def</span> <span class="nam">get_config</span><span class="op">(</span><span class="nam">self</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t964" class="stm run hide_run">        <span class="nam">config</span> <span class="op">=</span> <span class="op">{</span><span class="str">'l1'</span><span class="op">:</span> <span class="nam">self</span><span class="op">.</span><span class="nam">l1</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t965" class="pln">                  <span class="str">'l2'</span><span class="op">:</span> <span class="nam">self</span><span class="op">.</span><span class="nam">l2</span><span class="op">}</span><span class="strut">&nbsp;</span></p>
<p id="t966" class="stm run hide_run">        <span class="nam">base_config</span> <span class="op">=</span> <span class="nam">super</span><span class="op">(</span><span class="nam">ActivityRegularization</span><span class="op">,</span> <span class="nam">self</span><span class="op">)</span><span class="op">.</span><span class="nam">get_config</span><span class="op">(</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t967" class="stm run hide_run">        <span class="key">return</span> <span class="nam">dict</span><span class="op">(</span><span class="nam">list</span><span class="op">(</span><span class="nam">base_config</span><span class="op">.</span><span class="nam">items</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> <span class="nam">list</span><span class="op">(</span><span class="nam">config</span><span class="op">.</span><span class="nam">items</span><span class="op">(</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t968" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t969" class="stm run hide_run">    <span class="key">def</span> <span class="nam">compute_output_shape</span><span class="op">(</span><span class="nam">self</span><span class="op">,</span> <span class="nam">input_shape</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t970" class="stm run hide_run">        <span class="key">return</span> <span class="nam">input_shape</span><span class="strut">&nbsp;</span></p>

            </td>
        </tr>
    </table>
</div>

<div id="footer">
    <div class="content">
        <p>
            <a class="nav" href="index.html">&#xab; index</a> &nbsp; &nbsp; <a class="nav" href="https://coverage.readthedocs.io">coverage.py v4.5.3</a>,
            created at 2019-03-19 10:50
        </p>
    </div>
</div>

</body>
</html>
